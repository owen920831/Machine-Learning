{"cells":[{"cell_type":"markdown","metadata":{"id":"X_Te27fi-0pP"},"source":["# **HW1: Regression** \n","In *assignment 1*, you need to finish:\n","\n","1.  Basic Part: Implement the regression model to predict the number of dengue cases\n","\n","\n","> *   Step 1: Split Data\n","> *   Step 2: Preprocess Data\n","> *   Step 3: Implement Regression\n","> *   Step 4: Make Prediction\n","> *   Step 5: Train Model and Generate Result\n","\n","2.  Advanced Part: Implementing a regression model to predict the number of dengue cases in a different way than the basic part"]},{"cell_type":"markdown","metadata":{"id":"_wDdnos-4uUv"},"source":["# 1. Basic Part (60%)\n","In the first part, you need to implement the regression to predict the number of dengue cases\n","\n","Please save the prediction result in a csv file **hw1_basic.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"RzCR7vk9BFkf"},"source":["## Import Packages\n","\n","> Note: You **cannot** import any other package in the basic part"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"HL5XjqFf4wSj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import csv\n","import math\n","import random\n","\n","# from sklearn import linear_model\n","# from sklearn.preprocessing import PolynomialFeatures\n","# from sklearn.pipeline import make_pipeline\n","# from sklearn.datasets import make_regression\n","# from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"jnWjrzi0dMPz"},"source":["## Global attributes\n","Define the global attributes"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"EWLDPOlHBbcK"},"outputs":[],"source":["input_dataroot = 'hw1_basic_input.csv' # Input file named as 'hw1_basic_input.csv'\n","output_dataroot = 'hw1_basic.csv' # Output file will be named as 'hw1_basic.csv'\n","\n","input_datalist =  [] # Initial datalist, saved as numpy array\n","output_datalist =  [] # Your prediction, should be 10 * 4 matrix and saved as numpy array\n","             # The format of each row should be ['epiweek', 'CityA', 'CityB', 'CityC']"]},{"cell_type":"markdown","metadata":{"id":"PsFC-cvqIcYK"},"source":["You can add your own global attributes here\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"OUbS2BEgcut6"},"outputs":[],"source":["\n","shuffle_value = 0.8"]},{"cell_type":"markdown","metadata":{"id":"rUoRFoQjBW5S"},"source":["## Load the Input File\n","First, load the basic input file **hw1_basic_input.csv**\n","\n","Input data would be stored in *input_datalist*"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"dekR1KnqBtI6"},"outputs":[],"source":["# Read input csv to datalist\n","with open(input_dataroot, newline='') as csvfile:\n","  input_datalist = np.array(list(csv.reader(csvfile)))\n"]},{"cell_type":"markdown","metadata":{"id":"6kYPuikLCFx4"},"source":["## Implement the Regression Model\n","\n","> Note: It is recommended to use the functions we defined, you can also define your own functions\n"]},{"cell_type":"markdown","metadata":{"id":"jWwdx06JNEYs"},"source":["### Step 1: Split Data\n","Split data in *input_datalist* into training dataset and validation dataset \n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"USDciENcB-5F"},"outputs":[],"source":["\n","def SplitData(tmp, country_index):\n","  shuffled_data = np.delete(tmp, 0, 0)\n","  #np.random.shuffle(shuffled_data)\n","  rows, columns = shuffled_data.shape\n","  x, y = np.array(shuffled_data.T[country_index]), np.array(shuffled_data.T[country_index+3])\n","\n","  str_data = np.vstack((x, y)).T\n","  new_data = np.asarray(str_data, dtype=float)\n","\n","  training_data, vaildation_data = np.array(new_data[:int(rows*shuffle_value)]), np.array(new_data[int(rows*shuffle_value):])\n","\n","\n","  return [training_data, vaildation_data]\n","  #print(x_test.shape, x_vaild.shape, y_test.shape, y_vaild.shape)"]},{"cell_type":"markdown","metadata":{"id":"u-3Qln4aNgVy"},"source":["### Step 2: Preprocess Data\n","Handle the unreasonable data\n","> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "]},{"cell_type":"code","execution_count":33,"metadata":{"id":"XXvW1n_5NkQ5"},"outputs":[],"source":["def PreprocessData(country_index):\n","    data = []\n","    tmp = input_datalist\n","    for col in range(len(input_datalist)-1, -1, -1):\n","        if input_datalist[col, 1] == '' or input_datalist[col, 4] == '0':\n","            tmp = np.delete(tmp, col, 0) #將''刪除及0刪除\n","    #print(tmp)\n","    for col in range(1, len(tmp)):\n","        #print(col)\n","        data.append(1/float(tmp[col, country_index]))\n","        #print(data)\n","\n","    data_mean, data_std = np.mean(data), np.std(data)\n","    lower, upper = data_mean - data_std*1.5, data_mean + data_std*1.5\n","    tmp_iter = tmp\n","    for index in range(len(data)-1, -1, -1):\n","        if data[index] >= upper or data[index] <= lower:\n","           # print(index, tmp[index+1], data[index])\n","            tmp = np.delete(tmp, index+1, 0)   \n","            \n","    return tmp\n","\n","  "]},{"cell_type":"markdown","metadata":{"id":"yDLpJmQUN3V6"},"source":["### Step 3: Implement Regression\n","> Hint: You can use Matrix Inversion, or Gradient Descent to finish this part\n","\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Tx9n1_23N8C0"},"outputs":[],"source":["def gradient(w_i, j, data, L):\n","    data_x, data_y = data[:, 0], data[:, 1]\n","    n = len(data_x)\n","    w_gradient_i = np.zeros(j+1)\n","    for i in range(n):\n","        x = data_x[i]\n","        y = data_y[i]\n","        x_power_list = np.power(x, np.arange(j+1)) #[1, x, x^2, ...]\n","        #print(x_power_list.shape, w_i.shape)\n","        for l in range(j+1):\n","            #print(l, j)\n","            w_gradient_i[l] = w_gradient_i[l] - (2/n)*x_power_list[l]*(y - w_i.dot(x_power_list.T))\n","\n","    return w_i - w_gradient_i*L\n","\n","\n","\n","\n","def Regression(data, j):\n","    w_i = []\n","    data_x, data_y = data[:, 0], data[:, 1]\n","    #print(data_x, data_y)\n","    w_i = np.zeros(j+1)\n","    alpha = 0.000002\n","    repeats = 10000\n","\n","    for i in range(repeats):\n","        w_i = gradient(w_i, j, data, alpha)\n","\n","    return w_i\n"]},{"cell_type":"markdown","metadata":{"id":"2NxRNFwyN8xd"},"source":["### Step 4: Make Prediction\n","Make prediction of testing dataset and store the value in *output_datalist*"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"EKlDIC2-N_lk"},"outputs":[{"ename":"SyntaxError","evalue":"unexpected EOF while parsing (1545714617.py, line 2)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn [35], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"]}],"source":["def MakePrediction():\n","  "]},{"cell_type":"markdown","metadata":{"id":"cCd0Z6izOCwq"},"source":["### Step 5: Train Model and Generate Result\n","\n","> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n","* If your regression model is *3x^2 + 2x^1 + 1*, your output would be: \n","```\n","3 2 1\n","```\n","\n","\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"iCL92EPKOFIn"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [36], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m training_data, vaildation_data \u001b[39m=\u001b[39m SplitData(PreprocessData(i), i)\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     w_i \u001b[39m=\u001b[39m Regression(training_data, j)\n\u001b[1;32m     16\u001b[0m     plt\u001b[39m.\u001b[39mscatter(training_data[:, \u001b[39m0\u001b[39m], training_data[:, \u001b[39m1\u001b[39m], color \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[39m.\u001b[39mscatter(vaildation_data[:, \u001b[39m0\u001b[39m], vaildation_data[:, \u001b[39m1\u001b[39m], color \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m)\n","Cell \u001b[0;32mIn [34], line 28\u001b[0m, in \u001b[0;36mRegression\u001b[0;34m(data, j)\u001b[0m\n\u001b[1;32m     25\u001b[0m repeats \u001b[39m=\u001b[39m \u001b[39m100000\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repeats):\n\u001b[0;32m---> 28\u001b[0m     w_i \u001b[39m=\u001b[39m gradient(w_i, j, data, alpha)\n\u001b[1;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m w_i\n","Cell \u001b[0;32mIn [34], line 12\u001b[0m, in \u001b[0;36mgradient\u001b[0;34m(w_i, j, data, L)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39m#print(x_power_list.shape, w_i.shape)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     11\u001b[0m         \u001b[39m#print(l, j)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         w_gradient_i[l] \u001b[39m=\u001b[39m w_gradient_i[l] \u001b[39m-\u001b[39m (\u001b[39m2\u001b[39m\u001b[39m/\u001b[39mn)\u001b[39m*\u001b[39mx_power_list[l]\u001b[39m*\u001b[39m(y \u001b[39m-\u001b[39m w_i\u001b[39m.\u001b[39;49mdot(x_power_list\u001b[39m.\u001b[39;49mT))\n\u001b[1;32m     14\u001b[0m \u001b[39mreturn\u001b[39;00m w_i \u001b[39m-\u001b[39m w_gradient_i\u001b[39m*\u001b[39mL\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","def Mape(vaild, w_i, j):\n","    print(w_i)\n","    mape = 0.0\n","    N = len(vaild)\n","    for i in range(N):\n","        x_power_list = np.power(vaild[i, 0], np.arange(j+1))\n","        mape += (abs(vaild[i, 1] - w_i.dot(x_power_list.T)))*100/(vaild[i, 1]*N)\n","    return mape\n","\n","    \n","for i in range(1, 4):\n","    w_i = []\n","    training_data, vaildation_data = SplitData(PreprocessData(i), i)\n","    for j in range(1, 3):\n","        w_i = Regression(training_data, j)\n","        plt.scatter(training_data[:, 0], training_data[:, 1], color ='black')\n","        plt.scatter(vaildation_data[:, 0], vaildation_data[:, 1], color ='green')\n","\n","        x = np.arange(max(training_data[:, 0]))\n","        y = np.zeros(len(x))\n","        for k in range(len(x)):\n","            x_power_list = np.power(x[k], np.arange(j+1))\n","            y[k] = w_i.dot(x_power_list.T)\n","        plt.plot(x, y, color ='red') # 繪製x,y軸的圖\n","        mymodel = np.poly1d(np.polyfit(training_data[:, 0], training_data[:, 1], j))\n","        myline = np.linspace(1, max(training_data[:, 0]))\n","        plt.plot(myline, mymodel(myline))\n","        plt.show()\n","        mape = Mape(vaildation_data, w_i, j)\n","        print(mape)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"J8Jhd8wAOk3D"},"source":["## Write the Output File\n","Write the prediction to output csv\n","> Format: 'epiweek', 'CityA', 'CityB', 'CityC'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYQVYLlKOtDB"},"outputs":[],"source":["with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n","  writer = csv.writer(csvfile)\n","  for row in output_datalist:\n","    writer.writerow(row)"]},{"cell_type":"markdown","metadata":{"id":"rx4408qg4xMQ"},"source":["# 2. Advanced Part (35%)\n","In the second part, you need to implement the regression in a different way than the basic part to help your predictions for the number of dengue cases\n","\n","We provide you with two files **hw1_advanced_input1.csv** and **hw1_advanced_input2.csv** that can help you in this part\n","\n","Please save the prediction result in a csv file **hw1_advanced.csv** \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaZCe19m41g1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"EtgCJU7FPeJL"},"source":["# Report *(5%)*\n","\n","Report should be submitted as a pdf file **hw1_report.pdf**\n","\n","*   Briefly describe the difficulty you encountered \n","*   Summarize your work and your reflections \n","*   No more than one page\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hlEE53_MPf4W"},"source":["# Save the Code File\n","Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
