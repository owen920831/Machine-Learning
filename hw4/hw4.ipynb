{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IagZMs0_qjdL"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "Welcome to your fourth assignment. In this assignment, you will build a convolutional neural network step by step. In this notebook, you will implement all the functions required to build a convolutional neural network.\n",
        "\n",
        "After finishing this assignment, you will have a deeper understanding of the process of training a convolutional neural network, which mainly consists of two parts: convolution layer and pooling layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGFR00CQvoaH"
      },
      "source": [
        "# 2. Packages\n",
        "All the packages that you need to finish basic part of this assignment are listed below.\n",
        "*   numpy : The fundamental package for scientific computing with Python.\n",
        "*   matplotlib : A comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
        "*   math : Python has a built-in module that you can use for mathematical tasks.\n",
        "*   pandas.read_csv : Provides functionality for reading a csv dataset from a GitHub repository.\n",
        "* sklearn.model_selection.train_test_split: A function helps you split train and test data.\n",
        "* os: A module provides the facility to establish the interaction between the user and the operating system. You can access the image directory by os.\n",
        "* cv2.imread: It is the module import name for opencv-python.\n",
        "* time: Provides various time-related functions.\n",
        "* google.colab.drive: Let you connect colab and your googol drive.\n",
        "* sys: Let you access system-specific parameters and functions.\n",
        "\n",
        "⚠️ **WARNING** ⚠️: \n",
        "*   Please do not import any other packages in basic part.\n",
        "*   np.random.seed(seed) is used to keep all the random function calls consistent. It will help us grade your work. Please don't change the seed.\n",
        "\n",
        "❗ **Important** ❗: Please do not change the code outside this code bracket.\n",
        "```\n",
        "### START CODE HERE ### (≈ n lines)\n",
        "...\n",
        "### END CODE HERE ###\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YcLLrIEc-4h6"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_go37iU6-4k8"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append(\"/content/drive/....\") ## the path of the directory where you place dense.py, activation.py ...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fmTH9UkeqdYf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import time \n",
        "import numpy as np\n",
        "from cv2 import imread, IMREAD_GRAYSCALE # IMREAD_GRAYSCALE allow you to load the image as gray scale image\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###### import your HW3 code (Don't change this part) ######\n",
        "from Dense import Dense\n",
        "from Activation import Activation\n",
        "from Loss import compute_BCE_cost\n",
        "from Predict import predict\n",
        "##################################\n",
        "\n",
        "output = {}\n",
        "seed = 1\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMe4BNRPRQvF"
      },
      "source": [
        "# 3. Convolution layer\n",
        "\n",
        "In this section, you will need to implement a very important part of the convolutional neural network, which is the convolution layer. Convolution layer enables us to capture the important features of input images.\n",
        "\n",
        "You will have to implement two helper functions and the forward pass of the convolution layer. All you need to do is to follow the instructions and understand how each part works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ADlgENHVRQvG"
      },
      "outputs": [],
      "source": [
        "def zero_pad(X, pad):\n",
        "    \"\"\"\n",
        "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image.\n",
        "    \n",
        "    Argument:\n",
        "    X -- python numpy array of shape (m, n_H, n_W, n_C), where m represent the number of examples.\n",
        "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
        "    \n",
        "    Returns:\n",
        "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # GRADED FUNCTION: zero_padding\n",
        "    ### START CODE HERE ### (≈ 1 line)\n",
        "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=(0, 0))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nNerbFLTRQvG"
      },
      "outputs": [],
      "source": [
        "class Conv():\n",
        "    def __init__(self, filter_size=2, input_channel=3, output_channel=8, pad=1, stride=1, seed=1):\n",
        "        \n",
        "        self.filter_size= filter_size\n",
        "        self.input_channel=input_channel\n",
        "        self.output_channel=output_channel\n",
        "        self.seed = seed\n",
        "        \n",
        "        self.parameters = {\"pad\": pad, \"stride\": stride}\n",
        "        self.initialize_parameters()\n",
        "        \n",
        "        \n",
        "        self.name=\"conv\"\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        self.filter_size -- size of the filter\n",
        "        self.input_channel -- size of the input channel\n",
        "        self.output_channel -- size of the output channel\n",
        "        self.parameters -- python dictionary containing your parameters:\n",
        "                           W -- weight matrix of shape (filter_size, filter_size, input channel size, output channel size)\n",
        "                           b -- bias vector of shape (1, 1, 1, output channel size)\n",
        "                           pad -- amount of padding around each image on vertical and horizontal dimensions\n",
        "                           stride -- represent the amount of movement that a filter move in one step\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        # GRADED FUNCTION: conv_initialization\n",
        "        ### START CODE HERE ### (≈ 8 lines)\n",
        "        limit = math.sqrt(6/(self.input_channel+self.output_channel))\n",
        "        W = np.random.uniform(-limit, limit, (self.filter_size,self.filter_size, self.input_channel, self.output_channel))\n",
        "        b = np.zeros((1,1,1,self.output_channel))\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        assert(W.shape == (self.filter_size,self.filter_size,self.input_channel,self.output_channel))\n",
        "        assert(b.shape == (1,1,1,self.output_channel))\n",
        "\n",
        "        self.parameters['W'] = W\n",
        "        self.parameters['b'] = b\n",
        "        \n",
        "    \n",
        "    \n",
        "    def conv_single_step(self, a_slice_prev, W, b):\n",
        "        \"\"\"\n",
        "        Apply a filter W on a_slice_prev.\n",
        "\n",
        "        Arguments:\n",
        "        a_slice_prev -- slice of input data of shape (filter_size, filter_size, n_C_prev)\n",
        "        W -- Weight parameters contained in a window - matrix of shape (filter_size, filter_size, n_C_prev)\n",
        "        b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
        "\n",
        "        Returns:\n",
        "        Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data\n",
        "        \"\"\"\n",
        "\n",
        "        # GRADED FUNCTION: conv_single_step\n",
        "        ### START CODE HERE ### (≈ 3 lines)\n",
        "        # Element-wise product between a_slice and W.\n",
        "        s = np.multiply(a_slice_prev, W)\n",
        "        # Sum over all entries of the volume s.\n",
        "        Z = np.sum(s)\n",
        "        # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
        "        Z = Z + float(b)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return Z\n",
        "    \n",
        "    def forward(self, A_prev):\n",
        "        \"\"\"\n",
        "        Implements the forward propagation for a convolution layer\n",
        "\n",
        "        Arguments:\n",
        "        A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "\n",
        "        Returns:\n",
        "        Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
        "        \"\"\"\n",
        "\n",
        "        # GRADED FUNCTION: conv_forward\n",
        "        ### START CODE HERE ###\n",
        "        # Retrieve dimensions from A_prev's shape (≈1 line)  \n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "        # Retrieve dimensions from W's shape (≈1 line)\n",
        "        (f, f, n_C_prev, n_C) = self.parameters[\"W\"].shape\n",
        "\n",
        "        # Compute the dimensions of the convolution output volume using the formula given below.(≈2 lines)\n",
        "        n_H = int((n_H_prev - f + (2 * self.parameters[\"pad\"])) / self.parameters[\"stride\"]) +1 \n",
        "        n_W = int((n_W_prev - f + (2 * self.parameters[\"pad\"])) / self.parameters[\"stride\"]) +1\n",
        "\n",
        "        # Initialize the output volume Z with zeros. (≈1 line)\n",
        "        Z = np.zeros((m, n_H, n_W, n_C))\n",
        "\n",
        "        # if pad!=0, create A_prev_pad by padding A_prev with the parameter \"pad\". (≈1 line)\n",
        "        A_prev_pad = zero_pad(A_prev, self.parameters[\"pad\"])\n",
        "\n",
        "        for i in range(m):                               # loop over the batch of training examples\n",
        "            a_prev_pad = A_prev_pad[i,:,:,:]               # Select ith training example's padded activation\n",
        "            for h in range(n_H):                           # loop over vertical axis of the output volume\n",
        "                for w in range(n_W):                       # loop over horizontal axis of the output volume\n",
        "                    for c in range(n_C):                   # loop over channels (= #filter) of the output volume\n",
        "\n",
        "                        # Find the corners of the current \"slice\" (≈4 lines)\n",
        "                        vert_start = h * self.parameters[\"stride\"]\n",
        "                        vert_end = vert_start + f\n",
        "                        horiz_start = w * self.parameters[\"stride\"]\n",
        "                        horiz_end = horiz_start + f\n",
        "                        # Use the corners to define the slice of a_prev_pad. (≈1 line)\n",
        "                        a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end]\n",
        "\n",
        "                        # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)\n",
        "                        Z[i, h, w, c] = self.conv_single_step(a_slice_prev, self.parameters[\"W\"][:, :, :, c], self.parameters[\"b\"][:, :, :, c])\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Making sure your output shape is correct\n",
        "        assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "\n",
        "        # Save information in \"cache\" for the backward pass\n",
        "        self.cache = A_prev\n",
        "\n",
        "        return Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \"\"\"\n",
        "        Implement the backward propagation for a convolution layer\n",
        "\n",
        "        Arguments:\n",
        "        dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)\n",
        "\n",
        "        Returns:\n",
        "        dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),\n",
        "                   numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        A_prev = self.cache\n",
        "\n",
        "        # Retrieve dimensions from A_prev's shape\n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "        # Retrieve dimensions from W's shape\n",
        "        (f, f, n_C_prev, n_C) = self.parameters[\"W\"].shape\n",
        "\n",
        "\n",
        "        # Retrieve dimensions from dZ's shape\n",
        "        (m, n_H, n_W, n_C) = dZ.shape\n",
        "\n",
        "        # Initialize dA_prev, dW, db with the correct shapes\n",
        "        dA_prev = np.zeros((m, n_H_prev, n_W_prev, n_C_prev))                           \n",
        "        dW = np.zeros((f, f, n_C_prev, n_C))\n",
        "        db = np.zeros((1, 1, 1, n_C))\n",
        "\n",
        "        # Pad A_prev and dA_prev\n",
        "        A_prev_pad = zero_pad(A_prev, self.parameters[\"pad\"])\n",
        "        dA_prev_pad = zero_pad(dA_prev, self.parameters[\"pad\"])\n",
        "\n",
        "        for i in range(m):                       # loop over the training examples\n",
        "\n",
        "            # select ith training example from A_prev_pad and dA_prev_pad\n",
        "            a_prev_pad = A_prev_pad[i]\n",
        "            da_prev_pad = dA_prev_pad[i]\n",
        "\n",
        "            for h in range(n_H):                   # loop over vertical axis of the output volume\n",
        "                for w in range(n_W):               # loop over horizontal axis of the output volume\n",
        "                    for c in range(n_C):           # loop over the channels of the output volume\n",
        "\n",
        "                        # Find the corners of the current \"slice\"\n",
        "                        vert_start = h * self.parameters[\"stride\"]\n",
        "                        vert_end = vert_start + f\n",
        "                        horiz_start = w * self.parameters[\"stride\"]\n",
        "                        horiz_end = horiz_start + f\n",
        "\n",
        "                        # Use the corners to define the slice from a_prev_pad\n",
        "                        a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "\n",
        "                        # Update gradients for the window and the filter's parameters\n",
        "                        da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += self.parameters[\"W\"][:,:,:,c] * dZ[i, h, w, c]\n",
        "                        dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                        db[:,:,:,c] += dZ[i, h, w, c]\n",
        "\n",
        "            # Set the ith training example's dA_prev to the unpaded da_prev_pad\n",
        "            dA_prev[i, :, :, :] = da_prev_pad[self.parameters[\"pad\"]:da_prev_pad.shape[0]-self.parameters[\"pad\"], \n",
        "                                              self.parameters[\"pad\"]:da_prev_pad.shape[1]-self.parameters[\"pad\"], :]\n",
        "\n",
        "        assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "\n",
        "        self.dW = dW\n",
        "        self.db = db\n",
        "\n",
        "        return dA_prev\n",
        "    \n",
        "    def update(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Update parameters using gradient descent\n",
        "        \n",
        "        Arguments:\n",
        "        learning rate -- step size\n",
        "        \"\"\"\n",
        "\n",
        "        # GRADED FUNCTION: conv_update\n",
        "        ### START CODE HERE ### (≈ 2 lines of code)\n",
        "        self.parameters[\"W\"] = self.parameters[\"W\"] - learning_rate*self.dW\n",
        "        self.parameters[\"b\"] = self.parameters[\"b\"] - learning_rate*self.db\n",
        "        ### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_4VjV5W_gL"
      },
      "source": [
        "##3.1 initialization\n",
        "Using Glorot uniform initialization to initialize the convolution layer's filters with the parameters: filter_size, input_channel, and output_channel.\n",
        "\n",
        "*   Use random initialization (uniform distribution) for the weight matrices. Draws samples from a uniform distribution within [-limit, limit], where limit = sqrt(6 / (fan_in + fan_out)), fan_in is the **number of input channel** and fan_out is the **number of output channel**. However, in the usual implementation, we will consider fan_in and fan_out as the number of input units and the number of output units.\n",
        "*   Use zero initialization for the biases.\n",
        "\n",
        "Exercise: Create and initialize parameters of a convolution layer using Glorot uniform initialization. (1%)\n",
        "\n",
        "It will take following parameters to initialize the convolution layer:\n",
        "*   filter_size: The filter will be in the shape of (filter_size*filter_size)\n",
        "*   input_channel: size of the input channel\n",
        "*   output_channel: size of the output channel\n",
        "*   pad: amount of padding around each image on vertical and horizontal dimensions\n",
        "*   stride: represent the amount of movement that a filter move in one step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "McQisK1WW-4t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W[0][0][0] =  [-0.12256662  0.32544084 -0.73838    -0.29197414 -0.52177613 -0.6021558\n",
            " -0.46342438 -0.22812192]\n",
            "b =  [[[[0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "conv = Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
        "print(\"W[0][0][0] = \",  conv.parameters[\"W\"][0][0][0])\n",
        "print(\"b = \", conv.parameters[\"b\"])\n",
        "\n",
        "np.random.seed(seed)\n",
        "conv = Conv(filter_size=2, input_channel=3, output_channel=16, pad=2, stride=2)\n",
        "output[\"conv_initialization\"] = conv.parameters[\"W\"][0][0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t50bsMBRTrP6"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>W[0][0][0]: </td>\n",
        "    <td>[-0.12256662  0.32544084 -0.73838    -0.29197414 -0.52177613 -0.6021558 -0.46342438 -0.22812192]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>b: </td>\n",
        "    <td>[[[[0. 0. 0. 0. 0. 0. 0. 0.]]]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAHuFnmDIhgY"
      },
      "source": [
        "## 3.2  Zero-Padding\n",
        "\n",
        "Pad around each image on vertical and horizontal dimensions with zero.\n",
        "\n",
        "1. It allows you to use a convolution layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks since otherwise the height/width would shrink as you go to deeper layers. \n",
        "2. It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.\n",
        "\n",
        "**Exercise**: Implement the zero_pad() function to pad the input X with the given parameter \"pad\". (3%)\n",
        "\n",
        "This function takes the following inputs:\n",
        "*   X: input.\n",
        "*   pad: amount of padding around each image on vertical and horizontal dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h9xGiJH5IgyJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 7, 7, 2)\n",
            "x[0,2,:,0] =\n",
            " [-0.3224172   1.13376944 -0.17242821]\n",
            "x_pad[0,2,:,0] =\n",
            " [ 0.          0.          1.62434536 -0.52817175  0.86540763  0.\n",
            "  0.        ]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAEjCAYAAAD6/uGiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlTElEQVR4nO3df3RU9YH38c+EyAQkiQTILwiQFkogIeFHgAZYCWskRorFtaxL7UOIla6cRIHYStPtisqW0dOqsMhDQBeCqxSkFfAnGIMhZQkCwWyh9CCxSCKSoAskJOqAmfv8sY/TTkkQam5uvsn7dc49x3vne+d+ZjJ3/HDn3hmXZVmWAAAADBHkdAAAAIBrQXkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABiF8gIAAIxCeQEAoBVz587V4MGDnY6Bv0J5AQAARqG8AAAAo1BeAACAUSgvcNxnn32mhIQEJSQk6LPPPvMvP3v2rGJiYjRx4kQ1Nzc7mBBAW2irfb20tFQul0ubN2/Wz372M0VHR+v666/XbbfdppqamoCxv/vd7zRr1iwNHDhQbrdbcXFxWrRoUcD2v7Rt2zYlJSUpJCRESUlJ2rp169d/0LAF5QWO69GjhzZs2KCqqir9y7/8i395bm6u6uvrVVRUpG7dujmYEEBbaOt9/Re/+IVee+01LV68WPfff7+Ki4uVkZERUEy2bNmiTz/9VPPnz9fKlSuVmZmplStXas6cOQH39eabb+qOO+6Qy+WSx+PRzJkzlZOTo4MHD379B462ZwEdREFBgRUUFGSVlZVZW7ZssSRZy5cvdzoWgDb2dff1t99+25Jk9e/f32poaPAvf/HFFy1J1ooVK/zLPv3008vW93g8lsvlsk6ePOlfNmrUKCsmJsY6f/68f9mbb75pSbIGDRp0jY8QdnNZlmU52p6A/+/ixYtKTU1VY2OjGhsbNWLECL399ttyuVxORwPQhr7uvl5aWqqpU6eqoKBAy5Yt8y+3LEv9+/dXcnKyduzYcdl6TU1N+uyzz3T06FFNmTJF27Zt03e/+12dPn1asbGx+ulPfyqPxxOwTmJiopqamvTBBx98rceMtsXHRugwunfvrnXr1unEiRO6cOGC1q9fT3EBOqG22teHDh0aMO9yuTRkyJCAolFdXa25c+cqIiJCvXr1Ur9+/TRlyhRJUn19vSTp5MmTLd6fJA0bNuyac8F+wU4HAP7Szp07JUmff/65jh8/rvj4eIcTAbBDe+zrzc3Nuvnmm3X27FktXrxYCQkJuv7663Xq1CnNnTtXPp+vzbeJ9kF5QYfx+9//Xo8++qhycnJUWVmpe+65R4cPH1Z4eLjT0QC0obba148fPx4wb1mWqqqqlJycLEk6fPiw3nvvPW3YsCHgBN3i4uKA9QYNGtTi/UnSsWPHrikT2gcfG6FDuHTpkubOnavY2FitWLFCRUVFqqur06JFi5yOBqANteW+/txzz+nChQv++d/85jc6ffq0srKyJMl/5dJfntppWZZWrFgRcD8xMTEaNWqUNmzY4P8oSfrfknP06NFrzgX7ceQFHcK//du/qbKyUiUlJQoNDVVycrIeeugh/fznP9f3vvc93XrrrU5HBNAG2nJfj4iI0OTJk5WTk6O6ujotX75cQ4YM0bx58yRJCQkJ+uY3v6kf//jHOnXqlMLCwvTb3/5W586du+y+PB6Ppk+frsmTJ+vuu+/W2bNntXLlSiUmJqqxsbHNHj/aiJOXOgGWZVkVFRVWcHCwdd999wUs/+KLL6xx48ZZsbGx1rlz55wJB6DNtNW+/uWl0r/+9a+tgoICKzIy0urRo4c1ffr0gMufLcuyjh49amVkZFi9evWy+vbta82bN8/67//+b0uStX79+oCxv/3tb63hw4dbbrfbGjFihPXSSy9Z2dnZXCrdAXGpNADAKF9eKr1lyxZ973vfczoOHMA5LwAAwCic8wIA6BAuXryos2fPXnEMVx9CorwAADqIvXv3aurUqVccs379eg0ePLh9AqHDsu2cl7Nnz+q+++7TK6+8oqCgIN1xxx1asWKFevXq1eo66enp2r17d8Cyf/7nf1ZhYaEdEQEAHci5c+dUUVFxxTGJiYmKiYlpp0ToqGwrL1lZWTp9+rTWrFmjS5cuKScnR+PGjdPGjRtbXSc9PV3f+ta39Oijj/qX9ezZU2FhYXZEBAAABrLlY6M//vGP2rFjhw4cOKDU1FRJ0sqVK3XrrbfqV7/6lWJjY1tdt2fPnoqOjrYjFgAA6ARsKS/l5eW64YYb/MVFkjIyMhQUFKR33nlHt99+e6vrvvDCC3r++ecVHR2tGTNm6F//9V/Vs2fPVsd7vV55vV7/vM/n09mzZ9WnTx9+1A9wiGVZunDhgmJjYxUUZMZFjT6fTx999JFCQ0N57wAccC3vG7aUl9raWkVGRgZuKDhYERERqq2tbXW973//+xo0aJBiY2P1+9//XosXL9axY8f00ksvtbqOx+PRI4880mbZAbSdmpoaDRgwwOkYV+Wjjz5SXFyc0zGALu9q3jeuqbz89Kc/1eOPP37FMX/84x+v5S4D/OhHP/L/98iRIxUTE6ObbrpJ77//vr75zW+2uE5BQYHy8/P98/X19Ro4cKB+905f9eplxr/4nLQoMc3pCMaoLkp0OoIxfJ959cH8JxQaGup0lKv2ZdZxNxUoODjE4TRA1/PFF5/rQInnqt43rqm8PPDAA5o7d+4Vx3zjG99QdHS0zpw581ehvtDZs2ev6XyWCRMmSJKqqqpaLS9ut1tut/uy5b16BSk0lPLyVYJd1zkdwRhBPfkf2rUy6eOXL7MGB4co+Dr+1oBTruZ945rKS79+/dSvX7+vHJeWlqbz58+roqJCY8eOlSTt2rVLPp/PX0iuRmVlpSRxWRwAAPCz5dDE8OHDdcstt2jevHnav3+//uu//kt5eXn6p3/6J/+VRqdOnVJCQoL2798vSXr//fe1dOlSVVRU6IMPPtDLL7+sOXPm6MYbb1RycrIdMQEAgIFs+1zlhRdeUEJCgm666Sbdeuutmjx5stauXeu//dKlSzp27Jg+/fRTSVL37t311ltvadq0aUpISNADDzygO+64Q6+88opdEQEAgIFs+3mAiIiIK34h3eDBg/WX348XFxd32bfrAgAA/DXOaAUAAEahvAAAAKNQXgAAgFEoLwAAwCiUFwAAYBTKC4BOY9WqVRo8eLBCQkI0YcIE//dIAehcKC8AOoXNmzcrPz9fS5Ys0aFDh5SSkqLMzMzLfqoEgPkoLwA6hSeffFLz5s1TTk6ORowYocLCQvXs2VPr1q1zOhqANkZ5AWC8ixcvqqKiQhkZGf5lQUFBysjIUHl5eYvreL1eNTQ0BEwAzEB5AWC8Tz75RM3NzYqKigpYHhUVpdra2hbX8Xg8Cg8P909xcXHtERVAG6C8AOiSCgoKVF9f759qamqcjgTgKtn220YA0F769u2rbt26qa6uLmB5XV2doqOjW1zH7XbL7Xa3RzwAbYwjLwCM1717d40dO1YlJSX+ZT6fTyUlJUpLS3MwGQA7cOQFQKeQn5+v7Oxspaamavz48Vq+fLmampqUk5PjdDQAbYzyAqBTuPPOO/Xxxx/roYceUm1trUaNGqUdO3ZcdhIvAPNRXgB0Gnl5ecrLy3M6BgCbcc4LAAAwCuUFAAAYhfICAACMQnkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABilXcrLqlWrNHjwYIWEhGjChAnav3//Fcdv2bJFCQkJCgkJ0ciRI/X666+3R0wAAGAA28vL5s2blZ+fryVLlujQoUNKSUlRZmamzpw50+L4vXv3avbs2frhD3+od999VzNnztTMmTN15MgRu6MCAAAD2F5ennzySc2bN085OTkaMWKECgsL1bNnT61bt67F8StWrNAtt9yin/zkJxo+fLiWLl2qMWPG6Omnn7Y7KgAAMICt5eXixYuqqKhQRkbGnzcYFKSMjAyVl5e3uE55eXnAeEnKzMxsdbzX61VDQ0PABAAAOi9by8snn3yi5uZmRUVFBSyPiopSbW1ti+vU1tZe03iPx6Pw8HD/FBcX1zbhAQBAh2T81UYFBQWqr6/3TzU1NU5HAgAANgq288779u2rbt26qa6uLmB5XV2doqOjW1wnOjr6msa73W653e62CQwAADo8W4+8dO/eXWPHjlVJSYl/mc/nU0lJidLS0lpcJy0tLWC8JBUXF7c6HgAAdC22HnmRpPz8fGVnZys1NVXjx4/X8uXL1dTUpJycHEnSnDlz1L9/f3k8HknSggULNGXKFD3xxBOaPn26Nm3apIMHD2rt2rV2RwUAAAawvbzceeed+vjjj/XQQw+ptrZWo0aN0o4dO/wn5VZXVyso6M8HgCZOnKiNGzfq5z//uX72s59p6NCh2rZtm5KSkuyOCgAADGB7eZGkvLw85eXltXhbaWnpZctmzZqlWbNm2ZwKAACYyPirjQBAksrKyjRjxgzFxsbK5XJp27ZtTkcCYBPKC4BOoampSSkpKVq1apXTUQDYrF0+NgIAu2VlZSkrK8vpGADaAeUFQJfk9Xrl9Xr98/y0CGAOPjYC0CXx0yKAuSgvALokfloEMBcfGwHokvhpEcBcHHkBAABG4cgLgE6hsbFRVVVV/vkTJ06osrJSERERGjhwoIPJALQ1yguATuHgwYOaOnWqfz4/P1+SlJ2draKiIodSAbAD5QVAp5Ceni7LspyOAaAdcM4LAAAwCuUFAAAYhfICAACMQnkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK37ALAJAkrf+/TzkdQfcOmuzo9j/YnOzo9mOe45fOrwZHXgAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjNIu5WXVqlUaPHiwQkJCNGHCBO3fv7/VsUVFRXK5XAFTSEhIe8QEAAAGsL28bN68Wfn5+VqyZIkOHTqklJQUZWZm6syZM62uExYWptOnT/unkydP2h0TAAAYwvby8uSTT2revHnKycnRiBEjVFhYqJ49e2rdunWtruNyuRQdHe2foqKi7I4JAAAMYes37F68eFEVFRUqKCjwLwsKClJGRobKy8tbXa+xsVGDBg2Sz+fTmDFjtGzZMiUmJrY41uv1yuv1+ucbGhokSYOv66Ww6zil56vULpzodARjPD7mOacjGOPTC836P06HANBp2fp/908++UTNzc2XHTmJiopSbW1ti+sMGzZM69at0/bt2/X888/L5/Np4sSJ+vDDD1sc7/F4FB4e7p/i4uLa/HEAAICOo8MdmkhLS9OcOXM0atQoTZkyRS+99JL69eunNWvWtDi+oKBA9fX1/qmmpqadEwNwmsfj0bhx4xQaGqrIyEjNnDlTx44dczoWAJvYWl769u2rbt26qa6uLmB5XV2doqOjr+o+rrvuOo0ePVpVVVUt3u52uxUWFhYwAehadu/erdzcXO3bt0/FxcW6dOmSpk2bpqamJqejAbCBreWle/fuGjt2rEpKSvzLfD6fSkpKlJaWdlX30dzcrMOHDysmJsaumAAMt2PHDs2dO1eJiYlKSUlRUVGRqqurVVFR4XQ0ADaw9YRdScrPz1d2drZSU1M1fvx4LV++XE1NTcrJyZEkzZkzR/3795fH45EkPfroo/r2t7+tIUOG6Pz58/rlL3+pkydP6p577rE7KoBOor6+XpIUERHR6pjWTvYH0PHZXl7uvPNOffzxx3rooYdUW1urUaNGaceOHf6TeKurqxUU9OcDQOfOndO8efNUW1ur3r17a+zYsdq7d69GjBhhd1QAnYDP59PChQs1adIkJSUltTrO4/HokUceacdkANqK7eVFkvLy8pSXl9fibaWlpQHzTz31lJ566ql2SAWgM8rNzdWRI0e0Z8+eK44rKChQfn6+f76hoYGrFQFDtEt5AYD2kJeXp1dffVVlZWUaMGDAFce63W653e52SgagLVFeABjPsizdd9992rp1q0pLSxUfH+90JAA2orwAMF5ubq42btyo7du3KzQ01P8lmOHh4erRo4fD6QC0tQ73JXUAcK1Wr16t+vp6paenKyYmxj9t3rzZ6WgAbMCRFwDGsyzL6QgA2hFHXgAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUfiGXQCAJCn+ul5OR1DtwomObv/xMc85uv3lz812dPum4MgLAAAwCuUFAAAYhfICAACMQnkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABiF8gIAAIxCeQEAAEaxtbyUlZVpxowZio2Nlcvl0rZt275yndLSUo0ZM0Zut1tDhgxRUVGRnREBdAKrV69WcnKywsLCFBYWprS0NL3xxhtOxwJgE1vLS1NTk1JSUrRq1aqrGn/ixAlNnz5dU6dOVWVlpRYuXKh77rlHO3futDMmAMMNGDBAjz32mCoqKnTw4EH9/d//vb773e/qD3/4g9PRANgg2M47z8rKUlZW1lWPLywsVHx8vJ544glJ0vDhw7Vnzx499dRTyszMtCsmAMPNmDEjYP4Xv/iFVq9erX379ikxMdGhVADsYmt5uVbl5eXKyMgIWJaZmamFCxe2uo7X65XX6/XPNzQ02BUPgAGam5u1ZcsWNTU1KS0trdVxvHcA5upQJ+zW1tYqKioqYFlUVJQaGhr02WeftbiOx+NReHi4f4qLi2uPqAA6mMOHD6tXr15yu9269957tXXrVo0YMaLV8bx3AObqUOXlb1FQUKD6+nr/VFNT43QkAA4YNmyYKisr9c4772j+/PnKzs7W0aNHWx3Pewdgrg71sVF0dLTq6uoCltXV1SksLEw9evRocR232y23290e8QB0YN27d9eQIUMkSWPHjtWBAwe0YsUKrVmzpsXxvHcA5upQR17S0tJUUlISsKy4uPiKn1sDQEt8Pl/AOS0AOg9bj7w0NjaqqqrKP3/ixAlVVlYqIiJCAwcOVEFBgU6dOqXnnntOknTvvffq6aef1oMPPqi7775bu3bt0osvvqjXXnvNzpgADFdQUKCsrCwNHDhQFy5c0MaNG1VaWsrXLACdlK3l5eDBg5o6dap/Pj8/X5KUnZ2toqIinT59WtXV1f7b4+Pj9dprr2nRokVasWKFBgwYoGeffZbLpAFc0ZkzZzRnzhydPn1a4eHhSk5O1s6dO3XzzTc7HQ2ADWwtL+np6bIsq9XbW/r23PT0dL377rs2pgLQ2fzHf/yH0xEAtKMOdc4LAADAV6G8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLAAAwCuUFAAAYhfICAACM0qF+mBEA4JzpE29zOoKGPX/M0e0Xfv92R7evSGc3bwqOvAAAAKNQXgAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLgE7nsccek8vl0sKFC52OAsAGlBcAncqBAwe0Zs0aJScnOx0FgE0oLwA6jcbGRt1111165pln1Lt3b6fjALAJ5QVAp5Gbm6vp06crIyPjK8d6vV41NDQETADMEOx0AABoC5s2bdKhQ4d04MCBqxrv8Xj0yCOP2JwKgB1sPfJSVlamGTNmKDY2Vi6XS9u2bbvi+NLSUrlcrsum2tpaO2MCMFxNTY0WLFigF154QSEhIVe1TkFBgerr6/1TTU2NzSkBtBVbj7w0NTUpJSVFd999t/7hH/7hqtc7duyYwsLC/PORkZF2xAPQSVRUVOjMmTMaM2aMf1lzc7PKysr09NNPy+v1qlu3bgHruN1uud3u9o4KoA3YWl6ysrKUlZV1zetFRkbqhhtuaPtAADqlm266SYcPHw5YlpOTo4SEBC1evPiy4gLAbB3ynJdRo0bJ6/UqKSlJDz/8sCZNmtTqWK/XK6/X65/npDug6wkNDVVSUlLAsuuvv159+vS5bDkA83Wo8hITE6PCwkKlpqbK6/Xq2WefVXp6ut55552Aw8F/qbWT7mbdnKXgIA4Jf5Vhzx9zOoIxCr9/u9MRjPFF8+eSDn/lOAD4W3So8jJs2DANGzbMPz9x4kS9//77euqpp/Sf//mfLa5TUFCg/Px8/3xDQ4Pi4uJszwqgYystLXU6AgCbdKjy0pLx48drz549rd7OSXcAAHQtHf5L6iorKxUTE+N0DAAA0EHYeuSlsbFRVVVV/vkTJ06osrJSERERGjhwoAoKCnTq1Ck999xzkqTly5crPj5eiYmJ+vzzz/Xss89q165devPNN+2MCQAADGJreTl48KCmTp3qn//y3JTs7GwVFRXp9OnTqq6u9t9+8eJFPfDAAzp16pR69uyp5ORkvfXWWwH3AQAAujZby0t6erosy2r19qKiooD5Bx98UA8++KCdkQAAgOE6/DkvAAAAf4nyAgAAjEJ5AQAARunw3/MCAGgfTYlRTkdQk8fhAPwOsBE48gIAAIxCeQEAAEahvAAAAKNQXgAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAIz38MMPy+VyBUwJCQlOxwJgE35VGkCnkJiYqLfeess/HxzM2xvQWbF3A+gUgoODFR0d7XQMAO2Aj40AdArHjx9XbGysvvGNb+iuu+5SdXX1Fcd7vV41NDQETADMQHkBYLwJEyaoqKhIO3bs0OrVq3XixAn93d/9nS5cuNDqOh6PR+Hh4f4pLi6uHRMD+DooLwCMl5WVpVmzZik5OVmZmZl6/fXXdf78eb344outrlNQUKD6+nr/VFNT046JAXwdnPMCoNO54YYb9K1vfUtVVVWtjnG73XK73e2YCkBb4cgLgE6nsbFR77//vmJiYpyOAsAGlBcAxvvxj3+s3bt364MPPtDevXt1++23q1u3bpo9e7bT0QDYgI+NABjvww8/1OzZs/U///M/6tevnyZPnqx9+/apX79+TkcDYAPKCwDjbdq0yekIANqRrR8beTwejRs3TqGhoYqMjNTMmTN17Nixr1xvy5YtSkhIUEhIiEaOHKnXX3/dzpgAAMAgtpaX3bt3Kzc3V/v27VNxcbEuXbqkadOmqampqdV19u7dq9mzZ+uHP/yh3n33Xc2cOVMzZ87UkSNH7IwKAAAMYevHRjt27AiYLyoqUmRkpCoqKnTjjTe2uM6KFSt0yy236Cc/+YkkaenSpSouLtbTTz+twsJCO+MCAAADtOvVRvX19ZKkiIiIVseUl5crIyMjYFlmZqbKy8tbHM9XfAMA0LW0W3nx+XxauHChJk2apKSkpFbH1dbWKioqKmBZVFSUamtrWxzPV3wDANC1tFt5yc3N1ZEjR9r8qgC+4hsAgK6lXS6VzsvL06uvvqqysjINGDDgimOjo6NVV1cXsKyurq7Vn7rnK74BAOhabD3yYlmW8vLytHXrVu3atUvx8fFfuU5aWppKSkoClhUXFystLc2umAAAwCC2HnnJzc3Vxo0btX37doWGhvrPWwkPD1ePHj0kSXPmzFH//v3l8XgkSQsWLNCUKVP0xBNPaPr06dq0aZMOHjyotWvX2hkVAAAYwtYjL6tXr1Z9fb3S09MVExPjnzZv3uwfU11drdOnT/vnJ06cqI0bN2rt2rVKSUnRb37zG23btu2KJ/kCAICuw9YjL5ZlfeWY0tLSy5bNmjVLs2bNsiERAAAwHb8qDQAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLAAAwCuUFAAAYhfICAACMQnkBAABGobwA6BROnTqlH/zgB+rTp4969OihkSNH6uDBg07HAmADW3/bCADaw7lz5zRp0iRNnTpVb7zxhvr166fjx4+rd+/eTkcDYAPKCwDjPf7444qLi9P69ev9y+Lj4x1MBMBOfGwEwHgvv/yyUlNTNWvWLEVGRmr06NF65plnrriO1+tVQ0NDwATADJQXAMb705/+pNWrV2vo0KHauXOn5s+fr/vvv18bNmxodR2Px6Pw8HD/FBcX146JAXwdlBcAxvP5fBozZoyWLVum0aNH60c/+pHmzZunwsLCVtcpKChQfX29f6qpqWnHxAC+DsoLAOPFxMRoxIgRAcuGDx+u6urqVtdxu90KCwsLmACYgfICwHiTJk3SsWPHApa99957GjRokEOJANiJ8gLAeIsWLdK+ffu0bNkyVVVVaePGjVq7dq1yc3OdjgbABpQXAMYbN26ctm7dql//+tdKSkrS0qVLtXz5ct11111ORwNgA77nBUCn8J3vfEff+c53nI4BoB1w5AUAABiF8gIAAIxCeQEAAEahvAAAAKNQXgAAgFFsLS8ej0fjxo1TaGioIiMjNXPmzMu+SOqvFRUVyeVyBUwhISF2xgQAAAaxtbzs3r1bubm52rdvn4qLi3Xp0iVNmzZNTU1NV1wvLCxMp0+f9k8nT560MyYAADCIrd/zsmPHjoD5oqIiRUZGqqKiQjfeeGOr67lcLkVHR9sZDQAAGKpdv6Suvr5ekhQREXHFcY2NjRo0aFDAL8UmJia2ONbr9crr9V62jS98F9soded2qYnn6Wp90fy50xGM8UXz/+6TlmU5nOTqfZn1iy/4OwNO+HLfu5r3DZfVTu8uPp9Pt912m86fP689e/a0Oq68vFzHjx9XcnKy6uvr9atf/UplZWX6wx/+oAEDBlw2/uGHH9YjjzxiZ3QAf6OampoW99uO6MMPP1RcXJzTMYAu72reN9qtvMyfP19vvPGG9uzZc01vZpcuXdLw4cM1e/ZsLV269LLb//rIi8/n09mzZ9WnTx+5XK42yd4WGhoaFBcXp5qaGoWFhTkdp0Pjubp6HfW5sixLFy5cUGxsrIKCzLio0efz6aOPPlJoaOjf9N7RUf8W7aWrP36J5+DrPv5red9ol4+N8vLy9Oqrr6qsrOya/xV23XXXafTo0aqqqmrxdrfbLbfbHbDshhtu+Fuj2i4sLKxLvqj/FjxXV68jPlfh4eFOR7gmQUFBbXKUqCP+LdpTV3/8Es/B13n8V/u+Yes/iSzLUl5enrZu3apdu3YpPj7+mu+jublZhw8fVkxMjA0JAQCAaWw98pKbm6uNGzdq+/btCg0NVW1traT/bVY9evSQJM2ZM0f9+/eXx+ORJD366KP69re/rSFDhuj8+fP65S9/qZMnT+qee+6xMyoAADCEreVl9erVkqT09PSA5evXr9fcuXMlSdXV1QGfbZ07d07z5s1TbW2tevfurbFjx2rv3r0aMWKEnVFt53a7tWTJkss+4sLleK6uHs9Vx9HV/xZd/fFLPAft+fjb7YRdAACAtmDGZQAAAAD/H+UFAAAYhfICAACMQnkBAABGobwAAACjUF7awapVqzR48GCFhIRowoQJ2r9/v9OROqSysjLNmDFDsbGxcrlc2rZtm9OROiyPx6Nx48YpNDRUkZGRmjlzpo4dO+Z0rC6rK+/jvBYDPfbYY3K5XFq4cKHTUdrVqVOn9IMf/EB9+vRRjx49NHLkSB08eNC27VFebLZ582bl5+dryZIlOnTokFJSUpSZmakzZ844Ha3DaWpqUkpKilatWuV0lA5v9+7dys3N1b59+1RcXKxLly5p2rRpampqcjpal9PV93Fei3924MABrVmzRsnJyU5HaVfnzp3TpEmTdN111+mNN97Q0aNH9cQTT6h37972bdSCrcaPH2/l5ub655ubm63Y2FjL4/E4mKrjk2Rt3brV6RjGOHPmjCXJ2r17t9NRuhz28UBd9bV44cIFa+jQoVZxcbE1ZcoUa8GCBU5HajeLFy+2Jk+e3K7b5MiLjS5evKiKigplZGT4lwUFBSkjI0Pl5eUOJkNnU19fL0mKiIhwOEnXwj5+ua76WszNzdX06dMDXgtdxcsvv6zU1FTNmjVLkZGRGj16tJ555hlbt0l5sdEnn3yi5uZmRUVFBSyPiory/84T8HX5fD4tXLhQkyZNUlJSktNxuhT28UBd9bW4adMmHTp0yP8bfV3Nn/70J61evVpDhw7Vzp07NX/+fN1///3asGGDbdu09beNANgvNzdXR44c0Z49e5yOgi6uK74Wa2pqtGDBAhUXFyskJMTpOI7w+XxKTU3VsmXLJEmjR4/WkSNHVFhYqOzsbFu2yZEXG/Xt21fdunVTXV1dwPK6ujpFR0c7lAqdSV5enl599VW9/fbbGjBggNNxuhz28T/rqq/FiooKnTlzRmPGjFFwcLCCg4O1e/du/fu//7uCg4PV3NzsdETbxcTEXPbjycOHD1d1dbVt26S82Kh79+4aO3asSkpK/Mt8Pp9KSkqUlpbmYDKYzrIs5eXlaevWrdq1a5fi4+OdjtQlsY/zWrzpppt0+PBhVVZW+qfU1FTdddddqqysVLdu3ZyOaLtJkyZddnn8e++9p0GDBtm2TT42sll+fr6ys7OVmpqq8ePHa/ny5WpqalJOTo7T0TqcxsZGVVVV+edPnDihyspKRUREaODAgQ4m63hyc3O1ceNGbd++XaGhof7zK8LDw9WjRw+H03UtXX0f7+qvxdDQ0MvO77n++uvVp0+fLnPez6JFizRx4kQtW7ZM//iP/6j9+/dr7dq1Wrt2rX0bbddrm7qolStXWgMHDrS6d+9ujR8/3tq3b5/TkTqkt99+25J02ZSdne10tA6npedJkrV+/Xqno3VJXXkf57V4ua52qbRlWdYrr7xiJSUlWW6320pISLDWrl1r6/ZclmVZ9lUjAACAtsU5LwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLAAAwyv8DgGQuTYEdmXYAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_pad(x, 2)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[0,2,:,0] =\\n\", x[0,2,:,0])\n",
        "print (\"x_pad[0,2,:,0] =\\n\", x_pad[0,2,:,0])\n",
        "\n",
        "fig, axarr = plt.subplots(1, 2)\n",
        "axarr[0].set_title('x')\n",
        "axarr[0].imshow(x[0,:,:,0])\n",
        "axarr[1].set_title('x_pad')\n",
        "axarr[1].imshow(x_pad[0,:,:,0])\n",
        "\n",
        "np.random.seed(seed)\n",
        "x = np.random.randn(4, 2, 2, 2)\n",
        "x_pad = zero_pad(x, 1)\n",
        "output[\"zero_padding\"] = x_pad[0,1,:,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snXOn3sETwDb"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>x.shape: </td>\n",
        "    <td>(4, 3, 3, 2)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>x_pad.shape: </td>\n",
        "    <td>(4, 7, 7, 2)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>x[0,0,:,0]: </td>\n",
        "    <td>[-0.3224172   1.13376944 -0.17242821]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>x_pad[0,2,:,0]: </td>\n",
        "    <td>[ 0. 0. 1.62434536 -0.52817175 0.86540763 0. 0.]\n",
        "</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPVifontJlWr"
      },
      "source": [
        "## 3.3 Convolution_single_step\n",
        "In this part, you will implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit.\n",
        "\n",
        "We will convolve an f*f filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias.\n",
        "\n",
        "**Exercise**: Implement conv_single_step( ). (5%)\n",
        "\n",
        "This function takes the following inputs:\n",
        "*   a_slice_prev: the output of the activation by the previous layer.\n",
        "*   W: the filter with size f*f.\n",
        "*   b: the bias.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "02WmPxJKJbJa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Z = -6.999089450680221\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "a_slice_prev = np.random.randn(4, 4, 3)\n",
        "W = np.random.randn(4, 4, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "\n",
        "conv = Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
        "Z = conv.conv_single_step(a_slice_prev, W, b)\n",
        "print(\"Z =\", Z)\n",
        "\n",
        "np.random.seed(seed)\n",
        "a_slice_prev = np.random.randn(3, 3, 3)\n",
        "W = np.random.randn(3, 3, 3)\n",
        "b = np.random.randn(1, 1, 1)\n",
        "conv = Conv()\n",
        "Z = conv.conv_single_step(a_slice_prev, W, b)\n",
        "output[\"conv_single_step\"] = Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVHY5VIFVLiC"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>Z: </td>\n",
        "    <td>[[[-6.99908945]]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "764-uaZwLGNL"
      },
      "source": [
        "## 3.4 Forward pass\n",
        "In the forward pass, you will take many filters and convolve them through the input. Each 'convolution' gives you a 2D matrix output. You will then stack these outputs to get a 3D volume.\n",
        "\n",
        "Notice that the output shape of the convolution forward will be (H, W, C).\n",
        "* $H= \\lfloor\\frac{H_{prev }-f+2*pad}{stride}\\rfloor+1$\n",
        "* $W= \\lfloor\\frac{W_{prev }-f+2*pad}{stride}\\rfloor+1$\n",
        "* $C = $ number of filters\n",
        "\n",
        "f = filter_size\n",
        "\n",
        "**Exercise**: Implement forward( ) to convolve the filters W on an input activation A_prev. (15%)\n",
        "\n",
        "This function takes the following input:\n",
        "*   A_prev: the output of the activation by the previous layer, it's an array with shape (m, H_prev, W_prev, C_prev).\n",
        "    *  m: number of examples.\n",
        "    *  H_prev, W_prev, C_prev: the height, width, and channel of the output of the previous layer.\n",
        "\n",
        "Here are some steps for you to finish this exercise:\n",
        "1. Define **a_slice_prev**, which represent the input slice of conv_single_step( ).\n",
        "2. To define **a_slice_prev**, you have to define its' corners: **vert_start, vert_end, horiz_start and horiz_end**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Ags0LKKRQvH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Z's mean = 0.0031904169881830785\n",
            "Z[3,2,1] = [ 1.32947002  2.12083471  0.37853495 -3.53602735  1.38816885 -1.01503137\n",
            " -1.01667531  0.86993377]\n",
            "cache_conv[1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed) \n",
        "A_prev = np.random.randn(10,4,4,3)\n",
        "conv=Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
        "Z = conv.forward(A_prev)\n",
        "\n",
        "print(\"Z's mean =\", np.mean(Z))\n",
        "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
        "print(\"cache_conv[1][2][3] =\", conv.cache[1][2][3])\n",
        "\n",
        "\n",
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(10,3,3,3)\n",
        "conv=Conv(filter_size=3, input_channel=3, output_channel=16, pad=1, stride=1)\n",
        "Z = conv.forward(A_prev)\n",
        "\n",
        "output[\"conv_forward_1\"] = np.mean(Z)\n",
        "output[\"conv_forward_2\"] = Z[3,2,1]\n",
        "output[\"conv_forward_3\"] = conv.cache[1][2][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qiBeJbhVTlU"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>Z's mean: </td>\n",
        "    <td>0.0031904169881830785</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Z[3,2,1]: </td>\n",
        "    <td>[ 1.32947002  2.12083471  0.37853495 -3.53602735  1.38816885 -1.01503137\n",
        " -1.01667531  0.86993377]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>cache_conv[1][2][3]: </td>\n",
        "    <td>[-0.20075807  0.18656139  0.41005165]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbGLz2F_ReRr"
      },
      "source": [
        "## 3.5 Update parameters\n",
        "In this section you will update the parameters of the convolution layer, using gradient descent:\n",
        "\n",
        "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} $$\n",
        "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} $$\n",
        "\n",
        "**Exercise**: Implement update( ) to update your parameters using gradient descent. (1%)\n",
        "\n",
        "**Instructions**: \n",
        "*   Update parameters using gradient descent on $W^{[l]}$ and $b^{[l]}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QOw8N6q7RgGU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W[0][0][0] =  [-1.74691199  0.93719726 -0.21020825  0.78099448 -1.38718376  1.69938289\n",
            " -2.20823614  0.53308498]\n",
            "b =  [[[[ 0.34385368 -0.04359686  0.62000084 -0.69803203  0.44712856\n",
            "    -1.2245077  -0.40349164 -0.59357852]]]]\n"
          ]
        }
      ],
      "source": [
        "conv=Conv(filter_size=2, input_channel=3, output_channel=8, pad=2, stride=2)\n",
        "np.random.seed(seed)\n",
        "conv.dW = np.random.randn(2, 2, 3, 8)\n",
        "conv.db = np.random.randn(1, 1, 1, 8)\n",
        "conv.update(1.0)\n",
        "print(\"W[0][0][0] = \", conv.parameters[\"W\"][0][0][0])\n",
        "print(\"b = \", conv.parameters[\"b\"])\n",
        "\n",
        "conv=Conv(filter_size=3, input_channel=3, output_channel=8, pad=1, stride=2)\n",
        "np.random.seed(seed)\n",
        "conv.dW = np.random.randn(3, 3, 3, 8)\n",
        "conv.db = np.random.randn(1, 1, 1, 8)\n",
        "conv.update(0.1)\n",
        "output[\"conv_update_1\"] = conv.parameters[\"W\"][0][0][0]\n",
        "output[\"conv_update_2\"] = conv.parameters[\"b\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WBrdsS9RsTA"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>W[0][0][0]: </td>\n",
        "    <td>[-1.74691199  0.93719726 -0.21020825  0.78099448 -1.38718376  1.69938289 -2.20823614  0.53308498]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>b: </td>\n",
        "    <td>[[[[ 0.34385368 -0.04359686  0.62000084 -0.69803203  0.44712856\n",
        "    -1.2245077  -0.40349164 -0.59357852]]]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goYhkmioRQvI"
      },
      "source": [
        "# 4. Maxpooling layer\n",
        "\n",
        "The pooling layer reduces the size (height and width) of the input. It helps reduce computation, as well as helps make feature detectors more invariant to their position in the input. In this section, we will focus on maxpooling layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z8j9VErNRQvI"
      },
      "outputs": [],
      "source": [
        "class MaxPool():\n",
        "    def __init__(self, filter_size=2, stride=2):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        self.parameters -- python dictionary containing your parameters:\n",
        "                           f -- size of a filter\n",
        "                           stride -- the amount of movement that a filter move in one step\n",
        "        \"\"\"\n",
        "    \n",
        "        self.parameters = {\"f\": filter_size, \"stride\": stride}\n",
        "        self.name=\"maxpool\"\n",
        "        \n",
        "        \n",
        "    def forward(self, A_prev):\n",
        "        \"\"\"\n",
        "        Implements the forward pass of the max pooling layer\n",
        "\n",
        "        Arguments:\n",
        "        A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "\n",
        "        Returns:\n",
        "        A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
        "        \"\"\"\n",
        "\n",
        "        # GRADED FUNCTION: maxpool_forward\n",
        "        ### START CODE HERE ###\n",
        "        # Retrieve dimensions from the input shape. (≈1 line)\n",
        "        (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "\n",
        "        # Define the dimensions of the output. (≈3 lines)\n",
        "        n_H = int((n_H_prev - self.parameters[\"f\"]) / self.parameters[\"stride\"]) + 1\n",
        "        n_W = int((n_W_prev - self.parameters[\"f\"]) / self.parameters[\"stride\"]) + 1\n",
        "        n_C = n_C_prev\n",
        "\n",
        "        # Initialize output matrix A with zeros. (≈1 line)\n",
        "        A =  A = np.zeros((m, n_H, n_W, n_C))            \n",
        "\n",
        "        for i in range(m):                         # loop over the training examples\n",
        "            for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
        "                for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
        "                    for c in range (n_C):            # loop over the channels of the output volume\n",
        "\n",
        "                        # Find the corners of the current \"slice\". (≈4 lines)\n",
        "                        vert_start = h * self.parameters[\"stride\"]\n",
        "                        vert_end = vert_start + self.parameters[\"f\"]\n",
        "                        horiz_start = w * self.parameters[\"stride\"]\n",
        "                        horiz_end = horiz_start + self.parameters[\"f\"] \n",
        "\n",
        "                        # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
        "                        a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "\n",
        "                        # Compute the max pooling operation on a_prev_slice. (≈1 line)\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Store the input in \"cache\" for backward pass\n",
        "        self.cache = A_prev\n",
        "\n",
        "        # Making sure your output shape is correct\n",
        "        assert(A.shape == (m, n_H, n_W, n_C))\n",
        "\n",
        "        return A\n",
        "    \n",
        "    def create_mask_from_window(self, x):\n",
        "        \"\"\"\n",
        "        Creates a mask from an input x to identify the max entry of x.\n",
        "\n",
        "        Arguments:\n",
        "        x -- Array of shape (filter_size, filter_size)\n",
        "\n",
        "        Returns:\n",
        "        mask -- Array of the same shape as filter, contains a True at the position corresponding to the max entry of x.\n",
        "        \"\"\"\n",
        "\n",
        "        mask = x == np.max(x)\n",
        "\n",
        "        return mask\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        Implements the backward pass of the max pooling layer\n",
        "\n",
        "        Arguments:\n",
        "        dA -- gradient of cost with respect to the output of the pooling layer, same shape as A \n",
        "\n",
        "        Returns:\n",
        "        dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev\n",
        "        \"\"\"\n",
        "\n",
        "        # Retrieve information from cache\n",
        "        A_prev = self.cache\n",
        "\n",
        "        # Retrieve dimensions from A_prev's shape and dA's shape\n",
        "        m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "        m, n_H, n_W, n_C = dA.shape\n",
        "\n",
        "        # Initialize dA_prev with zeros\n",
        "        dA_prev = np.zeros(A_prev.shape)\n",
        "\n",
        "        for i in range(m):  # loop over the training examples\n",
        "            # select training example from A_prev                    \n",
        "            a_prev = A_prev[i]\n",
        "            for h in range(n_H):   # loop on the vertical axis            \n",
        "                for w in range(n_W):  # loop on the horizontal axis             \n",
        "                    for c in range(n_C): # loop over the channels\n",
        "\n",
        "                        # Find the corners of the current \"slice\"          \n",
        "                        vert_start = h * self.parameters[\"stride\"]\n",
        "                        vert_end = vert_start + self.parameters[\"f\"]\n",
        "                        horiz_start = w * self.parameters[\"stride\"]\n",
        "                        horiz_end = horiz_start + self.parameters[\"f\"] \n",
        "\n",
        "                        #Use the corners and \"c\" to define the current slice from a_prev\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        # Create the mask from a_prev_slice\n",
        "                        mask = self.create_mask_from_window(a_prev_slice)\n",
        "                        # Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA)\n",
        "                        dA_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += np.multiply(mask, dA[i, h, w, c])\n",
        "\n",
        "\n",
        "\n",
        "        # Make sure your output shape is correct\n",
        "        assert(dA_prev.shape == A_prev.shape)\n",
        "\n",
        "        return dA_prev\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXSF-PhOxauK"
      },
      "source": [
        "## 4.1 Forward pass\n",
        "\n",
        "It will take following parameters to initialize a max pooling layer:\n",
        "*   filter_size: the filter will be in the shape of (filter_size*filter_size)\n",
        "*   stride: the amount of movement that a filter move in one step\n",
        "\n",
        "In the forward pass, you will slide a ( f*f ) filter over the input and store the max value of the window in the output. (f means the filter size)\n",
        "\n",
        "Notice that the output shape of the forward pass will be (H, W, C).\n",
        "* $H= \\lfloor\\frac{H_{prev }-f}{stride}\\rfloor+1$\n",
        "* $W= \\lfloor\\frac{W_{prev }-f}{stride}\\rfloor+1$\n",
        "* $C = C_{prev}$\n",
        "\n",
        "**Exercise**: Create a max pooling layer and implement the forward pass of the pooling layer. (15%)\n",
        "\n",
        "This forward function takes the following input:\n",
        "*   A_prev: the output of the previous layer, it's an array with shape (m, H_prev, W_prev, C_prev).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BpL0HQvQRQvJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A = [[[[1.74481176 0.86540763 1.13376944]]]\n",
            "\n",
            "\n",
            " [[[1.13162939 1.51981682 2.18557541]]]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(2, 4, 4, 3)\n",
        "maxpool=MaxPool(filter_size=3, stride=2)\n",
        "A = maxpool.forward(A_prev)\n",
        "print(\"A =\", A)\n",
        "\n",
        "A_prev = np.random.randn(2, 5, 5, 3)\n",
        "maxpool=MaxPool(filter_size=2, stride=1)\n",
        "A = maxpool.forward(A_prev)\n",
        "output[\"maxpool_forward\"] = A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcEzFinVYHP"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>A: </td>\n",
        "    <td>[[[[1.74481176 0.86540763 1.13376944]]] [[[1.13162939 1.51981682 2.18557541]]]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn-VBGGURQvJ"
      },
      "source": [
        "# 5. Flatten layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJN7EvSuaKGW"
      },
      "source": [
        "To connect the convolution layer and the dense layer, you should flatten the output of the convolution layer or max pooling layer before dense layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2-F3jskjRQvK"
      },
      "outputs": [],
      "source": [
        "class Flatten():\n",
        "    def __init__(self):\n",
        "        self.name=\"flatten\"\n",
        "\n",
        "    def forward(self, A_prev):\n",
        "        \"\"\"\n",
        "        Implements the forward pass of the flatten layer\n",
        "\n",
        "        Arguments:\n",
        "        A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "\n",
        "        Returns:\n",
        "        A -- output of the flatten layer, a 1-dimensional array\n",
        "        \"\"\"\n",
        "\n",
        "        # Save information in \"cache\" for the backward pass\n",
        "        self.cache = A_prev.shape\n",
        "\n",
        "        # GRADED FUNCTION: flatten_forward\n",
        "        ### START CODE HERE ### (≈1 line)\n",
        "        A = A_prev.reshape(A_prev.shape[0], A_prev.shape[1]*A_prev.shape[2]*A_prev.shape[3])\n",
        "        ### END CODE HERE ###\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        Implements the backward pass of the flatten layer\n",
        "\n",
        "        Arguments:\n",
        "        dA -- Input data, a 1-dimensional array\n",
        "\n",
        "        Returns:\n",
        "        dA_prev -- An array with its original shape (the output shape of its' previous layer).\n",
        "        \"\"\"\n",
        "        # GRADED FUNCTION: flatten_backward\n",
        "        ### START CODE HERE ### (≈1 line)\n",
        "        dA_prev = dA.reshape(self.cache)\n",
        "        ### END CODE HERE ###\n",
        "        return dA_prev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Haf0l4nau3y"
      },
      "source": [
        "## 5.1 Forward pass\n",
        "\n",
        "**Exercise**: Implement the forward pass of flatten layer. Turn the input array into a 1-dimensional array. (5%)\n",
        "\n",
        "This function takes the following input:\n",
        "*   A_prev: Input data, it's an array with shape (m, n_H_prev, n_W_prev, n_C_prev).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TF96C0Fyat_4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A.shape = (2, 8)\n",
            "A[0] = [ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
            "  1.74481176 -0.7612069 ]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(2,2,2,2)\n",
        "flatten = Flatten()\n",
        "A = flatten.forward(A_prev)\n",
        "print(\"A.shape =\", A.shape)\n",
        "print(\"A[0] =\", A[0])\n",
        "\n",
        "\n",
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(2,3,3,2)\n",
        "flatten = Flatten()\n",
        "A = flatten.forward(A_prev)\n",
        "output[\"flatten_forward\"] = A[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq3qbOjiVhjj"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>A.shape: </td>\n",
        "    <td>(2, 8)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>A[0]: </td>\n",
        "    <td>[ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763 -2.3015387\n",
        "  1.74481176 -0.7612069 ]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdWPIB6_a8_n"
      },
      "source": [
        "## 5.2  Backward pass\n",
        "\n",
        "**Exercise**: Implement the backward pass of flatten layer. Turn the input array back to its original shape.(the output shape of its' previous layer). (5%)\n",
        "\n",
        "This function takes the following input:\n",
        "*   dA: the output of backward pass from the next layer, it's a 1-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dY8vpJPLauWd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B.shape = (2, 2, 2, 2)\n",
            "B[0] = [[[ 1.62434536 -0.61175641]\n",
            "  [-0.52817175 -1.07296862]]\n",
            "\n",
            " [[ 0.86540763 -2.3015387 ]\n",
            "  [ 1.74481176 -0.7612069 ]]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(2,2,2,2)\n",
        "flatten = Flatten()\n",
        "A = flatten.forward(A_prev)\n",
        "B = flatten.backward(A)\n",
        "print(\"B.shape =\", B.shape)\n",
        "print(\"B[0] =\", B[0])\n",
        "\n",
        "# B and A_prev should be same\n",
        "assert((B==A_prev).all())\n",
        "\n",
        "np.random.seed(seed)\n",
        "A_prev = np.random.randn(4,3,3,3)\n",
        "flatten = Flatten()\n",
        "A = flatten.forward(A_prev)\n",
        "B = flatten.backward(A)\n",
        "output[\"flatten_backward\"] = B[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3khMiPehVjIV"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>B.shape: </td>\n",
        "    <td>(2, 2, 2, 2)</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>B[0]: </td>\n",
        "    <td>[[[ 1.62434536 -0.61175641]\n",
        "  [-0.52817175 -1.07296862]]\n",
        "  [[ 0.86540763 -2.3015387 ]\n",
        "  [ 1.74481176 -0.7612069 ]]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYqpQu6Eye7h"
      },
      "source": [
        "# 6. Model\n",
        "Alright, now you have all the tools that are needed to build a convolutional neural network. Let's get started! Use the knowledge you learned from assignment 4 to finish this part. But there is some difference:\n",
        "\n",
        "1. In this part, we will call model.add( ) to add a layer into the model. For example:\n",
        "* model.add(Conv( )): add a convolution layer into the model.\n",
        "* model.add(Dense( )): add a dense layer into the model.\n",
        "* model.add(Activation( )): add an activation layer into the model.\n",
        "\n",
        "2. Because the dense layer you implement in assignment3 takes the input shape as [:, m], where m represents the number of examples. However, when the training data go through the convolution layer and maxpool layer, its shape will be [m,:]. As a consequence, in the forward pass, the output of flatten.forward( ) need to be transposed. Similarly, in the backward pass, before the data goes into flatten.backward( ), it needs to be transposed again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7dWrCCkPRQvK"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "    def __init__(self):       \n",
        "        self.layers=[]\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        A = X\n",
        "        # GRADED FUNCTION: model\n",
        "        ### START CODE HERE ### (≈ 5 lines)\n",
        "        for l in range(len(self.layers)):\n",
        "            if(self.layers[l].name==\"flatten\"):\n",
        "                A = self.layers[l].forward(A).T # Transpose after flatten layer\n",
        "            else:\n",
        "                A = self.layers[l].forward(A)\n",
        "        ### END CODE HERE ###\n",
        "        return A\n",
        "\n",
        "    def backward(self, AL=None, Y=None):\n",
        "        L = len(self.layers)\n",
        "\n",
        "        # GRADED FUNCTION: model\n",
        "        ### START CODE HERE ### (≈ 7 lines)\n",
        "        if self.layers[-1].name == \"sigmoid\":\n",
        "            e = 1e-5\n",
        "            dAL = - ((np.divide(Y, AL+e)) - (np.divide(1-Y, 1-AL+e)))\n",
        "            dZ = self.layers[-1].backward(dA=dAL)  #activation layer backward\n",
        "            dA_prev = self.layers[-2].backward(dZ) #linear layer backward\n",
        "        else:\n",
        "            dZ = self.layers[-1].backward(Y=Y)\n",
        "            dA_prev = self.layers[-2].backward(dZ)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        \n",
        "        # Loop from l=L-3 to l=0\n",
        "        # GRADED FUNCTION: model\n",
        "        ### START CODE HERE ### (≈ 5 lines)\n",
        "        for l in reversed(range(L-2)):\n",
        "            if(self.layers[l].name==\"flatten\"):\n",
        "                dA_prev=self.layers[l].backward(dA_prev.T) # Transpose before goes into flatten layer\n",
        "            else:\n",
        "                dA_prev = self.layers[l].backward(dA_prev)\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return dA_prev\n",
        "\n",
        "    def update(self, learning_rate):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "        learning_rate -- step size\n",
        "        \"\"\"\n",
        "        \n",
        "        # GRADED FUNCTION: model\n",
        "        # Only convolution layer and dense layer have to update parameters\n",
        "        ### START CODE HERE ### (≈ 3 lines)\n",
        "        L = len(self.layers)\n",
        "        for i in range(L):\n",
        "            if(self.layers[i].name==\"conv\" or self.layers[i].name==\"dense\"):\n",
        "                self.layers[i].update(learning_rate)\n",
        "        ### END CODE HERE ###\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36my0zWnlv3K"
      },
      "source": [
        "## 6.1 Model forward, backward and update:\n",
        "**Exercise**: Here is an exercise to make sure your model works correctly. (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gN-8NQ_KRQvK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.36135339 -0.08462337 -0.00125603 -0.75846791 -0.10766644 -0.30566005\n",
            " -0.6160899   0.17289454]\n",
            "[[[[-0.17413437 -1.16136976  2.2091218   1.09197293  1.09878206\n",
            "    -0.99630691  2.22696487 -0.20973624]]]]\n",
            "[-2.14606176 -0.75085187 -1.19750975 -0.8916535  -0.91436404 -0.76753\n",
            " -1.30207298 -0.52670234]\n",
            "[[-0.47493517]]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(seed)\n",
        "A = np.random.randn(4,10,10,3)\n",
        "Y = np.array([[1,0,1,0]])\n",
        "\n",
        "model=Model()\n",
        "model.add(Conv(filter_size=3, input_channel=3, output_channel=8, pad=1, stride=2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool(filter_size=2, stride=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, 1))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "\n",
        "AL = model.forward(A)\n",
        "dA_prev = model.backward(AL=AL, Y=Y)\n",
        "model.update(0.01)\n",
        "\n",
        "print(model.layers[0].dW[0,0,0])\n",
        "print(model.layers[0].db)\n",
        "print(model.layers[4].dW[0,:8])\n",
        "print(model.layers[4].db)\n",
        "\n",
        "\n",
        "np.random.seed(seed)\n",
        "A = np.random.randn(4,8,8,3)\n",
        "Y = np.array([[1,1,0,0]])\n",
        "\n",
        "model=Model()\n",
        "model.add(Conv(filter_size=3, input_channel=3, output_channel=16, pad=1, stride=2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool(filter_size=2, stride=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, 1))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "\n",
        "AL = model.forward(A)\n",
        "dA_prev = model.backward(AL=AL, Y=Y)\n",
        "model.update(0.001)\n",
        "\n",
        "output[\"model_1\"] = model.layers[0].dW[0,0,0]\n",
        "output[\"model_2\"] = model.layers[0].db\n",
        "output[\"model_3\"] = model.layers[4].dW[0,:8]\n",
        "output[\"model_4\"] = model.layers[4].db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGTtpnWcVvce"
      },
      "source": [
        "Expected output: \n",
        "<table>\n",
        "  <tr>\n",
        "    <td>model.layers[0].dW[0,0,0]: </td>\n",
        "    <td>[ 0.36135339 -0.08462337 -0.00125603 -0.75846791 -0.10766644 -0.30566005\n",
        " -0.6160899   0.17289454]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>model.layers[0].db: </td>\n",
        "    <td>[[[[-0.17413437 -1.16136976  2.2091218   1.09197293  1.09878206\n",
        "    -0.99630691  2.22696487 -0.20973624]]]]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>model.layers[4].dW[0,:8]: </td>\n",
        "    <td>[-2.14606176 -0.75085187 -1.19750975 -0.8916535  -0.91436404 -0.76753\n",
        " -1.30207298 -0.52670234]</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>model.layers[4].db: </td>\n",
        "    <td>[[-0.47493517]]</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EC0qy26RQvN"
      },
      "source": [
        "# 7. Binary classification\n",
        "\n",
        "Congratulations on implementing all the functions by yourself. You have done an incredible job! 👏\n",
        "\n",
        "Now you have all the tools you need to get started with classification. In this section, you will build a binary classifier using the functions you had previously written. You will create a model that can determine whether a CXR image is normal or not. There will be 600 training images and 60 testing images, and the size of all images are 32 * 32 * 1.\n",
        "\n",
        "\n",
        "**Exercise**: Implement a binary classifier and tune the hyperparameter. You will get all 10% if your prediction achieves accuracy greater than 0.55 in testing data. (10%)\n",
        "\n",
        "**Instruction**:\n",
        "*   You can only use the functions you had previously written.\n",
        "*   Preprocess the data by using min-max scaling to normalize X. Normalize the values of each feature between 0 and 1.\n",
        "*   Use batch gradient descent to train the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2X2fb7aoJTg"
      },
      "source": [
        "## 7.1 Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QWHxt5cDZ9mg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(600, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "PATH = \"Training_data\"  #path to your training image\n",
        "file_dir = os.listdir(PATH) #read the images from the directory\n",
        "file_dir.sort() #Make sure the images are loaded in order\n",
        "X_train = np.array([])\n",
        "\n",
        "# Prepare X_train\n",
        "# The shape of X_train will be (number of examples, height of image, width of image, channel of image)\n",
        "# GRADED CODE: Binary classification (Data preprocessing)\n",
        "# hint: use imread(PATH, IMREAD_GRAYSCALE) to load image\n",
        "### START CODE HERE ### (≈ 9 line)\n",
        "#print(file_dir)\n",
        "for i in range(len(file_dir)):\n",
        "    if (i != 0):\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[i], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_train = np.concatenate([X_train, img_gray], axis=0)\n",
        "    else:\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[0], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_train = img_gray\n",
        "\n",
        "X_train = np.divide(X_train, 255)\n",
        "print(X_train.shape)\n",
        "### END CODE HERE ###\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "I527tbN2_Obg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "PATH = \"Testing_data\"  #path to your testing image\n",
        "file_dir = os.listdir(PATH)\n",
        "file_dir.sort()\n",
        "X_test = np.array([])\n",
        "\n",
        "# Prepare X_test\n",
        "# The shape of X_teset will be (number of examples, height of image, width of image, channel of image)\n",
        "# GRADED CODE: Binary classification (Data preprocessing)\n",
        "### START CODE HERE ### (≈ 9 line)\n",
        "for i in range(0, len(file_dir)):\n",
        "    if (i != 0):\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[i], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_test = np.concatenate([X_test, img_gray], axis=0)\n",
        "    else:\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[1], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_test = img_gray\n",
        "\n",
        "X_test = np.divide(X_test, 255)\n",
        "print(X_test.shape)\n",
        "\n",
        "### END CODE HERE ###\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bxaslew_lkKY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(600, 1)\n"
          ]
        }
      ],
      "source": [
        "data = read_csv(\"Training_label.csv\")\n",
        "\n",
        "y_train = []\n",
        "# Prepare y_train\n",
        "# The shape of y_train will be (number of examples, 1), we will transpose y_train latter.\n",
        "# GRADED CODE: Binary classification (Data preprocessing)\n",
        "### START CODE HERE ### (≈ 2 line)\n",
        "data = data.values\n",
        "y_train = data[:, 1].reshape(data[:, 1].shape[0], 1)\n",
        "print(y_train.shape)\n",
        "### END CODE HERE ###\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iwhza4gUboQ6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 32, 32, 1) (120, 32, 32, 1) (480, 1) (120, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#You can split training and validation set here. (Optional)\n",
        "### START CODE HERE ###\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state = 42)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wKkOpp6uyCQY"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: X=(480, 32, 32, 1), y=(1, 480)\n",
            "Test: X=(60, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train.T #transpose y_train\n",
        "y_val = y_val.T\n",
        "\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "    # define subplot\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(X_train[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "# show the figure\n",
        "plt.show()\n",
        "# check the shape of training data and testing data\n",
        "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
        "print('Test: X=%s' % (X_test.shape, ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdK9_gnZAjYD"
      },
      "source": [
        "## 7.2 mini-batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LVTeqK9TqMwP"
      },
      "outputs": [],
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape !!!!!!!!!!!(number of examples ,input size)!!!!!!!!!!!\n",
        "    Y -- true \"label\" vector, of shape (number of classes, number of examples)\n",
        "    mini_batch_size -- size of the mini-batches, integer\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[0]  # number of training examples\n",
        "    mini_batches = []\n",
        "\n",
        "    # GRADED CODE: Binary classification\n",
        "    ### START CODE HERE ###\n",
        "        \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[permutation, :, :, :]\n",
        "    shuffled_Y = Y[:, permutation]\n",
        "    \n",
        "    inc = mini_batch_size\n",
        "\n",
        "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
        "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
        "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        # (approx. 2 lines)\n",
        "        mini_batch_X = shuffled_X[k*inc: (k+1)*inc, :, :, :]\n",
        "        mini_batch_Y = shuffled_Y[:, k*inc: (k+1)*inc]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
        "    if m % mini_batch_size != 0:\n",
        "        #(approx. 2 lines)\n",
        "        mini_batch_X = shuffled_X[(k+1)*mini_batch_size:, :, :, :]\n",
        "        mini_batch_Y = shuffled_Y[:, (k+1)*mini_batch_size:]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    \n",
        "    return mini_batches\n",
        "\n",
        "    ### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def learning_rate_optimizer(iter, lr_p, mode = \"expo\", k = None, t = None, r = None, div = None):\n",
        "    lr_list = []\n",
        "    for i in range(iter):\n",
        "        if div > 0 and i <= div:\n",
        "            lr_list += [i * (lr_p / div)]\n",
        "        else:   \n",
        "            if mode == \"expo\":\n",
        "                lr_list += [lr_p * np.exp(-k * (i-div))]\n",
        "            elif mode == \"step\":\n",
        "                lr_list += [lr_p * (r ** np.floor((i-div)/t))]\n",
        "    return lr_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FIrnqYMFGRq"
      },
      "source": [
        "## 7.3 Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1CBktduDyKd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:  0\n",
            "Accuracy: 0.5041666666666667\n",
            "Accuracy: 0.5583333333333333\n",
            "Cost after iteration 0: 0.682883\n",
            "epoch:  1\n",
            "Accuracy: 0.5937499999999999\n",
            "Accuracy: 0.6416666666666666\n",
            "Cost after iteration 1: 0.690105\n",
            "epoch:  2\n",
            "Accuracy: 0.6291666666666667\n",
            "Accuracy: 0.6166666666666666\n",
            "Cost after iteration 2: 0.679694\n",
            "epoch:  3\n",
            "Accuracy: 0.59375\n",
            "Accuracy: 0.5666666666666667\n",
            "Cost after iteration 3: 0.686504\n",
            "epoch:  4\n",
            "Accuracy: 0.675\n",
            "Accuracy: 0.7\n",
            "Cost after iteration 4: 0.707454\n",
            "epoch:  5\n",
            "Accuracy: 0.6520833333333333\n",
            "Accuracy: 0.6333333333333333\n",
            "Cost after iteration 5: 0.677656\n",
            "epoch:  6\n",
            "Accuracy: 0.6666666666666666\n",
            "Accuracy: 0.6583333333333333\n",
            "Cost after iteration 6: 0.671078\n",
            "epoch:  7\n",
            "Accuracy: 0.7\n",
            "Accuracy: 0.7083333333333333\n",
            "Cost after iteration 7: 0.666853\n",
            "epoch:  8\n",
            "Accuracy: 0.5541666666666667\n",
            "Accuracy: 0.5166666666666666\n",
            "Cost after iteration 8: 0.669656\n",
            "epoch:  9\n",
            "Accuracy: 0.6708333333333333\n",
            "Accuracy: 0.6916666666666667\n",
            "Cost after iteration 9: 0.633777\n",
            "epoch:  10\n",
            "Accuracy: 0.6395833333333333\n",
            "Accuracy: 0.5916666666666666\n",
            "Cost after iteration 10: 0.631822\n",
            "epoch:  11\n",
            "Accuracy: 0.7104166666666666\n",
            "Accuracy: 0.6499999999999999\n",
            "Cost after iteration 11: 0.625613\n",
            "epoch:  12\n",
            "Accuracy: 0.5229166666666667\n",
            "Accuracy: 0.425\n",
            "Cost after iteration 12: 0.688190\n",
            "epoch:  13\n",
            "Accuracy: 0.7229166666666667\n",
            "Accuracy: 0.7416666666666667\n",
            "Cost after iteration 13: 0.617782\n",
            "epoch:  14\n",
            "Accuracy: 0.6104166666666666\n",
            "Accuracy: 0.675\n",
            "Cost after iteration 14: 0.649589\n",
            "epoch:  15\n",
            "Accuracy: 0.7354166666666666\n",
            "Accuracy: 0.6833333333333333\n",
            "Cost after iteration 15: 0.645291\n",
            "epoch:  16\n",
            "Accuracy: 0.7458333333333333\n",
            "Accuracy: 0.675\n",
            "Cost after iteration 16: 0.576713\n",
            "epoch:  17\n",
            "Accuracy: 0.6895833333333332\n",
            "Accuracy: 0.7083333333333333\n",
            "Cost after iteration 17: 0.643018\n",
            "epoch:  18\n",
            "Accuracy: 0.49375\n",
            "Accuracy: 0.6\n",
            "Cost after iteration 18: 0.618893\n",
            "epoch:  19\n",
            "Accuracy: 0.7375\n",
            "Accuracy: 0.75\n",
            "Cost after iteration 19: 0.653298\n",
            "epoch:  20\n",
            "Accuracy: 0.6437499999999999\n",
            "Accuracy: 0.6\n",
            "Cost after iteration 20: 0.626098\n",
            "epoch:  21\n",
            "Accuracy: 0.6479166666666667\n",
            "Accuracy: 0.6833333333333333\n",
            "Cost after iteration 21: 0.589387\n",
            "epoch:  22\n",
            "Accuracy: 0.7291666666666666\n",
            "Accuracy: 0.7833333333333332\n",
            "Cost after iteration 22: 0.680662\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# GRADED CODE: Binary classification\n",
        "### START CODE HERE ###\n",
        "num_iterations = 23\n",
        "batch_size = 100\n",
        "print_cost = True\n",
        "classes = 2\n",
        "costs = []   # keep track of cost\n",
        "learning_rate_peak = 0.8\n",
        "batches_len = int(np.ceil(X_train.shape[0] / batch_size))\n",
        "learning_rate = learning_rate_optimizer(num_iterations * batches_len, learning_rate_peak, mode=\"expo\", r = 0.8, t = 400, div = 1600)\n",
        "\n",
        "# build the model\n",
        "model=Model()\n",
        "model.add(Conv(filter_size=3, input_channel=1, output_channel=32, pad=1, stride=2))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPool(filter_size=2, stride=1))\n",
        "model.add(Conv(filter_size=2, input_channel=32, output_channel=32, pad=0, stride=2))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1568, 512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(512, 216))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(216, 64))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(64, 32))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(32, 1))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "time_start = time.time()\n",
        "# Loop (gradient descent)\n",
        "for i in range(0, num_iterations):\n",
        "    print(\"epoch: \",i)\n",
        "    mini_batches = random_mini_batches(X_train, y_train, batch_size)\n",
        "    j=0\n",
        "    for batch in mini_batches:\n",
        "        x_batch, y_batch = batch\n",
        "\n",
        "        # forward\n",
        "        AL = model.forward(x_batch)\n",
        "\n",
        "        # compute cost\n",
        "        if classes == 2:\n",
        "            cost = compute_BCE_cost(AL, y_batch)\n",
        "        else:\n",
        "            cost = compute_CCE_cost(AL, y_batch)\n",
        "\n",
        "        # backward\n",
        "        dA_prev = model.backward(AL, y_batch)\n",
        "\n",
        "        # update\n",
        "        model.update(learning_rate[i])\n",
        "    \n",
        "    pred_train = predict(X_train, y_train, model, 2)\n",
        "    pred_val = predict(X_val, y_val, model, 2)\n",
        "    \n",
        "    print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    costs.append(cost)\n",
        "time_end = time.time()\n",
        "### END CODE HERE ###\n",
        "            \n",
        "# plot the cost\n",
        "\n",
        "plt.plot(np.squeeze(costs))\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('iterations (per hundreds)')\n",
        "plt.title(\"training lost\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time cost 8247.641866445541 s\n",
            "Accuracy: 0.7291666666666666\n",
            "Accuracy: 0.7833333333333332\n"
          ]
        }
      ],
      "source": [
        "time_c= time_end - time_start   #執行所花時間\n",
        "print('time cost', time_c, 's')\n",
        "pred_train= predict(X_train, y_train, model, 2)\n",
        "pred_val= predict(X_val, y_val, model, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7291666666666666\n",
            "Accuracy: 0.7833333333333332\n"
          ]
        }
      ],
      "source": [
        "pred_train= predict(X_train, y_train, model, 2)\n",
        "pred_val= predict(X_val, y_val, model, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1hIZQOfGAPJJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([[1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
            "        0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.]]), 0.0) 2\n",
            "['conv', 'relu', 'maxpool', 'conv', 'relu', 'flatten', 'dense', 'relu', 'dense', 'relu', 'dense', 'relu', 'dense', 'relu', 'dense', 'sigmoid'] [{'pad': 1, 'stride': 2, 'W': array([[[[ 2.37931647e-02,  1.05509761e-01, -5.16317666e-01,\n",
            "          -1.57555405e-01, -3.60006926e-01, -3.38464617e-01,\n",
            "          -2.31576141e-01, -1.93496761e-01, -1.75578655e-01,\n",
            "           6.59029142e-02, -7.03599794e-02,  1.29322945e-01,\n",
            "          -2.51057314e-01,  4.21785322e-01, -4.05128483e-01,\n",
            "           1.49610059e-01, -5.12801978e-02,  3.81570808e-02,\n",
            "          -3.05215469e-01, -2.38522312e-01,  1.95954272e-01,\n",
            "           4.16023075e-01, -1.59112395e-01,  1.66413270e-01,\n",
            "           3.24423761e-01,  3.01314700e-01, -3.53875486e-01,\n",
            "          -4.41533114e-01, -2.81570067e-01,  2.44217201e-01,\n",
            "          -3.43637784e-01,  3.44101577e-02]],\n",
            "\n",
            "        [[ 4.38949875e-01, -4.10352084e-02,  1.28780720e-01,\n",
            "          -1.01855603e-01,  1.62569651e-01,  2.83889164e-01,\n",
            "          -3.74596261e-01,  1.69255069e-01,  3.64177955e-01,\n",
            "           2.33578005e-01, -1.15349995e-01,  2.34278932e-01,\n",
            "          -3.30240589e-01,  2.45191485e-02,  3.54620436e-01,\n",
            "          -1.76396067e-01, -1.67163173e-01, -3.10849059e-01,\n",
            "          -4.11089680e-01,  1.14988284e-01, -2.84038795e-01,\n",
            "          -1.87688092e-01, -7.23187272e-03, -3.38670746e-01,\n",
            "           5.71151844e-03, -3.17876644e-01,  7.61600178e-02,\n",
            "           1.17262272e-01, -3.39130841e-01, -1.28314945e-01,\n",
            "           1.50304400e-01, -1.94003550e-02]],\n",
            "\n",
            "        [[-3.82983680e-01,  1.43004310e-03,  1.14323880e-01,\n",
            "           2.58881013e-02,  3.44493101e-01,  7.60492815e-02,\n",
            "           3.51799208e-01, -3.05852012e-01, -3.81643014e-01,\n",
            "           3.03049466e-01, -2.16610454e-02, -3.80430499e-01,\n",
            "           3.72260099e-01, -1.33611807e-01,  2.21658780e-01,\n",
            "           2.03206017e-01,  3.24181854e-01,  1.21610760e-01,\n",
            "           2.10200593e-01, -1.93842751e-01, -2.17608925e-01,\n",
            "           3.59056380e-01, -6.19488857e-02,  4.13345943e-01,\n",
            "           7.37417157e-02,  7.76809209e-02, -3.28545738e-01,\n",
            "           3.70424772e-01, -4.27155785e-02, -3.10679794e-02,\n",
            "          -9.78029405e-02, -2.86060180e-01]]],\n",
            "\n",
            "\n",
            "       [[[ 4.14513914e-01, -3.37804451e-02, -4.64958505e-01,\n",
            "           1.41946188e-01, -1.88262153e-01,  3.13425808e-02,\n",
            "           3.47699450e-01, -1.57645115e-01,  3.05232699e-01,\n",
            "           1.00211502e-01, -3.71671015e-01,  3.78049174e-01,\n",
            "           1.53698946e-01,  5.01233078e-01, -2.80568468e-01,\n",
            "          -3.04414270e-01,  4.37187557e-01,  1.47890433e-01,\n",
            "          -3.66348680e-01,  2.32516809e-01,  2.08197231e-01,\n",
            "           3.52255423e-01,  1.80390959e-01, -3.04499863e-01,\n",
            "          -4.65315045e-01, -4.17215243e-01, -4.02339552e-01,\n",
            "          -2.86852971e-01,  3.07635215e-01, -4.04355330e-04,\n",
            "           3.03944879e-02,  3.28644179e-01]],\n",
            "\n",
            "        [[-2.87806785e-01, -2.58429364e-01,  8.42179209e-02,\n",
            "           4.91842948e-01,  6.56662419e-02, -4.11339108e-01,\n",
            "           2.80920062e-01, -2.40067771e-01,  2.55005895e-01,\n",
            "          -1.13339873e-01,  4.08769437e-01,  2.41020665e-01,\n",
            "           4.39495891e-02, -2.43384150e-01, -3.76595272e-01,\n",
            "          -3.33623588e-01, -3.29867937e-01, -3.43968293e-01,\n",
            "          -2.29088553e-01,  1.29579180e-01,  5.95767486e-02,\n",
            "          -4.35524760e-01, -3.65015798e-01,  4.56383802e-01,\n",
            "          -5.81667565e-02, -2.52871569e-01, -2.11231976e-01,\n",
            "           1.66304673e-01, -2.59543914e-01,  4.40944047e-02,\n",
            "           3.74854200e-01,  3.04564006e-01]],\n",
            "\n",
            "        [[-2.28294558e-01, -2.27745491e-02,  1.24072506e-01,\n",
            "           3.45420894e-01, -3.26562659e-01, -4.07655317e-01,\n",
            "          -3.67690096e-01,  2.44833119e-02,  7.52866266e-02,\n",
            "           6.57188777e-02, -6.50509759e-02,  3.60278451e-01,\n",
            "           6.35847603e-02, -1.08135196e-01,  4.70777776e-02,\n",
            "           2.06996377e-01,  1.86666294e-01, -2.13622941e-01,\n",
            "          -3.60818705e-01, -2.04767439e-01,  1.37588741e-01,\n",
            "          -2.60791245e-01,  2.15238550e-01, -3.36747725e-01,\n",
            "          -3.04006449e-01,  2.60578733e-01, -2.61494851e-01,\n",
            "           1.34804654e-01,  2.11474822e-02,  2.74955909e-01,\n",
            "          -2.35051498e-01, -4.61224094e-01]]],\n",
            "\n",
            "\n",
            "       [[[ 2.67924839e-01,  1.22571446e-01,  3.29956976e-01,\n",
            "           3.97036655e-01, -4.37469546e-01, -2.17355209e-01,\n",
            "           1.53290509e-01,  3.83015403e-01,  3.30266213e-01,\n",
            "           3.89761094e-03,  4.05681043e-01,  1.53222150e-01,\n",
            "          -9.64974296e-02,  4.46382049e-02,  9.06485039e-02,\n",
            "           4.91401159e-02,  4.39708406e-01,  3.41322231e-01,\n",
            "          -6.87136046e-02,  4.18153236e-01, -3.01311921e-01,\n",
            "          -3.34788382e-01, -3.11205540e-01,  4.50220781e-02,\n",
            "          -4.67272201e-01,  3.71241239e-01,  2.78882099e-01,\n",
            "          -4.80435773e-01, -2.75819897e-01, -1.44016978e-01,\n",
            "          -3.24949724e-01,  2.47178019e-01]],\n",
            "\n",
            "        [[-8.70711554e-02,  3.08462695e-01,  1.01696292e-01,\n",
            "           4.19971436e-01,  3.15940714e-01,  3.39761061e-01,\n",
            "           1.10424934e-02,  5.84294977e-02,  2.40670319e-01,\n",
            "          -2.30718257e-01,  9.87634234e-02,  1.54614253e-01,\n",
            "          -4.12599063e-01,  1.33372286e-01, -6.16182067e-02,\n",
            "           2.44064112e-01, -8.77245387e-02,  3.20073543e-01,\n",
            "           8.18758532e-02, -3.08526464e-01,  2.40052417e-01,\n",
            "           6.79073558e-02, -3.80426995e-01,  1.84716500e-02,\n",
            "           4.52101093e-02,  3.51242117e-01, -4.26012270e-01,\n",
            "           3.91285223e-01, -1.05187592e-01,  4.07565245e-01,\n",
            "           6.52648772e-02,  2.47236902e-01]],\n",
            "\n",
            "        [[ 8.16900314e-02,  9.66077120e-02, -1.45947905e-01,\n",
            "           1.70835134e-01,  1.80378842e-01,  3.06338346e-01,\n",
            "           2.19215567e-01,  2.20569596e-01,  2.97584580e-01,\n",
            "          -1.68306784e-01,  2.40465384e-01, -2.83933770e-02,\n",
            "          -1.01227361e-01, -9.31247224e-02, -8.25561890e-02,\n",
            "          -1.67207701e-01,  1.58799243e-01, -8.40714255e-02,\n",
            "           4.25450211e-01,  6.37392508e-02, -2.41592534e-01,\n",
            "          -8.78039665e-02, -1.33777030e-01,  3.02790123e-01,\n",
            "           2.43708664e-01,  3.38812984e-01,  1.38639558e-01,\n",
            "          -1.50306118e-01, -2.11122300e-01,  2.43308251e-01,\n",
            "          -6.44892810e-03,  1.52413724e-01]]]]), 'b': array([[[[ 0.2099086 , -0.22595133,  0.11442467, -0.35927868,\n",
            "          -0.02466592,  0.12988446, -0.08357737, -0.05276835,\n",
            "          -0.52658737,  0.14587428, -0.04349925, -0.26292914,\n",
            "           0.06309345, -0.01669581,  0.04645417,  0.03993175,\n",
            "          -0.10049019, -0.12638389,  0.04252902, -0.00328811,\n",
            "           0.00735371,  0.05858986, -0.00223769, -0.24644451,\n",
            "           0.12710423, -0.29410729, -0.00127753,  0.09296163,\n",
            "           0.00668882, -0.30191999, -0.05808315, -0.03015743]]]])}, {'f': 2, 'stride': 1}, {'pad': 0, 'stride': 2, 'W': array([[[[-0.07986625,  0.11678102, -0.3288412 , ...,  0.2317816 ,\n",
            "          -0.30116569, -0.05409775],\n",
            "         [ 0.26087606, -0.03125104,  0.11424043, ..., -0.05418152,\n",
            "           0.10626364, -0.0556251 ],\n",
            "         [-0.32578237, -0.00448055,  0.0988528 , ...,  0.04888055,\n",
            "          -0.0664163 , -0.17217026],\n",
            "         ...,\n",
            "         [-0.07584487, -0.17112846, -0.2400375 , ..., -0.06406907,\n",
            "          -0.12227721,  0.04399296],\n",
            "         [ 0.2832714 ,  0.18920907,  0.11310988, ...,  0.27630209,\n",
            "           0.19359854, -0.14347455],\n",
            "         [-0.00660907, -0.15083581, -0.02042356, ...,  0.07114102,\n",
            "          -0.04283899,  0.20660944]],\n",
            "\n",
            "        [[-0.04624062, -0.29931108,  0.23511069, ..., -0.26625919,\n",
            "           0.1901117 ,  0.11845911],\n",
            "         [ 0.04636501,  0.12629391, -0.11688426, ...,  0.05518501,\n",
            "          -0.15518798, -0.18988642],\n",
            "         [-0.23157434,  0.21741094,  0.07248029, ..., -0.18330087,\n",
            "           0.15229206, -0.3068907 ],\n",
            "         ...,\n",
            "         [ 0.17731088,  0.07251675, -0.13754263, ...,  0.00735902,\n",
            "           0.28046027,  0.27520072],\n",
            "         [-0.0655164 , -0.13162418,  0.16087754, ..., -0.1811695 ,\n",
            "          -0.26499617, -0.18385028],\n",
            "         [-0.16121593,  0.07217745,  0.24613163, ..., -0.20263087,\n",
            "          -0.07480673, -0.12641833]]],\n",
            "\n",
            "\n",
            "       [[[-0.03121404,  0.16202667,  0.19411365, ..., -0.04612885,\n",
            "          -0.2071446 , -0.12878459],\n",
            "         [ 0.10597679, -0.05843497, -0.21740681, ..., -0.12112791,\n",
            "           0.27000818, -0.22407296],\n",
            "         [ 0.04823668, -0.15824326,  0.19284218, ...,  0.09808946,\n",
            "          -0.00492496,  0.07229667],\n",
            "         ...,\n",
            "         [-0.09565803, -0.11809949, -0.14347116, ...,  0.03087617,\n",
            "           0.14290741, -0.11736111],\n",
            "         [ 0.2643782 ,  0.0981774 ,  0.08451166, ..., -0.15006089,\n",
            "           0.26438087, -0.05178929],\n",
            "         [ 0.26999252,  0.1135007 , -0.2780152 , ...,  0.19308384,\n",
            "          -0.26586036, -0.18937131]],\n",
            "\n",
            "        [[ 0.0055112 ,  0.11414914, -0.01152241, ..., -0.1533409 ,\n",
            "           0.2413687 , -0.16174592],\n",
            "         [-0.23958211, -0.19448408,  0.1820139 , ..., -0.27043875,\n",
            "           0.08921228, -0.0546184 ],\n",
            "         [ 0.20963419,  0.2283667 ,  0.30813242, ..., -0.29735706,\n",
            "           0.10469427, -0.11542274],\n",
            "         ...,\n",
            "         [-0.08215787,  0.10949381,  0.0711541 , ...,  0.08169238,\n",
            "           0.28850231, -0.19821657],\n",
            "         [ 0.11873103,  0.10405403,  0.22601394, ..., -0.05101905,\n",
            "          -0.13018288,  0.21161201],\n",
            "         [-0.12789652,  0.26236035,  0.21724581, ..., -0.24424183,\n",
            "           0.3377904 ,  0.1613594 ]]]]), 'b': array([[[[-0.14511473, -0.02676096,  0.0657868 , -0.0783397 ,\n",
            "          -0.04290591, -0.01195857,  0.        , -0.07478454,\n",
            "          -0.02817676, -0.02322703, -0.02482717, -0.08247488,\n",
            "          -0.00774574, -0.03335528, -0.08276626,  0.07480316,\n",
            "          -0.12070901, -0.03794798, -0.02424381, -0.04964758,\n",
            "          -0.00148567,  0.00362876, -0.01534428, -0.04496504,\n",
            "          -0.03253063,  0.07180935, -0.09722714, -0.04619632,\n",
            "          -0.00067944, -0.0047682 , -0.16073971, -0.08102794]]]])}, {'W': array([[-0.008429857291195391, 0.0236898564803771, -0.053872242828628396,\n",
            "        ..., -0.03453519482780293, 0.05066177209639719,\n",
            "        0.02604306747321605],\n",
            "       [-0.026788265320327378, 0.00866862696413272, 0.04928111662035057,\n",
            "        ..., -0.04690260485970377, 0.008575105977823478,\n",
            "        -0.01803997648507085],\n",
            "       [0.040869246392762404, 0.04008292199713297, 0.05234790665695392,\n",
            "        ..., 0.0034804559700057497, 0.042091021395258076,\n",
            "        0.025585897507560722],\n",
            "       ...,\n",
            "       [0.00590586142387047, -0.0008143706010242241,\n",
            "        -0.03839855667217639, ..., 0.05197313741361182,\n",
            "        -0.016586676052209037, -0.021031766917320272],\n",
            "       [-0.03861144953771613, -0.03463375535579452, 0.015884868651131815,\n",
            "        ..., 0.0009613191897150999, 0.02818238333721185,\n",
            "        0.03804647566247269],\n",
            "       [-0.015495360170841105, -0.01821306276964703,\n",
            "        -0.037701297564126955, ..., 0.03175248972656864,\n",
            "        -0.009734926093991542, 0.010420628264064764]], dtype=object), 'b': array([[-2.8395937078096605e-05],\n",
            "       [-0.00028203627531187496],\n",
            "       [-0.0002653274104236077],\n",
            "       [-4.394642222089378e-05],\n",
            "       [0.0],\n",
            "       [-3.194822491206153e-05],\n",
            "       [-0.00013237743797033408],\n",
            "       [0.0003479656056464584],\n",
            "       [0.00010064445469359439],\n",
            "       [0.00017276444269761416],\n",
            "       [8.154460311732636e-05],\n",
            "       [-1.4550631699838576e-05],\n",
            "       [-0.0003467014183297173],\n",
            "       [1.0064353151124613e-05],\n",
            "       [9.773423683906625e-05],\n",
            "       [-6.228942337273086e-05],\n",
            "       [-7.036803618937305e-05],\n",
            "       [0.00011679977042961048],\n",
            "       [0.0003956437233399717],\n",
            "       [0.0],\n",
            "       [4.8005869064003974e-05],\n",
            "       [0.00032586237742012483],\n",
            "       [0.0],\n",
            "       [2.6943006772493288e-05],\n",
            "       [-0.00011370069828097482],\n",
            "       [0.00013165777637665088],\n",
            "       [-4.0743420563162935e-05],\n",
            "       [-2.3773930469112855e-05],\n",
            "       [-9.849291520382126e-05],\n",
            "       [-6.98926095664618e-05],\n",
            "       [0.00027217372951438684],\n",
            "       [0.0],\n",
            "       [0.00025665494321764547],\n",
            "       [2.2965064273768526e-05],\n",
            "       [0.0007311076264941768],\n",
            "       [-1.6883596740265123e-05],\n",
            "       [0.0],\n",
            "       [5.2549312457465894e-05],\n",
            "       [-0.00014994240875644386],\n",
            "       [0.0],\n",
            "       [-4.309816450324502e-05],\n",
            "       [0.00023760652246042964],\n",
            "       [-1.2662589133113754e-06],\n",
            "       [0.0],\n",
            "       [9.970139922691761e-05],\n",
            "       [-6.073295248004697e-06],\n",
            "       [-9.831473985078867e-06],\n",
            "       [-9.699872598107469e-05],\n",
            "       [-0.0001564549012636943],\n",
            "       [0.00031845115969941583],\n",
            "       [-3.4889666166987835e-06],\n",
            "       [0.0],\n",
            "       [-0.00013593854162064303],\n",
            "       [7.905214733464592e-05],\n",
            "       [-0.00022392783999246232],\n",
            "       [0.0],\n",
            "       [0.0002160231638061075],\n",
            "       [-0.0002215961259732565],\n",
            "       [-1.0375067395056885e-05],\n",
            "       [-5.555350925575078e-05],\n",
            "       [-3.619967215647877e-05],\n",
            "       [3.8920611828126396e-06],\n",
            "       [-0.00016155245619826582],\n",
            "       [-0.0001410798640203723],\n",
            "       [-8.914601543585193e-05],\n",
            "       [-7.408279250752445e-06],\n",
            "       [6.564074146050483e-05],\n",
            "       [7.650889600123217e-05],\n",
            "       [0.0001226845637127332],\n",
            "       [0.00018184417260632617],\n",
            "       [0.0001448723340918332],\n",
            "       [0.0003876322145656696],\n",
            "       [0.00010895135790117392],\n",
            "       [-0.00025422462902548854],\n",
            "       [3.632461077263056e-05],\n",
            "       [2.3931229051161642e-05],\n",
            "       [-6.610406131432317e-05],\n",
            "       [1.3808107797576201e-05],\n",
            "       [0.000411052423227108],\n",
            "       [-0.0005437647224844129],\n",
            "       [4.967501290124954e-05],\n",
            "       [-0.00019873369053062263],\n",
            "       [3.7777794008413585e-05],\n",
            "       [0.0],\n",
            "       [-0.0001609844458126859],\n",
            "       [0.00016617920448029334],\n",
            "       [-5.5952325864278624e-05],\n",
            "       [-0.00016050644733540465],\n",
            "       [0.00034430933587443086],\n",
            "       [-0.00018269917148638405],\n",
            "       [1.310975855000395e-05],\n",
            "       [0.0001516071209172412],\n",
            "       [1.6248803800378087e-06],\n",
            "       [0.0005566603633934675],\n",
            "       [-0.0004008402576274901],\n",
            "       [0.0003449253972322954],\n",
            "       [0.00020566617147241265],\n",
            "       [-8.267609991995432e-05],\n",
            "       [-8.536488624612879e-05],\n",
            "       [-0.00043029780585975474],\n",
            "       [-0.00010577090629799661],\n",
            "       [-0.0002681141907795418],\n",
            "       [0.0002060353803754394],\n",
            "       [0.00014937675327783502],\n",
            "       [0.0],\n",
            "       [-0.00018748037310091238],\n",
            "       [-9.161816431828656e-05],\n",
            "       [-2.702300204888598e-05],\n",
            "       [3.548222434226731e-05],\n",
            "       [1.6925862271201267e-05],\n",
            "       [1.8227375928993715e-05],\n",
            "       [-0.0001633509963612438],\n",
            "       [0.0005038933297225064],\n",
            "       [0.0],\n",
            "       [-2.727040086581052e-05],\n",
            "       [-5.7098747522692835e-05],\n",
            "       [-0.0001937125185692113],\n",
            "       [-0.00019056068514641973],\n",
            "       [-2.810930361540343e-05],\n",
            "       [-4.6543240410411675e-07],\n",
            "       [-4.015818645082756e-05],\n",
            "       [-3.9689604310791524e-06],\n",
            "       [2.2020101616845332e-05],\n",
            "       [-0.0001900970341442789],\n",
            "       [0.0],\n",
            "       [0.00014280620528795017],\n",
            "       [0.00020826759666995313],\n",
            "       [7.631897220237812e-06],\n",
            "       [-0.00029850432115989604],\n",
            "       [0.00022916338706805754],\n",
            "       [-3.2070667238652076e-05],\n",
            "       [1.7122196433074305e-05],\n",
            "       [-2.6453262572938177e-06],\n",
            "       [0.0],\n",
            "       [-1.2070968111494533e-05],\n",
            "       [3.3233120448967623e-06],\n",
            "       [-7.724269335204578e-05],\n",
            "       [0.00018215857748251528],\n",
            "       [-0.00010299894242159162],\n",
            "       [-8.088254507249581e-06],\n",
            "       [-4.891195330015434e-07],\n",
            "       [0.0],\n",
            "       [0.0001402087114668624],\n",
            "       [2.4508623450258524e-05],\n",
            "       [0.0007755808749382724],\n",
            "       [0.00028871217021457485],\n",
            "       [0.00031523335048332866],\n",
            "       [1.2651174570407407e-05],\n",
            "       [0.0001802560760431124],\n",
            "       [-0.00020076989371744505],\n",
            "       [-0.00026626718058426785],\n",
            "       [5.269470866822124e-05],\n",
            "       [-1.854011722502788e-05],\n",
            "       [-0.00025656096422996093],\n",
            "       [0.00014647878485500257],\n",
            "       [-7.184020359146224e-07],\n",
            "       [0.00019424963282867495],\n",
            "       [-0.0003506683588651788],\n",
            "       [1.1922488753562799e-05],\n",
            "       [-0.0001846093850328207],\n",
            "       [-6.656427402288195e-06],\n",
            "       [-0.00011827443888928646],\n",
            "       [0.00011525548144545474],\n",
            "       [0.0],\n",
            "       [9.448625254786563e-05],\n",
            "       [-0.00030777409324417987],\n",
            "       [-0.0002605267149737701],\n",
            "       [-1.1230375321778443e-05],\n",
            "       [7.109217858700241e-06],\n",
            "       [-0.00025698101620718895],\n",
            "       [0.0006787387295386886],\n",
            "       [9.21891656489657e-05],\n",
            "       [0.00022109525341217445],\n",
            "       [-0.00010238925465041284],\n",
            "       [7.735128013825679e-05],\n",
            "       [-1.0668384762554591e-05],\n",
            "       [5.560040558861201e-05],\n",
            "       [0.00045879211587140803],\n",
            "       [0.00023964726128570247],\n",
            "       [-5.7585925086173326e-05],\n",
            "       [-5.117528129590824e-05],\n",
            "       [-0.00020402699475509118],\n",
            "       [-8.770200021491982e-06],\n",
            "       [4.787079040301004e-05],\n",
            "       [3.8740186100356315e-05],\n",
            "       [3.2805558395336722e-06],\n",
            "       [-2.107594662808111e-05],\n",
            "       [0.00025362088343557434],\n",
            "       [-3.260154531350248e-06],\n",
            "       [7.112738727297051e-05],\n",
            "       [-3.0661092333024646e-06],\n",
            "       [-0.000286601845991003],\n",
            "       [-0.00018699693189895615],\n",
            "       [4.377654741954263e-06],\n",
            "       [1.47628370191764e-06],\n",
            "       [-1.3532975353621231e-05],\n",
            "       [-0.00012211142381097383],\n",
            "       [0.00014004037477502568],\n",
            "       [-1.4645621605516051e-05],\n",
            "       [-0.00025609868630403526],\n",
            "       [-1.5759470017043863e-05],\n",
            "       [-0.00011003290128424706],\n",
            "       [0.00017285984319439308],\n",
            "       [6.511245774622657e-05],\n",
            "       [-6.0038613341124224e-05],\n",
            "       [-0.000250061155960654],\n",
            "       [0.00039877334228472145],\n",
            "       [0.00011866276032359949],\n",
            "       [-0.0003172535020778204],\n",
            "       [5.6785202457845166e-05],\n",
            "       [7.65362051050579e-05],\n",
            "       [-0.00012770339824495511],\n",
            "       [-9.682660156453203e-06],\n",
            "       [0.00021156641763663795],\n",
            "       [3.603716501598855e-05],\n",
            "       [0.0],\n",
            "       [1.8228216132060737e-05],\n",
            "       [9.705134318847372e-05],\n",
            "       [0.0],\n",
            "       [-0.00035609491866100496],\n",
            "       [-8.518252298517685e-05],\n",
            "       [-2.4646486529817086e-06],\n",
            "       [-8.420840741260436e-05],\n",
            "       [0.0001644261444721742],\n",
            "       [-0.0002002930770814302],\n",
            "       [2.115532712568361e-05],\n",
            "       [-0.00021939353669495878],\n",
            "       [-0.00011426358493755811],\n",
            "       [0.0004229540944995446],\n",
            "       [-0.00010192666962437369],\n",
            "       [6.8157261309170076e-06],\n",
            "       [0.00010678802544311218],\n",
            "       [2.8214674189735202e-08],\n",
            "       [1.4133596554758435e-05],\n",
            "       [-1.5770461207906334e-06],\n",
            "       [-7.148256158058705e-06],\n",
            "       [-0.00042679703616997747],\n",
            "       [-0.00021159239551963392],\n",
            "       [4.1450700098269706e-05],\n",
            "       [-0.00016977889221070973],\n",
            "       [0.00013358746301848876],\n",
            "       [-0.0001215804945298538],\n",
            "       [0.0],\n",
            "       [-3.3869133879564794e-05],\n",
            "       [-1.1678712670226075e-05],\n",
            "       [-2.5993476621103933e-05],\n",
            "       [-0.00022612230510832076],\n",
            "       [0.00031257440206380085],\n",
            "       [4.878809748226024e-05],\n",
            "       [-0.0001869365633239164],\n",
            "       [0.0],\n",
            "       [-0.0002057784475339869],\n",
            "       [-8.518200701046217e-05],\n",
            "       [-0.00011990167842632853],\n",
            "       [3.483518219028307e-06],\n",
            "       [-0.00010618209486896069],\n",
            "       [7.173385688355682e-06],\n",
            "       [6.331308530247462e-05],\n",
            "       [0.00017542437859972737],\n",
            "       [-0.0002706615813305086],\n",
            "       [4.248746628529136e-05],\n",
            "       [9.715193727328701e-05],\n",
            "       [8.795012152242706e-06],\n",
            "       [-0.00020938514752339457],\n",
            "       [0.00033389729856040523],\n",
            "       [0.00017201027516137348],\n",
            "       [-0.0006337040896179949],\n",
            "       [-0.00019639962052284753],\n",
            "       [-0.00018907061232395725],\n",
            "       [-9.308894971646193e-05],\n",
            "       [-0.00032178576914721006],\n",
            "       [3.8595804826989774e-05],\n",
            "       [-1.960608917678476e-05],\n",
            "       [0.00012594214809468588],\n",
            "       [4.733824920755752e-06],\n",
            "       [3.7008372503527436e-05],\n",
            "       [-3.137111707280431e-05],\n",
            "       [-2.414820584090448e-05],\n",
            "       [-0.00035328407036677327],\n",
            "       [0.00045283568169162823],\n",
            "       [-5.1244682092297475e-06],\n",
            "       [-0.000334915125401662],\n",
            "       [5.82020948520548e-06],\n",
            "       [-1.4723787111873508e-06],\n",
            "       [6.794603318146572e-05],\n",
            "       [-1.6589698424202315e-05],\n",
            "       [3.719505890392098e-05],\n",
            "       [3.148810464528544e-05],\n",
            "       [-0.0003598338474639102],\n",
            "       [-1.5976574548794474e-07],\n",
            "       [-0.00019807441774078344],\n",
            "       [0.0003734568864169462],\n",
            "       [0.0],\n",
            "       [0.0001665658180618241],\n",
            "       [6.186985190822356e-05],\n",
            "       [-2.5934633466144997e-05],\n",
            "       [-0.00020204645185370877],\n",
            "       [0.0],\n",
            "       [0.00017515967385725294],\n",
            "       [-1.3630133235978263e-05],\n",
            "       [2.3921538867381256e-05],\n",
            "       [-0.00018059849688827406],\n",
            "       [0.0003195542722098908],\n",
            "       [9.501278882639783e-05],\n",
            "       [0.00025971521494543416],\n",
            "       [0.0],\n",
            "       [0.00018144533428986312],\n",
            "       [1.4286465043243804e-05],\n",
            "       [0.00028595101591265943],\n",
            "       [-3.40394164434007e-05],\n",
            "       [-3.3346444557344405e-06],\n",
            "       [0.00028939253919782996],\n",
            "       [3.230820988665129e-05],\n",
            "       [6.13521405707178e-05],\n",
            "       [-2.3159096154092914e-05],\n",
            "       [0.0],\n",
            "       [-9.504335281544066e-05],\n",
            "       [-9.876099452894493e-05],\n",
            "       [-0.0003142147088430272],\n",
            "       [5.0942456692317665e-05],\n",
            "       [-5.9421486825677724e-05],\n",
            "       [1.477205346152925e-06],\n",
            "       [0.00011511206480276602],\n",
            "       [-3.992800688978506e-05],\n",
            "       [0.0003094920233080258],\n",
            "       [-1.8221633619778687e-06],\n",
            "       [0.00011611568159090017],\n",
            "       [0.00012974577644736773],\n",
            "       [-0.00020761532359591498],\n",
            "       [0.0002688644693814389],\n",
            "       [8.253734638303299e-06],\n",
            "       [0.0002141590001835123],\n",
            "       [5.6238811992015536e-05],\n",
            "       [-8.3877737601535e-05],\n",
            "       [-2.3210798076215902e-05],\n",
            "       [-1.4480699580803047e-05],\n",
            "       [0.00016447413770430029],\n",
            "       [-9.682676730683401e-05],\n",
            "       [-6.500133431880886e-06],\n",
            "       [-4.737925258947622e-05],\n",
            "       [-0.00017711606591035481],\n",
            "       [-0.0004605345151413385],\n",
            "       [-0.0002039314409951338],\n",
            "       [0.0005124089711051963],\n",
            "       [-0.0001146551313096794],\n",
            "       [-1.2710125923653456e-06],\n",
            "       [0.00015742720020157005],\n",
            "       [-0.00015481919415833735],\n",
            "       [0.00038893922530958505],\n",
            "       [-5.9506254869403254e-05],\n",
            "       [-5.34502911140281e-05],\n",
            "       [0.0],\n",
            "       [-1.833081653533549e-05],\n",
            "       [1.6674172595850094e-05],\n",
            "       [0.0006422946573911248],\n",
            "       [-3.906103087848551e-05],\n",
            "       [9.387270264337446e-05],\n",
            "       [0.0003448446280628752],\n",
            "       [-9.421439102741604e-05],\n",
            "       [-5.767350540292675e-05],\n",
            "       [-0.00011371875644023066],\n",
            "       [-0.00047054733502886607],\n",
            "       [0.00019176955175506514],\n",
            "       [-0.0005445464016474525],\n",
            "       [-0.00014627632947633606],\n",
            "       [-0.00029080193791918593],\n",
            "       [4.409912774899662e-06],\n",
            "       [0.0],\n",
            "       [-0.00017808701972439698],\n",
            "       [6.244398860946141e-05],\n",
            "       [0.0004391036062912302],\n",
            "       [-0.0002259737866426021],\n",
            "       [-6.345902518724869e-05],\n",
            "       [4.714971306798043e-05],\n",
            "       [0.0],\n",
            "       [-0.0003075173220445538],\n",
            "       [0.0001484929280729502],\n",
            "       [2.5459037529825406e-05],\n",
            "       [-0.00035257139865843833],\n",
            "       [-7.598739357825084e-05],\n",
            "       [0.0],\n",
            "       [-4.7620224907658156e-06],\n",
            "       [-1.6140841912793284e-05],\n",
            "       [-6.802237615045869e-05],\n",
            "       [3.5017406824015346e-05],\n",
            "       [0.00015055116512992348],\n",
            "       [-1.8318966817135844e-05],\n",
            "       [-0.00014103649180052016],\n",
            "       [0.00010728397216352711],\n",
            "       [1.0045074101076735e-05],\n",
            "       [0.0001444746671382527],\n",
            "       [3.291812327672095e-05],\n",
            "       [-1.9465869445457566e-05],\n",
            "       [-0.00011038796838997751],\n",
            "       [-9.696134816427383e-05],\n",
            "       [-6.789792356411989e-05],\n",
            "       [1.810918254067106e-05],\n",
            "       [-0.0003765557037930599],\n",
            "       [-0.00012529675722116462],\n",
            "       [-0.00013006804988426932],\n",
            "       [0.00014332402719675934],\n",
            "       [1.1620547041081156e-05],\n",
            "       [0.0005820102191716356],\n",
            "       [3.69023645840547e-05],\n",
            "       [-7.288551156584179e-05],\n",
            "       [0.0002041854369734841],\n",
            "       [-2.345579021236557e-05],\n",
            "       [-8.60370681512815e-05],\n",
            "       [0.0],\n",
            "       [-0.00014266550160625476],\n",
            "       [-0.0002935807890257627],\n",
            "       [-0.00023099767157741722],\n",
            "       [-0.00010428243840621556],\n",
            "       [6.728253220396595e-05],\n",
            "       [0.00013136807354644187],\n",
            "       [-0.00017841932841349394],\n",
            "       [-6.9692817362765395e-06],\n",
            "       [-0.0003395045846921093],\n",
            "       [-5.3339879337524906e-05],\n",
            "       [7.259487129183671e-05],\n",
            "       [0.0],\n",
            "       [-1.97800403514696e-05],\n",
            "       [-3.696756228306482e-05],\n",
            "       [-0.00022576010397058904],\n",
            "       [3.329834124685257e-06],\n",
            "       [0.0005383482221364857],\n",
            "       [0.00016797910827564421],\n",
            "       [-7.631236995676504e-05],\n",
            "       [8.529952853554733e-06],\n",
            "       [0.0],\n",
            "       [-2.0512785369353653e-05],\n",
            "       [1.2682522600704329e-05],\n",
            "       [-2.4904130073051557e-06],\n",
            "       [0.00011378411787362828],\n",
            "       [-9.497141993302253e-05],\n",
            "       [-4.8971825397427465e-05],\n",
            "       [7.185814142293143e-05],\n",
            "       [-7.908730412505965e-05],\n",
            "       [-0.0004694222559527518],\n",
            "       [0.0004857918502754636],\n",
            "       [-0.0003173444304232717],\n",
            "       [-0.00024992936342663625],\n",
            "       [0.0002149413758849908],\n",
            "       [-1.1955135205014993e-05],\n",
            "       [-8.69444293635983e-05],\n",
            "       [-0.0004627928812586586],\n",
            "       [-9.41585984311564e-05],\n",
            "       [1.2671424951257444e-05],\n",
            "       [5.442284255416752e-05],\n",
            "       [-0.0002711222887969375],\n",
            "       [0.00010410567575482165],\n",
            "       [-6.31890034341147e-05],\n",
            "       [-3.747276281163548e-06],\n",
            "       [0.0003845018154014126],\n",
            "       [0.00027493618363617743],\n",
            "       [-6.954412461422336e-05],\n",
            "       [5.0289618239386144e-05],\n",
            "       [0.0005165964940009797],\n",
            "       [6.851351744787367e-05],\n",
            "       [8.097333035913025e-05],\n",
            "       [-2.1791100715659114e-06],\n",
            "       [0.0003047555120702976],\n",
            "       [-0.00015326778452025232],\n",
            "       [0.00015563872423502158],\n",
            "       [0.0],\n",
            "       [0.00029920176848931106],\n",
            "       [0.000150994720832313],\n",
            "       [-0.0002607201052963375],\n",
            "       [2.8103836892694995e-05],\n",
            "       [-0.00012049043532442387],\n",
            "       [-2.4150387674281922e-05],\n",
            "       [6.4272012599732464e-06],\n",
            "       [1.7076871308909375e-05],\n",
            "       [-0.00011104481796625615],\n",
            "       [1.8443310343242566e-05],\n",
            "       [2.138379015595516e-05],\n",
            "       [-0.00016883239266631423],\n",
            "       [-2.05668329170397e-05],\n",
            "       [-0.000247275882439072],\n",
            "       [-0.0001135970550806798],\n",
            "       [-0.00028001902302402355],\n",
            "       [1.0694454962704412e-05],\n",
            "       [0.0002611904729600854],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [0.00031029459031602135],\n",
            "       [-5.783246970013301e-06],\n",
            "       [0.0],\n",
            "       [0.00027698236617724],\n",
            "       [-1.4366609831233137e-05],\n",
            "       [3.176090944295403e-05],\n",
            "       [-5.819940382878002e-05],\n",
            "       [3.517538720769882e-05],\n",
            "       [2.953966652437257e-07],\n",
            "       [-9.87834698417707e-05],\n",
            "       [0.0001269074075056529],\n",
            "       [0.00015936579795288632],\n",
            "       [-0.00018622595858506483],\n",
            "       [-2.8166021113584718e-05],\n",
            "       [2.5961935777064057e-06],\n",
            "       [-7.733687963398355e-06],\n",
            "       [-3.489804178466548e-05],\n",
            "       [-6.637832313366721e-05],\n",
            "       [0.00020959045797038018],\n",
            "       [0.0],\n",
            "       [-0.00025111939311844525],\n",
            "       [0.0],\n",
            "       [8.992282609381997e-05],\n",
            "       [9.726193703486878e-05],\n",
            "       [-8.828869007806407e-05],\n",
            "       [2.5875880903484074e-05],\n",
            "       [0.0]], dtype=object)}, {'W': array([[-0.013980152160631459, 0.04113622523983461, -0.09076367608860672,\n",
            "        ..., -0.04707054561592885, 0.013491761077005514,\n",
            "        -0.027419059180934804],\n",
            "       [-0.07991030127973182, -0.048765711767596316,\n",
            "        0.029982281553935543, ..., 0.02132656523161327,\n",
            "        -0.012287690675506165, 0.06313136894973953],\n",
            "       [-0.008283575473799067, -0.08797640351593053, 0.0677417213353489,\n",
            "        ..., 0.05087585074290704, -0.06431158442854752,\n",
            "        -0.046321578461455834],\n",
            "       ...,\n",
            "       [-0.06427159792461573, -0.010036935532815055,\n",
            "        -0.04726150323690596, ..., -0.038442828205944767,\n",
            "        -0.024459117047230732, -0.027442809387543662],\n",
            "       [0.0092118669089462, 0.03512782124701573, 0.05152116475379628,\n",
            "        ..., 0.028303256530253486, -0.0899252566528055,\n",
            "        -0.03824954685505061],\n",
            "       [-0.04905662792727438, -0.06411481267400969, 0.011982328113856073,\n",
            "        ..., 0.0029422729462496742, -0.04952578677390439,\n",
            "        -0.07502688206081859]], dtype=object), 'b': array([[0.00042213672118601535],\n",
            "       [0.0006423374509359174],\n",
            "       [5.005495537354665e-05],\n",
            "       [5.3827350557702615e-05],\n",
            "       [0.0],\n",
            "       [0.00014032540398655087],\n",
            "       [0.00022437423131182823],\n",
            "       [0.00016746334791480246],\n",
            "       [0.0],\n",
            "       [-0.00047837799310347304],\n",
            "       [-0.0002901261625562002],\n",
            "       [0.0005199498666714924],\n",
            "       [0.0],\n",
            "       [-0.0003815424419603347],\n",
            "       [0.00019287292481118254],\n",
            "       [0.000521566010127488],\n",
            "       [4.7900673697170725e-06],\n",
            "       [-0.0002979014692196865],\n",
            "       [-0.0002690435780546502],\n",
            "       [0.0004256333737564275],\n",
            "       [-7.480883029052793e-05],\n",
            "       [0.0002000413704219649],\n",
            "       [-0.00033055809639567877],\n",
            "       [0.0006442800935781908],\n",
            "       [5.8771665908222386e-05],\n",
            "       [-0.0001451034668828533],\n",
            "       [0.00040687225667145163],\n",
            "       [0.00031347091597534017],\n",
            "       [-5.554424130827079e-05],\n",
            "       [0.0009410884712535894],\n",
            "       [0.0005408264387245345],\n",
            "       [0.0003112649161725277],\n",
            "       [-2.0031823850360072e-05],\n",
            "       [-0.00046264408649505717],\n",
            "       [-3.3148494043796814e-05],\n",
            "       [0.0010339566278243968],\n",
            "       [-0.0003782261973402276],\n",
            "       [0.0002304212997409811],\n",
            "       [0.00039436109864261337],\n",
            "       [-6.95389406900809e-05],\n",
            "       [-0.00010385161688569933],\n",
            "       [-8.608747305081897e-05],\n",
            "       [0.00015113533088669033],\n",
            "       [-0.00021537108939708973],\n",
            "       [-4.866561816300582e-06],\n",
            "       [-0.0005372893102123962],\n",
            "       [-0.0006464319950743092],\n",
            "       [-5.122982583636327e-05],\n",
            "       [3.902776443470245e-05],\n",
            "       [-0.0003636824542893234],\n",
            "       [0.00020660315585196228],\n",
            "       [-0.00045253108213463974],\n",
            "       [5.8520125982173955e-05],\n",
            "       [0.0003776639002795121],\n",
            "       [0.00015043710169207992],\n",
            "       [-1.9047902631091018e-06],\n",
            "       [-0.00013926326674231588],\n",
            "       [1.2238008778955661e-05],\n",
            "       [0.0001861274757133478],\n",
            "       [9.12698457815064e-05],\n",
            "       [0.0],\n",
            "       [4.052989712453104e-05],\n",
            "       [0.00040020457836394184],\n",
            "       [0.0001521892119508002],\n",
            "       [-0.0001887024358668264],\n",
            "       [0.0],\n",
            "       [-0.00024738306998107687],\n",
            "       [-2.2163181899047993e-05],\n",
            "       [-5.4805659153107376e-05],\n",
            "       [-0.00014994378136372327],\n",
            "       [7.607250460508284e-05],\n",
            "       [-4.849322372105119e-05],\n",
            "       [-0.0005545440361379953],\n",
            "       [-0.00012380023921350987],\n",
            "       [-0.0003425096895156818],\n",
            "       [-0.0004568970496528079],\n",
            "       [-0.00011613269575367526],\n",
            "       [-0.00039412362646809075],\n",
            "       [9.665686845425482e-06],\n",
            "       [0.0],\n",
            "       [-0.00011898081042850907],\n",
            "       [-3.820315261913438e-05],\n",
            "       [3.628547787700671e-05],\n",
            "       [2.2726685260274223e-05],\n",
            "       [0.00042250026893783286],\n",
            "       [-0.0001130144401554216],\n",
            "       [4.1758222517525634e-05],\n",
            "       [-0.0005990201535292102],\n",
            "       [0.0003804554913682558],\n",
            "       [0.00037202908424495304],\n",
            "       [6.728018700594843e-05],\n",
            "       [-0.0002506234481435989],\n",
            "       [0.0005506681429405273],\n",
            "       [4.23574531799603e-07],\n",
            "       [0.0],\n",
            "       [3.7603124283775455e-06],\n",
            "       [-0.0008474312418072776],\n",
            "       [-0.00010845489773892071],\n",
            "       [0.0],\n",
            "       [-4.3369406812797056e-05],\n",
            "       [-0.00015319559626682835],\n",
            "       [-2.3020210748047116e-05],\n",
            "       [-5.888947649025766e-05],\n",
            "       [-0.00018011628127726032],\n",
            "       [-0.0003295332869939452],\n",
            "       [-0.0001722566495675386],\n",
            "       [0.0003439365685620579],\n",
            "       [0.0002537311676163585],\n",
            "       [-0.000984127724425973],\n",
            "       [-0.00045817290351897884],\n",
            "       [4.325224031045958e-05],\n",
            "       [0.0008101610684516434],\n",
            "       [4.390213486231303e-05],\n",
            "       [0.0],\n",
            "       [0.00019540188512019266],\n",
            "       [0.00038097860406187845],\n",
            "       [-6.333106594358239e-06],\n",
            "       [-0.0001315614275180985],\n",
            "       [3.964149469658701e-06],\n",
            "       [-0.00012908620671841397],\n",
            "       [-8.188343967376593e-05],\n",
            "       [0.0],\n",
            "       [0.0008667857663431324],\n",
            "       [0.00010182106457745365],\n",
            "       [-0.00040257089456205376],\n",
            "       [7.720749065450763e-05],\n",
            "       [-6.167501910979786e-05],\n",
            "       [-3.1292369019960894e-05],\n",
            "       [-2.210821068554651e-06],\n",
            "       [0.000346384921989641],\n",
            "       [3.874119679573925e-05],\n",
            "       [0.0],\n",
            "       [0.00028976071667676466],\n",
            "       [2.641340675722093e-06],\n",
            "       [-0.00015602541793170455],\n",
            "       [0.00023840371647465552],\n",
            "       [-6.050506978584652e-06],\n",
            "       [-0.00013702847405296613],\n",
            "       [0.00031674218074032577],\n",
            "       [-3.5956400823635824e-05],\n",
            "       [0.00025289436318286484],\n",
            "       [-0.00011524914817063966],\n",
            "       [3.3527342565927535e-05],\n",
            "       [0.00017385553258947444],\n",
            "       [0.0006130775912304614],\n",
            "       [9.913523492449752e-05],\n",
            "       [0.0],\n",
            "       [-0.0001566232046878901],\n",
            "       [-3.9870303602612644e-05],\n",
            "       [4.7678236889590375e-05],\n",
            "       [-8.704557086002112e-05],\n",
            "       [8.032945525749598e-05],\n",
            "       [-0.00016807453023461621],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [-0.00013381005462570706],\n",
            "       [-8.659610133980146e-06],\n",
            "       [-3.544981221818733e-05],\n",
            "       [2.9023603442948036e-05],\n",
            "       [0.0],\n",
            "       [-5.1860092647825496e-05],\n",
            "       [0.00010761240990939091],\n",
            "       [0.0],\n",
            "       [-8.067430841132002e-05],\n",
            "       [-8.903019436811989e-06],\n",
            "       [0.0002683628880295641],\n",
            "       [4.342230915668237e-05],\n",
            "       [0.0002927605527646808],\n",
            "       [-1.4739249762423106e-05],\n",
            "       [1.1560261168496746e-05],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [-0.00032482956165836023],\n",
            "       [0.0007500173032200749],\n",
            "       [-0.00023524517966386265],\n",
            "       [0.00016907463652140128],\n",
            "       [-0.00014071098750663479],\n",
            "       [0.00031185173611643813],\n",
            "       [2.0100942315111785e-05],\n",
            "       [1.919341243083573e-05],\n",
            "       [-0.00042859498062603575],\n",
            "       [-2.1436082109451775e-05],\n",
            "       [-4.730164438291677e-06],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [1.6456550557094888e-05],\n",
            "       [0.0002232015500231176],\n",
            "       [1.5346703447490194e-05],\n",
            "       [3.3996273958364086e-06],\n",
            "       [-0.0005399039774180847],\n",
            "       [-0.00021761880643466692],\n",
            "       [0.0003567260396955171],\n",
            "       [-0.0005017874713635727],\n",
            "       [1.639653260349217e-05],\n",
            "       [-0.0009989206162713867],\n",
            "       [5.314625193643693e-05],\n",
            "       [-2.08636027653095e-05],\n",
            "       [-0.00022784737489410089],\n",
            "       [-0.000463715497500452],\n",
            "       [-9.820926724354581e-05],\n",
            "       [-4.1964406516576776e-05],\n",
            "       [-0.0002686803449180333],\n",
            "       [-7.37906378179222e-05],\n",
            "       [0.0],\n",
            "       [0.0005667039352086297],\n",
            "       [-1.9579330395134452e-05],\n",
            "       [0.0],\n",
            "       [-4.369765774374389e-05],\n",
            "       [0.00011329063685345022],\n",
            "       [3.21959361296949e-06],\n",
            "       [0.00017572299848198813],\n",
            "       [0.0001241603850005346],\n",
            "       [-0.0008767406216625196],\n",
            "       [0.00021512041963676464],\n",
            "       [0.00018070289024803418],\n",
            "       [0.00026345107898245523]], dtype=object)}, {'W': array([[-0.024644052523369864, 0.06444761297395564, -0.1463515254245029,\n",
            "        ..., -0.10950569618915378, -0.1070510836178707,\n",
            "        4.529732954657202e-05],\n",
            "       [-0.14011145822370166, 0.13123037600143253, 0.09577033729205246,\n",
            "        ..., 0.07231926447033013, -0.013900686888711327,\n",
            "        -0.014605763857674583],\n",
            "       [-0.006420066643856079, -0.007607059130370299,\n",
            "        0.08875713830536178, ..., -0.10768981121838801,\n",
            "        -0.08594199086120714, -0.12407307729444211],\n",
            "       ...,\n",
            "       [0.0591937428398483, 0.09709197748067575, 0.0549860293822053, ...,\n",
            "        0.010744480226900301, -0.08886718594433558,\n",
            "        -0.020984832904438734],\n",
            "       [-0.06619559435440632, -0.0938369975401482, 0.11170948736289527,\n",
            "        ..., 0.04791572390605167, 0.13041232673367498,\n",
            "        -0.14314503854552887],\n",
            "       [0.03517304501684762, 0.061487730711553966, 0.02264388278863676,\n",
            "        ..., 0.1385584163105543, 0.1358852432234456, -0.1106009444509085]],\n",
            "      dtype=object), 'b': array([[-0.001649172081522278],\n",
            "       [6.4549021135981825e-06],\n",
            "       [4.672000559928884e-06],\n",
            "       [0.00030961283258474455],\n",
            "       [0.0011381520690655924],\n",
            "       [0.000995252738271158],\n",
            "       [-0.0006567655455519993],\n",
            "       [-0.000464329207418111],\n",
            "       [-3.0058080530342502e-05],\n",
            "       [-0.00016546981874315342],\n",
            "       [0.0008736841182442425],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [-0.0006415572725462433],\n",
            "       [0.0011617949638523572],\n",
            "       [-0.0001546515774435532],\n",
            "       [1.1639650751884343e-05],\n",
            "       [0.0006927319591845249],\n",
            "       [0.0006486499232748957],\n",
            "       [-0.0007109177233121482],\n",
            "       [0.0],\n",
            "       [7.294836643862671e-06],\n",
            "       [0.0004062370643847185],\n",
            "       [0.0011531861312294692],\n",
            "       [0.0011711503794484036],\n",
            "       [0.000507398264928722],\n",
            "       [-0.00047690920219727566],\n",
            "       [0.00047025748584058404],\n",
            "       [-1.458632484974354e-05],\n",
            "       [0.0],\n",
            "       [0.0006275225198193587],\n",
            "       [-0.0010728471450370835],\n",
            "       [-0.0011403875043943482],\n",
            "       [-4.0247467248471125e-05],\n",
            "       [-5.013444543856811e-05],\n",
            "       [0.0],\n",
            "       [-0.0012937097054516425],\n",
            "       [-7.510756685558652e-05],\n",
            "       [-0.0002638512661445663],\n",
            "       [-0.00015083441911768554],\n",
            "       [0.0],\n",
            "       [0.0008480450790788391],\n",
            "       [-7.9234952184809e-06],\n",
            "       [0.0],\n",
            "       [-0.00014400270888483273],\n",
            "       [0.0005479248461842018],\n",
            "       [0.00027909737825341195],\n",
            "       [0.0],\n",
            "       [0.002103766052673849],\n",
            "       [4.2607404804532946e-05],\n",
            "       [-0.00027488790552967514],\n",
            "       [0.0003162531493900796],\n",
            "       [-0.00012883057074455638],\n",
            "       [0.0003450488330646847],\n",
            "       [-0.0001327314730108206],\n",
            "       [8.95395086002263e-05],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [1.899907345072349e-05],\n",
            "       [-0.001177087333567383],\n",
            "       [0.0005482580183628418],\n",
            "       [-1.122799724522753e-05],\n",
            "       [0.0001197534399914352],\n",
            "       [0.0009552351454399696]], dtype=object)}, {'W': array([[-0.04148900360429223, 0.11013517024951418, -0.24994281259132756,\n",
            "        ..., -0.04297200609021584, 0.09719979031944605,\n",
            "        -0.04303939915466933],\n",
            "       [-0.22476961789628616, 0.018174500331369747, 0.0819043513573167,\n",
            "        ..., 0.01942407881865637, 0.025858790346518497,\n",
            "        0.17018282606524643],\n",
            "       [-0.18791334244004443, -0.11040816049443025, 0.04287963572914394,\n",
            "        ..., 0.21240398519967535, -0.11835161475644451,\n",
            "        -0.2170194546579881],\n",
            "       ...,\n",
            "       [-0.23112036794280588, -0.17576722447762402, 0.21131960102650077,\n",
            "        ..., 0.05105063570100797, -0.03794670498186678,\n",
            "        0.15484485635054399],\n",
            "       [0.22083335535375534, 0.18490268979545288, 0.10199974913994425,\n",
            "        ..., 0.011504265867232133, 0.22164246034507462,\n",
            "        0.18235052378511935],\n",
            "       [-0.05396725601474102, -0.10804856686950011, 0.1308649313463709,\n",
            "        ..., -0.16365022021382244, -0.0888438828595786,\n",
            "        -0.12585544798107054]], dtype=object), 'b': array([[-0.00016654205055182165],\n",
            "       [0.0011730525567709726],\n",
            "       [0.0],\n",
            "       [-0.001021686053255601],\n",
            "       [-0.0020679606751349026],\n",
            "       [-0.00011577439219637387],\n",
            "       [-0.002196090914415491],\n",
            "       [2.037215972755822e-05],\n",
            "       [-0.0006258935558046497],\n",
            "       [0.0],\n",
            "       [0.0],\n",
            "       [0.0010263072326989042],\n",
            "       [-0.0005527619112341005],\n",
            "       [0.0],\n",
            "       [0.0007071669538524614],\n",
            "       [1.072324311813833e-05],\n",
            "       [-0.0004996328862325481],\n",
            "       [0.0002713235330575513],\n",
            "       [0.0],\n",
            "       [-0.0016735944773649605],\n",
            "       [-0.00038746911872018764],\n",
            "       [0.0026930465045361877],\n",
            "       [-0.0010292745875609315],\n",
            "       [5.540210580718915e-06],\n",
            "       [0.0021335152880193956],\n",
            "       [0.0030632652141169094],\n",
            "       [-0.002478791182900674],\n",
            "       [-0.00036983578171070636],\n",
            "       [0.00031072700564976674],\n",
            "       [0.0025368418493048645],\n",
            "       [-0.0006800239038975942],\n",
            "       [-2.5995044421526012e-05]], dtype=object)}, {'W': array([[-0.0706580457642674, 0.18759903688568086, -0.426303893539257,\n",
            "        -0.16294584845536775, -0.30368309056916853, -0.3527350799296196,\n",
            "        -0.26812376970517554, -0.131708434828631, -0.09025419889344209,\n",
            "        0.03310302198440351, -0.06891114965872203, 0.16063843072151215,\n",
            "        -0.25355157819842855, 0.32245963322038607, -0.4034474192194135,\n",
            "        0.14537793892867273, -0.0699616283475108, 0.0498080244641435,\n",
            "        -0.30667904920932115, -0.2563830976432079, 0.25640476977057597,\n",
            "        0.40005888980456716, -0.1599062955761008, 0.16401413309326077,\n",
            "        0.32976261768791687, 0.33727491826121836, -0.34693104905834976,\n",
            "        -0.3943106921827356, -0.2813473461571618, 0.323319094918923,\n",
            "        -0.3424293854921663, -0.0673823654123799]], dtype=object), 'b': array([[0.006707236758404914]], dtype=object)}]\n"
          ]
        }
      ],
      "source": [
        "pred_test = predict(X_test, None, model, 2)\n",
        "print(pred_test, len(pred_test))\n",
        "output[\"basic_pred_test\"] = pred_test[0].astype(int)\n",
        "\n",
        "basic_model_layers = []\n",
        "basic_model_parameters = []\n",
        "for layer in model.layers:\n",
        "    basic_model_layers.append(layer.name)\n",
        "    if(layer.name==\"conv\" or layer.name==\"dense\" or layer.name==\"maxpool\"):\n",
        "        basic_model_parameters.append(layer.parameters)\n",
        "print(basic_model_layers, basic_model_parameters)\n",
        "output[\"basic_model_layers\"] = basic_model_layers\n",
        "output[\"basic_model_parameters\"] = basic_model_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrrYp1RwSIOh"
      },
      "source": [
        "# 8. Advanced implementation\n",
        "In this part, you will practice how to build a model by **Tensorflow**, and you finally can use GPU to accelerate the training process☺️. You can import any packages in the advanced part.\n",
        "\n",
        "**Exercise**: Implement a binary classifier by Tensorflow. You will get 15% if your prediction achieves accuracy greater than 0.7 in testing data. The rest 10% will be graded by your rank.\n",
        "\n",
        "Except you have to build the model by Tensorflow, there is no limitation in this part. You can try different model architectures, optimization parametes and image augmentation methods to get good performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.applications import ResNet152V2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from cv2 import imread, IMREAD_GRAYSCALE # IMREAD_GRAYSCALE allow you to load the image as gray scale image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 32, 32, 1) (120, 32, 32, 1)\n",
            "(1440, 32, 32, 1) (1440, 1)\n",
            "(120, 2) (1920, 2)\n"
          ]
        }
      ],
      "source": [
        "# import some tensorflow packages to help you build the model\n",
        "# import some tensorflow packages to help you build the model\n",
        "\n",
        "# import other packages here\n",
        "# GRADED CODE: Advanced implementation\n",
        "### Data preprocess & augmentation ###\n",
        "\n",
        "PATH = \"Training_data\"  #path to your training image\n",
        "file_dir = os.listdir(PATH) #read the images from the directory\n",
        "file_dir.sort() #Make sure the images are loaded in order\n",
        "X_train = np.array([])\n",
        "for i in range(len(file_dir)):\n",
        "    if (i != 0):\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[i], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_train = np.concatenate([X_train, img_gray], axis=0)\n",
        "    else:\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[0], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_train = img_gray\n",
        "X_train = np.divide(X_train, 255)\n",
        "\n",
        "PATH = \"Testing_data\"  #path to your testing image\n",
        "file_dir = os.listdir(PATH)\n",
        "file_dir.sort()\n",
        "X_test = np.array([])\n",
        "\n",
        "for i in range(0, len(file_dir)):\n",
        "    if (i != 0):\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[i], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_test = np.concatenate([X_test, img_gray], axis=0)\n",
        "    else:\n",
        "        img_gray = imread(PATH+\"/\"+file_dir[0], IMREAD_GRAYSCALE)\n",
        "        img_gray = img_gray.reshape(1, img_gray.shape[0], img_gray.shape[1], 1)\n",
        "        X_test = img_gray\n",
        "\n",
        "X_test = np.divide(X_test, 255)\n",
        "\n",
        "data = read_csv(\"Training_label.csv\")\n",
        "\n",
        "y_train = []\n",
        "data = data.values\n",
        "y_train = data[:, 1].reshape(data[:, 1].shape[0], 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "print(X_train.shape, X_val.shape)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=35,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=False,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "X_train_aug, y_train_aug = [], []\n",
        "\n",
        "i = 0\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=3):\n",
        "    i += 1\n",
        "    if i > 480:\n",
        "        break \n",
        "    if (len(X_train_aug) != 0):\n",
        "        X_train_aug = np.concatenate([X_train_aug, X_batch], axis=0)\n",
        "        y_train_aug = np.concatenate([y_train_aug, y_batch], axis=0)\n",
        "\n",
        "    else:\n",
        "        X_train_aug = X_batch\n",
        "        y_train_aug = y_batch\n",
        "\n",
        "print(X_train_aug.shape, y_train_aug.shape)\n",
        "\n",
        "X_train = np.concatenate([X_train, X_train_aug], axis=0)\n",
        "y_train = np.concatenate([y_train, y_train_aug], axis=0)\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train)\n",
        "y_train=np.asarray(y_train).astype(int)\n",
        "y_train = tf.convert_to_tensor(y_train)\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
        "\n",
        "X_val = tf.convert_to_tensor(X_val)\n",
        "y_val=np.asarray(y_val).astype(int)\n",
        "y_val = tf.convert_to_tensor(y_val)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, 2)\n",
        "\n",
        "print(y_val.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PDyxdy9Jk982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 2.9999999999999997e-05.\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5031\n",
            "Epoch 1: val_accuracy improved from -inf to 0.42500, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 16s 174ms/step - loss: 0.6933 - accuracy: 0.5031 - val_loss: 0.6962 - val_accuracy: 0.4250 - lr: 3.0000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 5.9999999999999995e-05.\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5229\n",
            "Epoch 2: val_accuracy did not improve from 0.42500\n",
            "60/60 [==============================] - 9s 144ms/step - loss: 0.6918 - accuracy: 0.5229 - val_loss: 0.7003 - val_accuracy: 0.4250 - lr: 6.0000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 8.999999999999999e-05.\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5156\n",
            "Epoch 3: val_accuracy did not improve from 0.42500\n",
            "60/60 [==============================] - 8s 129ms/step - loss: 0.6916 - accuracy: 0.5156 - val_loss: 0.6993 - val_accuracy: 0.4250 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00011999999999999999.\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.5802\n",
            "Epoch 4: val_accuracy improved from 0.42500 to 0.69167, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 7s 119ms/step - loss: 0.6721 - accuracy: 0.5802 - val_loss: 0.5978 - val_accuracy: 0.6917 - lr: 1.2000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.00015.\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.6448\n",
            "Epoch 5: val_accuracy improved from 0.69167 to 0.73333, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 14s 236ms/step - loss: 0.6337 - accuracy: 0.6448 - val_loss: 0.5832 - val_accuracy: 0.7333 - lr: 1.5000e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.00014894713456638578.\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.6859\n",
            "Epoch 6: val_accuracy improved from 0.73333 to 0.76667, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 8s 137ms/step - loss: 0.5954 - accuracy: 0.6859 - val_loss: 0.5386 - val_accuracy: 0.7667 - lr: 1.4895e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0001479008166865959.\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.7063\n",
            "Epoch 7: val_accuracy improved from 0.76667 to 0.81667, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 7s 117ms/step - loss: 0.5830 - accuracy: 0.7063 - val_loss: 0.4876 - val_accuracy: 0.8167 - lr: 1.4790e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00014686102671131215.\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5526 - accuracy: 0.7292\n",
            "Epoch 8: val_accuracy did not improve from 0.81667\n",
            "60/60 [==============================] - 7s 116ms/step - loss: 0.5526 - accuracy: 0.7292 - val_loss: 0.4950 - val_accuracy: 0.8167 - lr: 1.4686e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0001458277211882303.\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7292\n",
            "Epoch 9: val_accuracy did not improve from 0.81667\n",
            "60/60 [==============================] - 7s 116ms/step - loss: 0.5482 - accuracy: 0.7292 - val_loss: 0.5282 - val_accuracy: 0.7833 - lr: 1.4583e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00014480087112675268.\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.7406\n",
            "Epoch 10: val_accuracy did not improve from 0.81667\n",
            "60/60 [==============================] - 7s 116ms/step - loss: 0.5437 - accuracy: 0.7406 - val_loss: 0.4838 - val_accuracy: 0.8083 - lr: 1.4480e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00014378043307573191.\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.7406\n",
            "Epoch 11: val_accuracy did not improve from 0.81667\n",
            "60/60 [==============================] - 7s 118ms/step - loss: 0.5374 - accuracy: 0.7406 - val_loss: 0.5135 - val_accuracy: 0.8000 - lr: 1.4378e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.00014276637804556738.\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.7609\n",
            "Epoch 12: val_accuracy did not improve from 0.81667\n",
            "60/60 [==============================] - 7s 125ms/step - loss: 0.5209 - accuracy: 0.7609 - val_loss: 0.5015 - val_accuracy: 0.8000 - lr: 1.4277e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00014175867704703692.\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.7563\n",
            "Epoch 13: val_accuracy improved from 0.81667 to 0.83333, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 10s 172ms/step - loss: 0.5111 - accuracy: 0.7563 - val_loss: 0.4955 - val_accuracy: 0.8333 - lr: 1.4176e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0001407572866306188.\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.7625\n",
            "Epoch 14: val_accuracy did not improve from 0.83333\n",
            "60/60 [==============================] - 9s 148ms/step - loss: 0.5090 - accuracy: 0.7625 - val_loss: 0.5112 - val_accuracy: 0.7917 - lr: 1.4076e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.00013976217780809782.\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.7682\n",
            "Epoch 15: val_accuracy did not improve from 0.83333\n",
            "60/60 [==============================] - 9s 145ms/step - loss: 0.5041 - accuracy: 0.7682 - val_loss: 0.4725 - val_accuracy: 0.8250 - lr: 1.3976e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0001387733215916418.\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7693\n",
            "Epoch 16: val_accuracy did not improve from 0.83333\n",
            "60/60 [==============================] - 7s 114ms/step - loss: 0.5042 - accuracy: 0.7693 - val_loss: 0.4937 - val_accuracy: 0.8333 - lr: 1.3877e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.00013779067453337.\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.7807\n",
            "Epoch 17: val_accuracy did not improve from 0.83333\n",
            "60/60 [==============================] - 7s 123ms/step - loss: 0.4902 - accuracy: 0.7807 - val_loss: 0.4779 - val_accuracy: 0.8167 - lr: 1.3779e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.00013681420764646718.\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.7734\n",
            "Epoch 18: val_accuracy did not improve from 0.83333\n",
            "60/60 [==============================] - 7s 122ms/step - loss: 0.4903 - accuracy: 0.7734 - val_loss: 0.4866 - val_accuracy: 0.8167 - lr: 1.3681e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.00013584389194450593.\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.7693\n",
            "Epoch 19: val_accuracy improved from 0.83333 to 0.84167, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 7s 119ms/step - loss: 0.4919 - accuracy: 0.7693 - val_loss: 0.4779 - val_accuracy: 0.8417 - lr: 1.3584e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.00013487968398126168.\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.7792\n",
            "Epoch 20: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 8s 131ms/step - loss: 0.4849 - accuracy: 0.7792 - val_loss: 0.4682 - val_accuracy: 0.8333 - lr: 1.3488e-04\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.00013392155477133394.\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.7844\n",
            "Epoch 21: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 8s 139ms/step - loss: 0.4765 - accuracy: 0.7844 - val_loss: 0.4904 - val_accuracy: 0.8000 - lr: 1.3392e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.00013296947532971464.\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.7865\n",
            "Epoch 22: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 8s 134ms/step - loss: 0.4756 - accuracy: 0.7865 - val_loss: 0.4812 - val_accuracy: 0.8250 - lr: 1.3297e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.00013202341667178965.\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.7760\n",
            "Epoch 23: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 101ms/step - loss: 0.4809 - accuracy: 0.7760 - val_loss: 0.4713 - val_accuracy: 0.8083 - lr: 1.3202e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.00013108333535348393.\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.7927\n",
            "Epoch 24: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 0.4658 - accuracy: 0.7927 - val_loss: 0.4861 - val_accuracy: 0.8083 - lr: 1.3108e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00013014920239122344.\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.7833\n",
            "Epoch 25: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 0.4709 - accuracy: 0.7833 - val_loss: 0.4935 - val_accuracy: 0.8167 - lr: 1.3015e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.00012922098880183274.\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.7927\n",
            "Epoch 26: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 0.4668 - accuracy: 0.7927 - val_loss: 0.4675 - val_accuracy: 0.8250 - lr: 1.2922e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.00012829866560253652.\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7974\n",
            "Epoch 27: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 105ms/step - loss: 0.4551 - accuracy: 0.7974 - val_loss: 0.4745 - val_accuracy: 0.8167 - lr: 1.2830e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00012738218935143584.\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.7943\n",
            "Epoch 28: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 103ms/step - loss: 0.4439 - accuracy: 0.7943 - val_loss: 0.4760 - val_accuracy: 0.8083 - lr: 1.2738e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0001264715310668087.\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7948\n",
            "Epoch 29: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 100ms/step - loss: 0.4563 - accuracy: 0.7948 - val_loss: 0.4702 - val_accuracy: 0.8333 - lr: 1.2647e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0001255666617673379.\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4428 - accuracy: 0.8047\n",
            "Epoch 30: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 102ms/step - loss: 0.4428 - accuracy: 0.8047 - val_loss: 0.4635 - val_accuracy: 0.8333 - lr: 1.2557e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0001246675524721126.\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8026\n",
            "Epoch 31: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.4407 - accuracy: 0.8026 - val_loss: 0.4775 - val_accuracy: 0.8167 - lr: 1.2467e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00012377417420062967.\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8026\n",
            "Epoch 32: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 106ms/step - loss: 0.4422 - accuracy: 0.8026 - val_loss: 0.4757 - val_accuracy: 0.8250 - lr: 1.2377e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00012288648351368542.\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8078\n",
            "Epoch 33: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.4319 - accuracy: 0.8078 - val_loss: 0.4583 - val_accuracy: 0.8250 - lr: 1.2289e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.00012200446589087302.\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8094\n",
            "Epoch 34: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.4256 - accuracy: 0.8094 - val_loss: 0.4728 - val_accuracy: 0.8417 - lr: 1.2200e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.00012112807789397841.\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.8083\n",
            "Epoch 35: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 99ms/step - loss: 0.4248 - accuracy: 0.8083 - val_loss: 0.4771 - val_accuracy: 0.8167 - lr: 1.2113e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00012025729054439458.\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8073\n",
            "Epoch 36: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.4296 - accuracy: 0.8073 - val_loss: 0.4737 - val_accuracy: 0.8167 - lr: 1.2026e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.00011939207486393001.\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4166 - accuracy: 0.8161\n",
            "Epoch 37: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.4166 - accuracy: 0.8161 - val_loss: 0.4656 - val_accuracy: 0.8250 - lr: 1.1939e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.00011853240187481015.\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4232 - accuracy: 0.8078\n",
            "Epoch 38: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.4232 - accuracy: 0.8078 - val_loss: 0.4799 - val_accuracy: 0.8000 - lr: 1.1853e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.00011767823537037421.\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8151\n",
            "Epoch 39: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.4169 - accuracy: 0.8151 - val_loss: 0.4672 - val_accuracy: 0.8417 - lr: 1.1768e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.00011682955360307433.\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8062\n",
            "Epoch 40: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.4080 - accuracy: 0.8062 - val_loss: 0.4734 - val_accuracy: 0.8417 - lr: 1.1683e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.00011598632036717484.\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8198\n",
            "Epoch 41: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.3993 - accuracy: 0.8198 - val_loss: 0.4834 - val_accuracy: 0.8250 - lr: 1.1599e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.00011514849945753051.\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8229\n",
            "Epoch 42: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.4041 - accuracy: 0.8229 - val_loss: 0.5141 - val_accuracy: 0.7917 - lr: 1.1515e-04\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.00011431606912786266.\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8333\n",
            "Epoch 43: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.3882 - accuracy: 0.8333 - val_loss: 0.4646 - val_accuracy: 0.8167 - lr: 1.1432e-04\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.00011348900040305584.\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8214\n",
            "Epoch 44: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.3982 - accuracy: 0.8214 - val_loss: 0.4702 - val_accuracy: 0.8167 - lr: 1.1349e-04\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.00011266725707936888.\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8250\n",
            "Epoch 45: val_accuracy did not improve from 0.84167\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.3905 - accuracy: 0.8250 - val_loss: 0.4563 - val_accuracy: 0.8083 - lr: 1.1267e-04\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.00011185081741168007.\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.8323\n",
            "Epoch 46: val_accuracy improved from 0.84167 to 0.85000, saving model to weights.best.hdf5\n",
            "60/60 [==============================] - 6s 98ms/step - loss: 0.3899 - accuracy: 0.8323 - val_loss: 0.4619 - val_accuracy: 0.8500 - lr: 1.1185e-04\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.00011103964519719194.\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8302\n",
            "Epoch 47: val_accuracy did not improve from 0.85000\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.3830 - accuracy: 0.8302 - val_loss: 0.4729 - val_accuracy: 0.8250 - lr: 1.1104e-04\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.00011023371869156138.\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8427\n",
            "Epoch 48: val_accuracy did not improve from 0.85000\n",
            "60/60 [==============================] - 6s 97ms/step - loss: 0.3700 - accuracy: 0.8427 - val_loss: 0.4885 - val_accuracy: 0.7833 - lr: 1.1023e-04\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.00010943300169294066.\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8432\n",
            "Epoch 49: val_accuracy did not improve from 0.85000\n",
            "60/60 [==============================] - 6s 95ms/step - loss: 0.3554 - accuracy: 0.8432 - val_loss: 0.5016 - val_accuracy: 0.7833 - lr: 1.0943e-04\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.00010863746522892839.\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.8370\n",
            "Epoch 50: val_accuracy did not improve from 0.85000\n",
            "60/60 [==============================] - 6s 96ms/step - loss: 0.3698 - accuracy: 0.8370 - val_loss: 0.4720 - val_accuracy: 0.8000 - lr: 1.0864e-04\n",
            "time cost 350.12228512763977 s\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiyElEQVR4nO3deVwU9f8H8NfsAst9KLKAAt63oqISopmJgpq3ZeZJauVtaKWVeFQeaWqeKHlXapb3QSqKieItah4oKofJISggINfu/P7w59Z+QeVaBtjX8/GYR+zMZz77nnlQvJrPZ2YEURRFEBEREekRmdQFEBEREZU1BiAiIiLSOwxAREREpHcYgIiIiEjvMAARERGR3mEAIiIiIr3DAERERER6hwGIiIiI9A4DEBEREekdBiAiKldGjBiBmjVrFmvfWbNmQRCE0i2okEpSNxGVPQYgIioUQRAKtYSEhEhdKhHRawl8FxgRFcbPP/+s9Xnz5s04cuQItmzZorW+S5cuUCqVxf6e3NxcqNVqKBSKIu+bl5eHvLw8GBsbF/v7i2vEiBEICQlBVFRUmX83ERWdgdQFEFHFMGTIEK3PZ86cwZEjR/Kt/1+ZmZkwNTUt9PcYGhoWqz4AMDAwgIEB/7NGRK/HITAiKjVvvfUWmjZtiosXL+LNN9+EqakpvvzySwDAnj170KNHDzg6OkKhUKBOnTr45ptvoFKptPr437k0UVFREAQBixYtwtq1a1GnTh0oFAq0adMG58+f19q3oDlAgiBg/Pjx2L17N5o2bQqFQoEmTZogKCgoX/0hISFo3bo1jI2NUadOHaxZs6ZE84oyMjIwZcoUODk5QaFQoEGDBli0aBH+98L7kSNH0L59e1hbW8Pc3BwNGjTQnLcXli9fjiZNmsDU1BQ2NjZo3bo1fv3112LVRUS8AkREpSw5ORndunXD+++/jyFDhmiGwzZu3Ahzc3P4+fnB3Nwcx44dg7+/P9LS0rBw4cLX9vvrr7/i6dOn+PjjjyEIAr7//nv069cP9+7de+1Vo9DQUOzcuRNjx46FhYUFli1bhv79+yMmJgZVq1YFAFy+fBk+Pj5wcHDA7NmzoVKpMGfOHFSrVq1Y50EURfTq1QvHjx/HyJEj0aJFC/z555/47LPP8M8//2DJkiUAgOvXr+Odd95B8+bNMWfOHCgUCkRGRuLUqVOavgIDAzFx4kQMGDAAkyZNQlZWFq5evYqzZ8/igw8+KFZ9RHpPJCIqhnHjxon/+5+Qjh07igDEgICAfO0zMzPzrfv4449FU1NTMSsrS7Nu+PDhoouLi+bz/fv3RQBi1apVxcePH2vW79mzRwQg7tu3T7Nu5syZ+WoCIBoZGYmRkZGadVeuXBEBiMuXL9es69mzp2hqair+888/mnV37twRDQwM8vVZkP+te/fu3SIA8dtvv9VqN2DAAFEQBE09S5YsEQGIjx49emnfvXv3Fps0afLaGoio8DgERkSlSqFQwNfXN996ExMTzc9Pnz5FUlISOnTogMzMTNy6deu1/Q4cOBA2Njaazx06dAAA3Lt377X7enl5oU6dOprPzZs3h6WlpWZflUqFo0ePok+fPnB0dNS0q1u3Lrp16/ba/gty8OBByOVyTJw4UWv9lClTIIoiDh06BACwtrYG8HyIUK1WF9iXtbU1Hjx4kG/Ij4iKjwGIiEpV9erVYWRklG/99evX0bdvX1hZWcHS0hLVqlXTTKBOTU19bb/Ozs5an1+EoSdPnhR53xf7v9g3MTERz549Q926dfO1K2hdYURHR8PR0REWFhZa6xs1aqTZDjwPdp6enhg1ahSUSiXef/99/Pbbb1ph6IsvvoC5uTnatm2LevXqYdy4cVpDZERUdAxARFSq/nul54WUlBR07NgRV65cwZw5c7Bv3z4cOXIECxYsAICXXvn4L7lcXuB6sRBP8ijJvrpmYmKCv/76C0ePHsXQoUNx9epVDBw4EF26dNFMEG/UqBEiIiKwbds2tG/fHn/88Qfat2+PmTNnSlw9UcXFAEREOhcSEoLk5GRs3LgRkyZNwjvvvAMvLy+tIS0p2dnZwdjYGJGRkfm2FbSuMFxcXPDw4UM8ffpUa/2L4T4XFxfNOplMhs6dO2Px4sW4ceMGvvvuOxw7dgzHjx/XtDEzM8PAgQOxYcMGxMTEoEePHvjuu++QlZVVrPqI9B0DEBHp3IsrMP+94pKTk4NVq1ZJVZIWuVwOLy8v7N69Gw8fPtSsj4yM1MzVKaru3btDpVJhxYoVWuuXLFkCQRA0c4seP36cb98WLVoAALKzswE8v7Puv4yMjNC4cWOIoojc3Nxi1Uek73gbPBHpXLt27WBjY4Phw4dj4sSJEAQBW7ZsKRdDUC/MmjULhw8fhqenJ8aMGaMJL02bNkV4eHiR++vZsyc6deqEr776ClFRUXB1dcXhw4exZ88eTJ48WTMpe86cOfjrr7/Qo0cPuLi4IDExEatWrUKNGjXQvn17AEDXrl1hb28PT09PKJVK3Lx5EytWrECPHj3yzTEiosJhACIinatatSr279+PKVOm4Ouvv4aNjQ2GDBmCzp07w9vbW+ryAABubm44dOgQpk6dihkzZsDJyQlz5szBzZs3C3WX2v+SyWTYu3cv/P39sX37dmzYsAE1a9bEwoULMWXKFE27Xr16ISoqCuvXr0dSUhJsbW3RsWNHzJ49G1ZWVgCAjz/+GL/88gsWL16M9PR01KhRAxMnTsTXX39dasdPpG/4LjAiolfo06cPrl+/jjt37khdChGVIs4BIiL6f8+ePdP6fOfOHRw8eBBvvfWWNAURkc7wChAR0f9zcHDAiBEjULt2bURHR2P16tXIzs7G5cuXUa9ePanLI6JSxDlARET/z8fHB1u3bkV8fDwUCgU8PDwwd+5chh+iSohXgIiIiEjvcA4QERER6R0GICIiItI7nANUALVajYcPH8LCwgKCIEhdDhERERWCKIp4+vQpHB0dIZO9+hoPA1ABHj58CCcnJ6nLICIiomKIjY1FjRo1XtmGAagALx4tHxsbC0tLS4mrISIiosJIS0uDk5NToV4RwwBUgBfDXpaWlgxAREREFUxhpq9wEjQRERHpHQYgIiIi0jsMQERERKR3ysUcoJUrV2LhwoWIj4+Hq6srli9fjrZt2xbY9q233sKJEyfyre/evTsOHDgA4PltcDNnzkRgYCBSUlLg6emJ1atX83H2REQVjEqlQm5urtRlUDlhaGgIuVxeKn1JHoC2b98OPz8/BAQEwN3dHUuXLoW3tzciIiJgZ2eXr/3OnTuRk5Oj+ZycnAxXV1e8++67mnXff/89li1bhk2bNqFWrVqYMWMGvL29cePGDRgbG5fJcRERUfGJooj4+HikpKRIXQqVM9bW1rC3ty/xc/okfxeYu7s72rRpgxUrVgB4/hBCJycnTJgwAdOmTXvt/kuXLoW/vz/i4uJgZmYGURTh6OiIKVOmYOrUqQCA1NRUKJVKbNy4Ee+///5r+0xLS4OVlRVSU1N5FxgRkQTi4uKQkpICOzs7mJqa8qG0BFEUkZmZicTERFhbW8PBwSFfm6L8/Zb0ClBOTg4uXryI6dOna9bJZDJ4eXkhLCysUH2sW7cO77//PszMzAAA9+/fR3x8PLy8vDRtrKys4O7ujrCwsAIDUHZ2NrKzszWf09LSintIRERUQiqVShN+qlatKnU5VI6YmJgAABITE2FnZ1ei4TBJJ0EnJSVBpVJBqVRqrVcqlYiPj3/t/ufOncPff/+NUaNGada92K8ofc6bNw9WVlaahU+BJiKSzos5P6amphJXQuXRi9+Lks4Nq9B3ga1btw7NmjV76YTpwpo+fTpSU1M1S2xsbClVSERExcVhLypIaf1eSBqAbG1tIZfLkZCQoLU+ISEB9vb2r9w3IyMD27Ztw8iRI7XWv9ivKH0qFArNU5/59GciIqLKT9IAZGRkBDc3NwQHB2vWqdVqBAcHw8PD45X77tixA9nZ2RgyZIjW+lq1asHe3l6rz7S0NJw9e/a1fRIREZU3NWvWxNKlSwvdPiQkBIIg6PwOuo0bN8La2lqn36FLkg+B+fn5ITAwEJs2bcLNmzcxZswYZGRkwNfXFwAwbNgwrUnSL6xbtw59+vTJN0FOEARMnjwZ3377Lfbu3Ytr165h2LBhcHR0RJ8+fcrikIiISA8JgvDKZdasWcXq9/z58/joo48K3b5du3aIi4uDlZVVsb5PX0j+HKCBAwfi0aNH8Pf3R3x8PFq0aIGgoCDNJOaYmBjIZNo5LSIiAqGhoTh8+HCBfX7++efIyMjARx99hJSUFLRv3x5BQUGSPwPoUcYjPMl6gto2tWEgk/zUExFRKYqLi9P8vH37dvj7+yMiIkKzztzcXPOzKIpQqVQwMHj934Jq1aoVqQ4jI6PXTiOhcnAFCADGjx+P6OhoZGdn4+zZs3B3d9dsCwkJwcaNG7XaN2jQAKIookuXLgX2JwgC5syZg/j4eGRlZeHo0aOoX7++Lg+hUH67/hsarGgA0+9M0WRVE/T/rT++PvY1fr76My48vID0nHSpSyQiomKyt7fXLFZWVhAEQfP51q1bsLCwwKFDh+Dm5gaFQoHQ0FDcvXsXvXv3hlKphLm5Odq0aYOjR49q9fu/Q2CCIOCnn35C3759YWpqinr16mHv3r2a7f87BPZiqOrPP/9Eo0aNYG5uDh8fH63AlpeXh4kTJ8La2hpVq1bFF198geHDhxd55GT16tWoU6cOjIyM0KBBA2zZskWzTRRFzJo1C87OzlAoFHB0dMTEiRM121etWoV69erB2NgYSqUSAwYMKNJ3FxUvQ5ShpzlPYWJggmd5z3Dj0Q3ceHQjX5saljXQ0LYhbE1tYWxgDGO5MYwNjKEwUDz//P+LQq7AGzXeQEuHlhIcCRFR2RJFEZm5mWX+vaaGpfsQxmnTpmHRokWoXbs2bGxsEBsbi+7du+O7776DQqHA5s2b0bNnT0RERMDZ2fml/cyePRvff/89Fi5ciOXLl2Pw4MGIjo5GlSpVCmyfmZmJRYsWYcuWLZDJZBgyZAimTp2KX375BQCwYMEC/PLLL9iwYQMaNWqEH3/8Ebt370anTp0KfWy7du3CpEmTsHTpUnh5eWH//v3w9fVFjRo10KlTJ/zxxx9YsmQJtm3bhiZNmiA+Ph5XrlwBAFy4cAETJ07Eli1b0K5dOzx+/BgnT54swpktOgagMjSt/TR87vk5YlNjcTPpJm4l3cKtpFuanxMzEvEg7QEepD0oVH8mBia4N+ke7M15qZOIKrfM3EyYzzN/fcNSlj49HWZGZqXW35w5c7RGL6pUqQJXV1fN52+++Qa7du3C3r17MX78+Jf2M2LECAwaNAgAMHfuXCxbtgznzp2Dj49Pge1zc3MREBCAOnXqAHg+8jJnzhzN9uXLl2P69Ono27cvAGDFihU4ePBgkY5t0aJFGDFiBMaOHQvg+RzfM2fOYNGiRejUqRNiYmJgb28PLy8vGBoawtnZWfMYm5iYGJiZmeGdd96BhYUFXFxc0LKlbv8HnwGojMkEGVysXeBi7QKfutq/qI+fPcatpFuISIpAWnYasvKyNEu2Klvr51MxpxCdGo2lZ5Zivtd8iY6GiIiKonXr1lqf09PTMWvWLBw4cABxcXHIy8vDs2fPEBMT88p+mjdvrvnZzMwMlpaWSExMfGl7U1NTTfgBAAcHB0371NRUJCQkaD1TTy6Xw83NDWq1utDHdvPmzXyTtT09PfHjjz8CAN59910sXboUtWvXho+PD7p3746ePXvCwMAAXbp0gYuLi2abj4+PZohPVxiAypEqJlXQzqkd2jm1e23bfRH70GtbL6w6vwrT2k+DtbG17gskIpKIqaEp0qeX/TxJU8PS/QP84rVNL0ydOhVHjhzBokWLULduXZiYmGDAgAFaL/0uiKGhodZnQRBeGVYKal/WrwJ1cnJCREQEjh49iiNHjmDs2LFYuHAhTpw4AQsLC1y6dAkhISE4fPgw/P39MWvWLJw/f15nt9qXi0nQVHQ96vdAU7umeJrzFCvPrZS6HCIinRIEAWZGZmW+6Ppp1KdOncKIESPQt29fNGvWDPb29oiKitLpd/4vKysrKJVKnD9/XrNOpVLh0qVLReqnUaNGOHXqlNa6U6dOoXHjxprPJiYm6NmzJ5YtW4aQkBCEhYXh2rVrAAADAwN4eXnh+++/x9WrVxEVFYVjx46V4MhejVeAKiiZIMM0z2kYsmsIlp5dik89Pi31/1MhIiLdqlevHnbu3ImePXtCEATMmDGjSMNOpWXChAmYN28e6tati4YNG2L58uV48uRJkQLgZ599hvfeew8tW7aEl5cX9u3bh507d2ruatu4cSNUKhXc3d1hamqKn3/+GSYmJnBxccH+/ftx7949vPnmm7CxscHBgwehVqvRoEEDXR0yrwBVZAObDkQt61pIykzCT5d+krocIiIqosWLF8PGxgbt2rVDz5494e3tjVatWpV5HV988QUGDRqEYcOGwcPDA+bm5vD29i7S8/P69OmDH3/8EYsWLUKTJk2wZs0abNiwAW+99RYAwNraGoGBgfD09ETz5s1x9OhR7Nu3D1WrVoW1tTV27tyJt99+G40aNUJAQAC2bt2KJk2a6OiIAUEs60HACiAtLQ1WVlZITU0t9+8FC7gQgDEHxsDJ0gmREyNhJDeSuiQiohLJysrC/fv3UatWLckfYKuv1Go1GjVqhPfeew/ffPON1OVoedXvR1H+fvMKUAU3osUI2JvbIzYtFr9c/UXqcoiIqAKKjo5GYGAgbt++jWvXrmHMmDG4f/8+PvjgA6lL0xkGoArO2MAYfm/4AQAWnFoAlVolcUVERFTRyGQybNy4EW3atIGnpyeuXbuGo0ePolGjRlKXpjMMQJXAJ60/gbWxNSKSI7D71m6pyyEiogrGyckJp06dQmpqKtLS0nD69Gm8+eabUpelUwxAlYCFwgIT2k4AAMwNnVvmz3YgIiKqaBiAKomJ7hNhamiKS3GXcOTeEanLISIqMf7PHBWktH4vGIAqCVtTW3zU6vkjyOeenCtxNURExffiqcWZmWX/8lMq/178Xvzv062Lig9CrESmtJuCledX4kT0CYTFhsHDyUPqkoiIikwul8Pa2lrzripT09J9IztVTKIoIjMzE4mJibC2toZcLi9RfwxAlUgNyxoY2nwo1oevx7zQedg7aK/UJRERFYu9vT0AvPIFn6SfrK2tNb8fJcEHIRagIj0I8X/dTr6NhisaQoSIq59cRTNlM6lLIiIqNpVKhdzcXKnLoHLC0NDwlVd+ivL3m1eAKpn6VetjQOMB2HFjB+afmo9f+vHhiERUccnl8hIPdRAVhJOgK6Hp7acDALb9vQ13H9+VuBoiIqLyhwGoEmrp0BI+dX2gFtVYeHqh1OUQERGVOwxAldSLq0AbwjcgIT1B4mqIiIjKFwagSqqDcwe0sG+BHFUOjt47KnU5RERE5QoDUCUlCAI61+oMAPgr+i+JqyEiIipfGIAqsTddnr/I7q8YBiAiIqL/YgCqxNo7twcA3Eq6hcQMPkyMiIjoBQagSqyKSRU0s3v+IMTQmFCJqyEiIio/GIAqOc0wGOcBERERaTAAVXIdnDsAYAAiIiL6LwagSq6Dy/MAFB4fjtSsVImrISIiKh8YgCo5RwtH1K1SFyJEnIo9JXU5RERE5QIDkB5405nzgIiIiP6LAUgPcCI0ERGRNgYgPfAiAF14eAGZuZkSV0NERCQ9BiA9UNO6JqpbVEeuOhdnH5yVuhwiIiLJMQDpAUEQOAxGRET0HwxAeoLvBSMiIvoXA5CeeBGAwmLDkKPKkbgaIiIiaTEA6YlGto1ga2qLZ3nPcPHhRanLISIikhQDkJ4QBIGvxSAiIvp/kgeglStXombNmjA2Noa7uzvOnTv3yvYpKSkYN24cHBwcoFAoUL9+fRw8eFCzfdasWRAEQWtp2LChrg+jQngxDHYy5qTElRAREUnLQMov3759O/z8/BAQEAB3d3csXboU3t7eiIiIgJ2dXb72OTk56NKlC+zs7PD777+jevXqiI6OhrW1tVa7Jk2a4OjRo5rPBgaSHma58eIKUGhMKFRqFeQyucQVERERSUPSZLB48WKMHj0avr6+AICAgAAcOHAA69evx7Rp0/K1X79+PR4/fozTp0/D0NAQAFCzZs187QwMDGBvb6/T2isiV3tXWBhZIDU7FdcSr6GFfQupSyIiIpKEZENgOTk5uHjxIry8vP4tRiaDl5cXwsLCCtxn79698PDwwLhx46BUKtG0aVPMnTsXKpVKq92dO3fg6OiI2rVrY/DgwYiJiXllLdnZ2UhLS9NaKiMDmQE8nT0BcB4QERHpN8kCUFJSElQqFZRKpdZ6pVKJ+Pj4Ave5d+8efv/9d6hUKhw8eBAzZszADz/8gG+//VbTxt3dHRs3bkRQUBBWr16N+/fvo0OHDnj69OlLa5k3bx6srKw0i5OTU+kcZDnEF6MSERFJPARWVGq1GnZ2dli7di3kcjnc3Nzwzz//YOHChZg5cyYAoFu3bpr2zZs3h7u7O1xcXPDbb79h5MiRBfY7ffp0+Pn5aT6npaVV2hD03ydCi6IIQRAkroiIiKjsSRaAbG1tIZfLkZCQoLU+ISHhpfN3HBwcYGhoCLn838m7jRo1Qnx8PHJycmBkZJRvH2tra9SvXx+RkZEvrUWhUEChUBTzSCqW1o6tYWxgjEeZj3A7+TYa2DaQuiQiIqIyJ9kQmJGREdzc3BAcHKxZp1arERwcDA8PjwL38fT0RGRkJNRqtWbd7du34eDgUGD4AYD09HTcvXsXDg4OpXsAFZTCQIE3arwBgMNgRESkvyR9DpCfnx8CAwOxadMm3Lx5E2PGjEFGRobmrrBhw4Zh+vTpmvZjxozB48ePMWnSJNy+fRsHDhzA3LlzMW7cOE2bqVOn4sSJE4iKisLp06fRt29fyOVyDBo0qMyPr7zSPBCR7wUjIiI9JekcoIEDB+LRo0fw9/dHfHw8WrRogaCgIM3E6JiYGMhk/2Y0Jycn/Pnnn/j000/RvHlzVK9eHZMmTcIXX3yhafPgwQMMGjQIycnJqFatGtq3b48zZ86gWrVqZX585RXfDE9ERPpOEEVRlLqI8iYtLQ1WVlZITU2FpaWl1OWUuoycDFgvsEaeOg9Rk6LgYu0idUlEREQlVpS/35K/CoPKnpmRGdwc3ADwKhAREeknBiA9xWEwIiLSZwxAeoovRiUiIn3GAKSnPJ08IUBARHIEEtITXr8DERFRJcIApKdsTGzQTNkMAK8CERGR/mEA0mN8LxgREekrBiA9xonQRESkrxiA9FgHl+dPhL6acBUpWSnSFkNERFSGGID0mL25PepXrQ8RIkJjQqUuh4iIqMwwAOm5F/OATkZzIjQREekPBiA992IYjC9GJSIifcIApOdeTIS+8PACMnIyJK6GiIiobDAA6TkXKxc4WTohT52Hs/+clbocIiKiMsEApOcEQfh3GIy3wxMRkZ5gACI+EJGIiPQOAxBp5gGFPQhDjipH4mqIiIh0jwGI0NC2IWxNbZGVl4WLDy9KXQ4REZHOMQDR83lAzpwHRERE+oMBiAD8571gfB4QERHpAQYgAvBvAAqNCYVKrZK4GiIiIt1iACIAgKvSFRZGFkjLTsO1xGtSl0NERKRTDEAEAJDL5PB09gTAeUBERFT5MQCRBp8HRERE+oIBiDRezAM6GXMSoihKXA0REZHuMACRRmvH1lDIFUjMSMTt5NtSl0NERKQzDECkoTBQ4I0abwDgMBgREVVuDECkhc8DIiIifcAARFpePBH6ZPRJiSshIiLSHQYg0uLh5AG5IEd0ajSiU6KlLoeIiEgnGIBIi7mROdwc3QA8vxuMiIioMmIAonz4YlQiIqrsGIAon/8+D4iIiKgyYgCifNo7twcA3Eq6hcSMRImrISIiKn0MQJRPFZMqaGbXDADvBiMiosqJAYgKpLkdnsNgRERUCTEAUYE0D0TkRGgiIqqEGICoQB1cnl8BCo8PR2pWqsTVEBERlS4GICqQo4Uj6tjUgQgRp2JPSV0OERFRqZI8AK1cuRI1a9aEsbEx3N3dce7cuVe2T0lJwbhx4+Dg4ACFQoH69evj4MGDJeqTCqa5HZ4ToYmIqJKRNABt374dfn5+mDlzJi5dugRXV1d4e3sjMbHgW69zcnLQpUsXREVF4ffff0dERAQCAwNRvXr1YvdJL8cXoxIRUWUliKIoSvXl7u7uaNOmDVasWAEAUKvVcHJywoQJEzBt2rR87QMCArBw4ULcunULhoaGpdJnQdLS0mBlZYXU1FRYWloW8+gqvntP7qHOsjowlBkiZVoKTA1NpS6JiIjopYry91uyK0A5OTm4ePEivLy8/i1GJoOXlxfCwsIK3Gfv3r3w8PDAuHHjoFQq0bRpU8ydOxcqlarYfdLL1bKuBUcLR+Sqc3H2wVmpyyEiIio1kgWgpKQkqFQqKJVKrfVKpRLx8fEF7nPv3j38/vvvUKlUOHjwIGbMmIEffvgB3377bbH7BIDs7GykpaVpLQQIgsDXYhARUaUk+SToolCr1bCzs8PatWvh5uaGgQMH4quvvkJAQECJ+p03bx6srKw0i5OTUylVXPG96cznARERUeUjWQCytbWFXC5HQkKC1vqEhATY29sXuI+DgwPq168PuVyuWdeoUSPEx8cjJyenWH0CwPTp05GamqpZYmNjS3BklcuL5wGFPQhDripX4mqIiIhKh2QByMjICG5ubggODtasU6vVCA4OhoeHR4H7eHp6IjIyEmq1WrPu9u3bcHBwgJGRUbH6BACFQgFLS0uthZ5rXK0xqphUQWZuJi7FXZK6HCIiolIh6RCYn58fAgMDsWnTJty8eRNjxoxBRkYGfH19AQDDhg3D9OnTNe3HjBmDx48fY9KkSbh9+zYOHDiAuXPnYty4cYXuk4pGJsg07wULiQqRthgiIqJSYiDllw8cOBCPHj2Cv78/4uPj0aJFCwQFBWkmMcfExEAm+zejOTk54c8//8Snn36K5s2bo3r16pg0aRK++OKLQvdJRde5VmfsidiDRWGLMKT5EFS3rP76nYiIiMoxSZ8DVF7xOUDasvKy4LHOA+Hx4ejg3AHHhh+DgUzS7ExERJRPhXgOEFUcxgbG+G3Ab7AwssDJmJOYeXym1CURERGVCAMQFUq9qvUQ2DMQADA3dC7+jPxT4oqIiIiKjwGICm1g04H4xO0TAMCQXUPwT9o/EldERERUPAxAVCRLfJbAVemKpMwkfLDzA+Sp86QuiYiIqMgYgKhIjA2MsePdHTA3Msdf0X9hVsgsqUsiIiIqMgYgKjKt+UAn5+Lw3cMSV0RERFQ0DEBULO83fR8fu30MESKG7ByCh08fSl0SERFRoTEAUbEt8X4+H+hR5iN88AfnAxERUcXBAETFZmJogt/e/Q3mRuY4EX0Cc07MkbokIiKiQmEAohKpX7U+1r6zFgDw7V/f4sjdIxJXRERE9HoMQFRig5oNwketPoIIEZP/nCx1OURERK/FAESl4vsu38NQZogbj27gdvJtqcshIiJ6JQYgKhVWxlZ4q+ZbAIB9EfukLYaIiOg1GICo1PRq0AsAsPf2XokrISIiejUGICo1Pev3BACExoQiOTNZ4mqIiIhejgGISo2LtQtcla5Qi2ocvHNQ6nKIiIheigGIShWHwYiIqCJgAKJS9SIABUUGITsvW+JqiIiICsYARKWqlUMrOFo4Ij0nHSFRIVKXQ0REVCAGICpVMkGmmQy9N4LDYEREVD4xAFGp++88IFEUJa6GiIgoPwYgKnVv13obpoameJD2AOHx4VKXQ0RElA8DEJU6YwNjeNfxBsBhMCIiKp8YgEgneDs8ERGVZwxApBM96vWAAAGX4i7hQdoDqcshIiLSwgBEOlHNrBraObUDwGEwIiIqfxiASGc0w2AMQEREVM4wAJHOvAhAx+4fQ1p2msTVEBER/YsBiHSmQdUGqFelHnLVuTh897DU5RAREWkwAJHOCILAYTAiIiqXGIBIp14EoAN3DiBPnSdxNURERM8xAJFOtXNqh6omVfH42WOcjj0tdTlEREQAGIBIxwxkBuhRvwcADoMREVH5wQBEOter/vNhsD0Re/hyVCIiKhcYgEjnutbpCiO5ESIfRyIiOULqcoiIiBiASPcsFBZ4u9bbADgMRkRE5QMDEJWJF8NgDEBERFQeMABRmejZoCcA4HTsaTzKeCRxNUREpO8YgKhM1LCsgVYOrSBCxIE7B6Quh4iI9Fy5CEArV65EzZo1YWxsDHd3d5w7d+6lbTdu3AhBELQWY2NjrTYjRozI18bHx0fXh0GvwWEwIiIqLyQPQNu3b4efnx9mzpyJS5cuwdXVFd7e3khMTHzpPpaWloiLi9Ms0dHR+dr4+Photdm6dasuD4MK4cVTofdE7MHQXUNx49ENiSsiIiJ9JXkAWrx4MUaPHg1fX180btwYAQEBMDU1xfr161+6jyAIsLe31yxKpTJfG4VCodXGxsZGl4dBhdDCvgV8W/hCLarx89Wf0XRVU/T/rT8uxV2SujQiItIzkgagnJwcXLx4EV5eXpp1MpkMXl5eCAsLe+l+6enpcHFxgZOTE3r37o3r16/naxMSEgI7Ozs0aNAAY8aMQXJy8kv7y87ORlpamtZCpU8QBKzvvR4XRl9Av0b9IELEzps74bbWDd1+6YbQmFCpSyQiIj0haQBKSkqCSqXKdwVHqVQiPj6+wH0aNGiA9evXY8+ePfj555+hVqvRrl07PHjwQNPGx8cHmzdvRnBwMBYsWIATJ06gW7duUKlUBfY5b948WFlZaRYnJ6fSO0jKx83RDX+89wf+HvM3BjcbDJkgQ1BkEDps6ICOGzvi8N3DfGI0ERHplCBK+Jfm4cOHqF69Ok6fPg0PDw/N+s8//xwnTpzA2bNnX9tHbm4uGjVqhEGDBuGbb74psM29e/dQp04dHD16FJ07d863PTs7G9nZ2ZrPaWlpcHJyQmpqKiwtLYtxZFQUdx/fxYJTC7AxfCNy1bkAgDaObfD1m1+jZ/2eEARB4gqJiKgiSEtLg5WVVaH+fkt6BcjW1hZyuRwJCQla6xMSEmBvb1+oPgwNDdGyZUtERka+tE3t2rVha2v70jYKhQKWlpZaC5WdOlXqYG3Ptbg36R4muU+CiYEJzj88j97beqPlmpb4/cbvUItqqcskIqJKRNIAZGRkBDc3NwQHB2vWqdVqBAcHa10RehWVSoVr167BwcHhpW0ePHiA5OTkV7Yh6dWwrIGlPksRNTkK0zynwdzIHFcSruDdHe+i6aqm+OXqL8hT50ldJhERVQKS3wXm5+eHwMBAbNq0CTdv3sSYMWOQkZEBX19fAMCwYcMwffp0Tfs5c+bg8OHDuHfvHi5duoQhQ4YgOjoao0aNAvB8gvRnn32GM2fOICoqCsHBwejduzfq1q0Lb29vSY6RisbOzA7zvOYhenI0/N/0h5XCCjeTbmLIriFotLIRNlzegFxVrtRlEhFRBSZ5ABo4cCAWLVoEf39/tGjRAuHh4QgKCtJMjI6JiUFcXJym/ZMnTzB69Gg0atQI3bt3R1paGk6fPo3GjRsDAORyOa5evYpevXqhfv36GDlyJNzc3HDy5EkoFApJjpGKp4pJFczuNBvRk6Px3dvfoapJVUQ+jsSHez9EveX1EHAhgFeEiIioWCSdBF1eFWUSFZWd9Jx0rLmwBgtPL0RCxvN5Y60dW2NTn01oXK2xxNUREZHUKswkaKKiMDcyx5R2U3B/0n0s81kGa2NrXHh4Aa3WtMKi04ugUhf8mAMiIqL/xQBEFY6JoQkmuE/A9bHX0b1ed2SrsvHZkc/w5sY3cSf5jtTlERFRBcAARBWWo4Uj9g/aj596/gQLIwucjj0N1wBXLD+7nLfNExHRKzEAUYUmCAJGthqJa2OuoXOtzniW9wwTgybCa7MXolKipC6PiIjKKQYgqhRcrF1weOhhrOy+EqaGpjgedRzNVjdD4MVAvlaDiIjyYQCiSkMmyDC2zVhc+eQK2ju3R3pOOj7a/xG+Pva11KUREVE5wwBElU7dKnURMjwE8zvPBwAsPL0Qdx/flbgqIiIqT4oVgGJjY7Xevn7u3DlMnjwZa9euLbXCiEpCLpPji/ZfwLuON3LVufji6BdSl0REROVIsQLQBx98gOPHjwMA4uPj0aVLF5w7dw5fffUV5syZU6oFEpXEoq6LIBNk+OPmHzgZfVLqcoiIqJwoVgD6+++/0bZtWwDAb7/9hqZNm+L06dP45ZdfsHHjxtKsj6hEmto1xehWowEAUw5P4e3xREQEoJgBKDc3V/NeraNHj6JXr14AgIYNG2q9t4uoPJj91mxYGFng/MPz2Hptq9TlEBFROVCsANSkSRMEBATg5MmTOHLkCHx8fAAADx8+RNWqVUu1QKKSUporMb39dADAtOBpyMzNlLgiIiKSWrEC0IIFC7BmzRq89dZbGDRoEFxdXQEAe/fu1QyNEZUnk9+YDGcrZzxIe4AlYUukLoeIiCRW7LfBq1QqpKWlwcbGRrMuKioKpqamsLOzK7UCpcC3wVdOW69txQc7P4C5kTnuTLgDe3N7qUsiIqJSpPO3wT979gzZ2dma8BMdHY2lS5ciIiKiwocfqrzeb/o+3Ku7Iz0nHf7H/aUuh4iIJFSsANS7d29s3rwZAJCSkgJ3d3f88MMP6NOnD1avXl2qBRKVFkEQsNh7MQBg3eV1uJpwVeKKiIhIKsUKQJcuXUKHDh0AAL///juUSiWio6OxefNmLFu2rFQLJCpN7Zza4d3G70ItqjHl8BS+J4yISE8VKwBlZmbCwsICAHD48GH069cPMpkMb7zxBqKjo0u1QKLSNt9rPozkRjh67ygORR6SuhwiIpJAsQJQ3bp1sXv3bsTGxuLPP/9E165dAQCJiYmcNEzlXm2b2pjkPgkAMPXwVOSp8ySuiIiIylqxApC/vz+mTp2KmjVrom3btvDw8ADw/GpQy5YtS7VAIl34ssOXqGpSFTeTbiLwYqDU5RARURkr9m3w8fHxiIuLg6urK2Sy5znq3LlzsLS0RMOGDUu1yLLG2+D1w8pzKzH+0HjYmtoickIkrIytpC6JiIhKQOe3wQOAvb09WrZsiYcPH2reDN+2bdsKH35If3zk9hEa2jZEUmYSZp+YLXU5RERUhooVgNRqNebMmQMrKyu4uLjAxcUF1tbW+Oabb6BW82WTVDEYyg2xqMsiAMCSM0sQcCFA4oqIiKisFCsAffXVV1ixYgXmz5+Py5cv4/Lly5g7dy6WL1+OGTNmlHaNRDrTo34PfNn+SwDA2ANj8eu1XyWuiIiIykKx5gA5OjoiICBA8xb4F/bs2YOxY8fin3/+KbUCpcA5QPpFFEVMPDQRK86vgFyQY+fAnejVoNfrdyQionJF53OAHj9+XOBcn4YNG+Lx48fF6ZJIMoIg4MduP2KY6zCoRBXe2/Eejt0/JnVZRESkQ8UKQK6urlixYkW+9StWrEDz5s1LXBRRWZMJMqzrtQ59GvZBtiobvbb2wtkHZ6Uui4iIdKRYQ2AnTpxAjx494OzsrHkGUFhYGGJjY3Hw4EHNazIqKg6B6a/svGy8s/UdHL13FDbGNggZEYLmSoZ6IqKKQOdDYB07dsTt27fRt29fpKSkICUlBf369cP169exZcuWYhVNVB4oDBTYPXA3PGp44EnWE3Td0hV3ku9IXRYREZWyYj8IsSBXrlxBq1atoFKpSqtLSfAKEKVkpeCtjW/hSsIVOFs5I9Q3FE5WTlKXRUREr1AmD0Ikqsysja1xeOhh1K9aHzGpMfDa4oXEjESpyyIiolLCAET0EnZmdjg69CicrZxxO/k2WgS0wJCdQ7Dq/CpcjrvMl6gSEVVgHAIrAIfA6L/uJN9Bp02d8M9T7edbmRmaoW31tvCo4YF2Tu3wRo03UNW0qkRVEhFRUf5+FykA9evX75XbU1JScOLECQYgqnQycjJwKvYUwmLDcPrBaZx5cAZp2Wn52rkqXfFVh68woPEACIIgQaVERPpLZwHI19e3UO02bNhQ2C7LJQYgeh21qMaNRzc0gSgsNgwRyRGa7W4ObpjvNR9etb0krJKISL/oLADpCwYgKo6kzCSsOLcCP4T9gPScdACAV20vzO88H26ObhJXR0RU+fEuMCIJ2JraYtZbs3B34l1MbDsRhjJDHL13FK0DW+O9He/hdvJtqUskIqL/xytABeAVICoNUSlR8D/uj5+v/gwRIuSCHCNbjsTMt2bC0cIRalENlVqFPHUe8tR5UIn//iwTZKhmWo3ziIiIioBDYCXEAESl6WrCVXx17Cvsv71fs06AABGv/lfvs3af4fsu3+u6PCKiSqPCDYGtXLkSNWvWhLGxMdzd3XHu3LmXtt24cSMEQdBajI2NtdqIogh/f384ODjAxMQEXl5euHOHrzMgaTRXNse+Qfvw14i/0M6pHQC8MvwIeH7VZ9HpRQiNCS2TGomI9I2B1AVs374dfn5+CAgIgLu7O5YuXQpvb29ERETAzs6uwH0sLS0REfHvHTf/O0zw/fffY9myZdi0aRNq1aqFGTNmwNvbGzdu3MgXlojKSgeXDgj1DcWjzEdQi2oYyAxgIDOAXJD/+7NMDpkgw8g9I7E+fD0+3PMhwj8Jh6mhqdTlExFVKpJfAVq8eDFGjx4NX19fNG7cGAEBATA1NcX69etfuo8gCLC3t9csSqVSs00URSxduhRff/01evfujebNm2Pz5s14+PAhdu/eXQZHRPRygiDAzswO9ub2sDW1hbWxNSwUFjAxNIGh3BAy4fm/kj94/4DqFtVx5/Ed+B/3l7hqIqLKR9IAlJOTg4sXL8LL699npchkMnh5eSEsLOyl+6Wnp8PFxQVOTk7o3bs3rl+/rtl2//59xMfHa/VpZWUFd3f3l/aZnZ2NtLQ0rYVIStbG1ljbcy0AYMmZJQiLffm/D0REVHSSBqCkpCSoVCqtKzgAoFQqER8fX+A+DRo0wPr167Fnzx78/PPPUKvVaNeuHR48eAAAmv2K0ue8efNgZWWlWZyc+NZvkl73et0xzHUY1KIaH+79EFl5WVKXRERUaUg+BFZUHh4eGDZsGFq0aIGOHTti586dqFatGtasWVPsPqdPn47U1FTNEhsbW4oVExXfEu8lsDe3x62kW5gVMkvqcoiIKg1JA5CtrS3kcjkSEhK01ickJMDe3r5QfRgaGqJly5aIjIwEAM1+RelToVDA0tJSayEqD6qYVEFAjwAAwMLTC3H+n/MSV0REVDlIGoCMjIzg5uaG4OBgzTq1Wo3g4GB4eHgUqg+VSoVr167BwcEBAFCrVi3Y29tr9ZmWloazZ88Wuk+i8qR3w94Y1HQQ1KIavnt8kZ2XLXVJREQVnuRDYH5+fggMDMSmTZtw8+ZNjBkzBhkZGZoXrw4bNgzTp0/XtJ8zZw4OHz6Me/fu4dKlSxgyZAiio6MxatQoAM/vspk8eTK+/fZb7N27F9euXcOwYcPg6OiIPn36SHGIRCW2rNsy2JnZ4fqj6/j2r2+lLoeIqMKT/DlAAwcOxKNHj+Dv74/4+Hi0aNECQUFBmknMMTExkMn+zWlPnjzB6NGjER8fDxsbG7i5ueH06dNo3Lixps3nn3+OjIwMfPTRR0hJSUH79u0RFBTEZwBRhWVraotV3VdhwI4BmBc6D/0a9UNLh5ZSl0VEVGHxVRgF4KswqLx6b8d72HFjB1yVrjg3+hyM5EZSl0REVG5UuFdhEFHhrOi+AramtriScAXzQ+cXq4/kzGT8Ff0XVp1fhXEHxqHjxo7ouqUrrsRfKeVqiYjKL14BKgCvAFF5tu3vbRj0xyAYygyx+/3dUJopNW+SV6lVUIkqrX8+fPoQfyf+jb8f/Y3ridcRlx5XYL/GBsZY0W0FPmz5Id9CT0QVEt8GX0IMQFSeiaKIfr/1w+5bu4vdR03rmmhq1xRNqjVBk2pNsO36Nhy8cxAAMNx1OFZ2XwkzI7NSqpiIqGwwAJUQAxCVd/Hp8ei5tSf+SfsHcpkcckH+0n/amtqiqV1TTeBpXK0xLBQWWv2pRTUWhC7A18e/hlpUo0m1Jvj9vd/R0LahREdIRFR0DEAlxABE+upE1Am8/8f7iE+Ph5mhGQJ7BmJQs0FSl0VEVCicBE1ExdKxZkdc/vgyOtXshIzcDHyw8wOMPTCWD18kokqHAYiItNib2+PI0CP4usPXAIDVF1bDc70n7j25J3FlRESlhwGIiPKRy+T45u1vcGjwIVQ1qYqLcRfRak0rHLl7ROrSiIhKBQMQEb2UT10fXP74Mt6o8QZSs1PR49ce2Pb3NqnLIiIqMQYgInolJysnhAwPwXtN3kOuOheD/hiEZWeXSV0WEVGJMAAR0WspDBTY2n8rxrcZDwCYFDQJXwV/Bd5ESkQVFQMQERWKTJBhWbdl+LbT87fRzw2di9H7RiNPnVeq33P8/nG0W9cOXpu9kJWXVap9ExG9wABERIUmCAK+evMrrH1nLWSCDOsur0P/3/rjWe6zEvd978k99NveD29vfhthD8IQfD8YC0IXlELVRET5MQARUZGNdhuNP977Awq5Ansj9qLrz13x5NmTYvX1NPspvgz+Eo1WNsKuW7sgF+ToXq87AGBe6DxEPo4szdKJiAAwABFRMfVp2AeHhx6GlcIKoTGheHPjm/gn7Z9C768W1dgYvhH1V9THvNB5yFHlwKu2F8I/Ccf+QfvRtU5XZKuyMf7geM41IqJSx1dhFICvwiAqvKsJV+Hzsw/i0uPgbOWMT9/4FPbm9rA3t4fSTAmluRI2xjZab5g/HXsak4Im4cLDCwCAulXq4oeuP6Bn/Z6adneS76Dp6qbIUeVgx7s7MKDxAEmOj4gqDr4LrIQYgIiKJiolCt4/e+N28u0CtxvJjWBnZgd7c3uYGJjgZMxJAICFkQVmvDkDE90nQmGgyLffzOMzMeevOahuUR03x93M9xJXIqL/YgAqIQYgoqJLykzC4rDFuPvkLhLSExCfHo+EjASkZKXkaytAwIctP8R3b38HpbnypX0+y32GZqub4e6Tu5jiMQWLui7S4REQUUXHAFRCDEBEpScrLwuJGYnPA1F6Ah5lPkIbxzZopmxWqP0P3TmE7r92h1yQ4/LHlwu9HxHpHwagEmIAIipfBvw2AH/c/AOeTp74y/cvyATev0FE+RXl7zf/K0JE5d4S7yUwMzTDqdhT2BS+SepyiKgSYAAionLPycoJs96aBQD47MhnSM5Mfu0+iRmJmHBwApqsaoJJhybxeUJEpIVDYAXgEBhR+ZOrykWrta3wd+Lf+KjVR1jTc02B7TJzM7EkbAkWnFqApzlPNesFCHin/juY5D4Jb9d6W+u2fCKqHDgERkSVjqHcEKt7rAYABF4KxJkHZ7S2q9QqrL+8HvWW18PXx7/G05yncHNww089f0L3et0hQsS+2/vgtcULzQOa46dLP5XKKzyIqGLiFaAC8AoQUfnlu8cXG8M3oqV9S5wbfQ5yQY4/7/6Jz498jmuJ1wAANa1rYu7bczGw6UDNhOmIpAgsP7ccG8M3IiM3AwBQ1aQqPnb7GGPbjEV1y+qSHRMRlQ7eBVZCDEBE5dejjEdosKIBnmQ9wadvfIqrCVcRfD8YAGBtbI2vO3yN8W3HF/hgRQBIyUrBukvrsPzcckSnRgMADGQGWNx1MSa4Tyiz4yCi0scAVEIMQETl25oLa/DJgU80n43kRpjQdgK+7PAlqphUKVQfeeo87I3Yi6VnluJkzEnIBBmCBgehS50uuiqbiHSMc4CIqFIb7TYaHV06AgAGNR2EW+NuYVHXRYUOP8Dzqz79GvXDX75/YVTLUVCLagz6YxCiUqJ0VDURlSe8AlQAXgEiKv+y87LxJOsJ7M3tS9xXVl4WOmzogAsPL6CVQyuE+obCxNCkFKokorLEK0BEVOkpDBSlEn4AwNjAGH+89wdsTW1xKe4Sxh4cC/6/IVHlxgBERATA2coZ2wdsh0yQYWP4Rqy5WPBzhoiocmAAIiL6f2/XehvzO88HAEw8NBFhsWESV0REusIARET0H1PbTcWAxgOQq87FgB0DEJ8eL3VJRKQDDEBERP8hCALW91qPRraN8PDpQwz8fSByVblSl0VEpYwBiIjof1goLLBr4C5YGFngr+i/8PmRz6UuiYhKGQMQEVEBGtg2wOa+mwEAS88uxdZrW0ul3/tP7mNfxD7eZUYkMQYgIqKX6NOwD75s/yUAYOTekbiacLVE/SVmJMJzvSd6beuFledXlkaJRFRMDEBERK8wp9McdK3TFc/ynqHPtj5IykwqVj9qUY0hO4cgLj0OAPD5kc9xO/l2aZZKREXAAERE9ApymRy/9vsVtaxr4X7KfQz4bQByVDlF7mfeyXk4cu8ITAxM0LZ6WzzLe4Zhu4YhT52ng6qJ6HXKRQBauXIlatasCWNjY7i7u+PcuXOF2m/btm0QBAF9+vTRWj9ixAgIgqC1+Pj46KByItIHVU2rYt+gfTA3MseJ6BMYf3B8kebwnIg6Af8QfwDAqh6r8Pu7v8NKYYWz/5zFgtAFuiqbiF5B8gC0fft2+Pn5YebMmbh06RJcXV3h7e2NxMTEV+4XFRWFqVOnokOHDgVu9/HxQVxcnGbZurV0JjASkX5qYtcEW/tvhQABgZcCsfzc8kLtl5CegEF/DIJaVGO463CMaDECTlZOWNF9BQBg1olZuBx3WZelE1EBJA9AixcvxujRo+Hr64vGjRsjICAApqamWL9+/Uv3UalUGDx4MGbPno3atWsX2EahUMDe3l6z2NjY6OoQiEhPvFP/HXzf5XsAwKd/forDdw+/sr1KrcKQXc/n/TSybYSV3f+d+Dy42WD0b9Qfeeo8DN01FFl5WTqtnYi0SRqAcnJycPHiRXh5eWnWyWQyeHl5ISzs5Y+gnzNnDuzs7DBy5MiXtgkJCYGdnR0aNGiAMWPGIDk5+aVts7OzkZaWprUQERVkiscUDHcdDrWoxns73sOtpFsvbTsvdB6O3jsKU0NT7Hh3B8yMzDTbBEHA6h6roTRT4vqj65hxbEZZlE9E/0/SAJSUlASVSgWlUqm1XqlUIj6+4MfPh4aGYt26dQgMDHxpvz4+Pti8eTOCg4OxYMECnDhxAt26dYNKpSqw/bx582BlZaVZnJycin9QRFSpCYKANe+sgaeTJ1KzU9Fza088fvY4X7uQqBDMDJkJAFjVfRWa2DXJ16aaWTUE9nz+37Ifwn7AiagTui2eiDQkHwIriqdPn2Lo0KEIDAyEra3tS9u9//776NWrF5o1a4Y+ffpg//79OH/+PEJCQgpsP336dKSmpmqW2NhYHR0BEVUGCgMFdg7cCWcrZ0Q+jsR7O97Tel3Gf+f9jGgxAsNbDH9pXz0b9MTIliMhQsSIPSOQls0r0ERlQdIAZGtrC7lcjoSEBK31CQkJsLe3z9f+7t27iIqKQs+ePWFgYAADAwNs3rwZe/fuhYGBAe7evVvg99SuXRu2traIjIwscLtCoYClpaXWQkT0KnZmdtg3aB/MDM0QfD8Yk4MmA/h33k98ejwaV2uMFd1WvLavxd6LUdO6JqJSouD3p5+OKyciQOIAZGRkBDc3NwQHB2vWqdVqBAcHw8PDI1/7hg0b4tq1awgPD9csvXr1QqdOnRAeHv7SoasHDx4gOTkZDg4OOjsWItI/zZXN8Uu/XyBAwKoLq7Dq/KpXzvt5GUuFJTb23ggBAtZdXod9EfvKoHoi/Sb5EJifnx8CAwOxadMm3Lx5E2PGjEFGRgZ8fX0BAMOGDcP06dMBAMbGxmjatKnWYm1tDQsLCzRt2hRGRkZIT0/HZ599hjNnziAqKgrBwcHo3bs36tatC29vbykPlYgqod4Ne+O7t78DAEw8NFFr3k/jao0L3U/Hmh3h5/H86s+ofaPwKONR6RdLRBqSB6CBAwdi0aJF8Pf3R4sWLRAeHo6goCDNxOiYmBjExcUVuj+5XI6rV6+iV69eqF+/PkaOHAk3NzecPHkSCoVCV4dBRHpsWvtpGNxsMFSiqlDzfl7m27e/ReNqjZGYkYhPDnzCF6YS6ZAg8t+wfNLS0mBlZYXU1FTOByKiQsnKy4LvHl88y32GX/r9Uqihr4JcirsE95/ckafOQyPbRmjv3B6eTp5o79wetW1qQxCE1/YhiiISMhJwPfE6IpIj0LZ6W7R2bF2seogqkqL8/WYAKgADEBFJafnZ5Zj852SoRbXWeqWZEp7Onmjv1B6ezp5oad8SKVkpuP7oOq4nXn/+z///OfnZv88+MzEwwbHhx/BGjTfK+lCIyhQDUAkxABGR1B5lPMLp2NM4FXsKp2JP4cLDC/lewioX5FCJBT/fTICAOlXqwEBmgFtJt1DFpApOfXgKDW0blkX5RJJgACohBiAiKm+y8rJw4eEFnIo5hdDYUJyOPa15AGMt61poYtcETao1QVO7pmhSrQka2jaEiaEJMnIy0GlTJ5x/eB7OVs4IGxkGRwtHiY+GSDcYgEqIAYiIyju1qEZMagyqmVZ77XyjRxmP4LneE3ce30Ezu2b4y/cvWBtbl02hRGWoKH+/Jb8LjIiIik4myFDTumahJltXM6uGP4f8CXtze1xLvIY+2/rw5auk9xiAiIj0QC2bWjg0+BAsjCxwIvoEhu4aCpW64PlDRPqAAYiISE+0sG+B3e/vhqHMEL/f+B2TgybzWUOktxiAiIj0yNu13saWvlsAACvOr8D80PkSV0QkDQYgIiI9M7DpQCz1XgoA+PLYl9gYvlHSeoikwABERKSHJr0xCV94fgEAGLV3FA7eOShxRURliwGIiEhPzes8D8Nch0ElqtB3e18sCF3AidGkNxiAiIj0lCAI+KnnTxjQeAByVDmYFjwNHTd2ROTjSKlLI9I5BiAiIj1mKDfEbwN+w/pe62FhZIFTsafgGuCK1edXl/odYjmqHKw+vxruP7ljU/imUu2bqKj4JOgC8EnQRKSPolOi4bvHF8ejjgMAutbpinW91qGGZY0S9ZunzsPmK5sx58QcRKdGAwAMZYY4M+oMWjm0KnHdRC/wSdBERFRkLtYuODrsKH70+RHGBsY4fPcwmq1uhl+u/lKsq0EqtQq/XP0FjVc2xsi9IxGdGg0Hcwe4V3dHrjoXH/zxATJyMnRwJESvxwBEREQaMkGGie4Tcfnjy2hbvS1SslIwZNcQvLvjXTzKeFSoPtSiGn/c+APNA5pjyK4huPP4DmxNbfFD1x9wd+JdHPjgAKpbVEdEcgT8/vTT8RERFYxDYAXgEBgR0fOhq/mh8zH7xGzkqfNgZmgGZytn2JnZQWmuhJ2pHezM7P79bGaHhPQEzPlrDsLjwwEA1sbW+KzdZ5joPhHmRuaavo/dPwavzV4QIWLnezvRt1FfiY6SKhO+Db6EGICIiP51Oe4yhu0ehr8T/y70PhZGFvj0jU/xqcenL33z/BdHvsD3p79HFZMquPrJVVS3rF5KFZO+YgAqIQYgIiJtKrUKt5JuISEjAYkZiZolIT0BiZn/fs7Ky8LQ5kPxWbvPUNW06iv7zFHloN26drgYdxFv13obR4YegUwo3MwMURSx+cpmpGWn4ZPWn8BQblgah0kVHANQCTEAERGVjdvJt9FyTUtk5mZigdcCfO75+Wv3SUhPwIg9IxAUGQQAaOXQCpv7bEYTuya6LpfKOd4FRkREFUL9qvWxzGcZAOCrY1/hwsMLr2x/4PYBNFvdDEGRQTA2MIaNsQ0uxV2C21o3LDq9iE+ypkJjACIiIkl92PJDDGg8AHnqPHzwxwdIz0nP1+ZZ7jOMPzge72x9B48yH6GZXTNcGH0B18deR/d63ZGtysZnRz5Dp02dcO/JPQmOgioaBiAiIpKUIAhY+85a1LCsgTuP72By0GSt7VcTrqJNYBusPL8SADDZfTLOjT6HJnZN4GDhgP2D9iOwZyDMjcxxMuYkmq9ujjUX1pT6k6ypcmEAIiIiydmY2ODnvj9DgIB1l9fhjxt/QC2q8eOZH9E2sC2uP7oOpZkShwYfwhKfJTA2MNbsKwgCRrUahaufXMWbLm8iIzcDnxz4BN1/7Y5/0v6R8KioPOMk6AJwEjQRkTS+DP4S80LnwcbYBm2qt8Hhu4cBAO/Ufwfreq2DnZndK/dXi2osPbMUXwZ/iWxVNmyMbbCy+0oMajaoLMonifEusBJiACIikkauKhee6z1x/uF5AICxgTF+6PoDxrQeA0EQCt3PjUc3MGzXMFyMuwgA8H/TH7PemlWkPqji4V1gRERUIRnKDfFr/19R3aI63BzccGH0BYxtM7bIwaVxtcYIGxmGL9t/CQCY89ccfH7kc84LIg1eASoArwAREUlLpVZBLpOXSl8/nvkRk/+cDAAY23oslndfXugHLlLFwitARERUoZVW+AGASW9Mwtp31kKAgFUXVmHU3lF8XhAxABERUeU32m00NvfdDJkgw4bwDRiyawhyVblSl0USYgAiIiK9MKT5EGwfsB0GMgNs+3sb3vv9PWTnZUtdFkmEAYiIiPTGgMYDsHvgbijkCuy+tRt9tvdBZm6m1GWRBBiAiIhIr/So3wMHPjgAU0NTBEUGocevPfA0+6nUZVEZYwAiIiK907l2Z/w55E9YGFkgJCoEXX/uipSsFKnLojLEAERERHqpvXN7BA8Lho2xDc48OINOmzohMSNR6rKojDAAERGR3mpTvQ1CRoTAzswO4fHheHPDm3iQ9kDqsqgMMAAREZFea65sjpO+J+Fk6YSI5Ai0X98ekY8jpS6LdIwBiIiI9F79qvUR+mEo6lWph+jUaHTY0AF/J/5dpD6SM5Px/anvERQZpKMqqTSViwC0cuVK1KxZE8bGxnB3d8e5c+cKtd+2bdsgCAL69OmjtV4URfj7+8PBwQEmJibw8vLCnTt3dFA5ERFVFs5WzjjpexLNlc0Rnx6Pjhs74tw/r/97lJadhtkhs1Hrx1r44ugX6LOtD+49uVcGFVNJSB6Atm/fDj8/P8ycOROXLl2Cq6srvL29kZj46oloUVFRmDp1Kjp06JBv2/fff49ly5YhICAAZ8+ehZmZGby9vZGVlaWrwyAiokpAaa5EyPAQvFHjDTx+9hidN3dGSFRIgW2f5T7DotOLUPvH2ph1Yhae5jyFsYExslXZmHJ4StkWTkUmeQBavHgxRo8eDV9fXzRu3BgBAQEwNTXF+vXrX7qPSqXC4MGDMXv2bNSuXVtrmyiKWLp0Kb7++mv07t0bzZs3x+bNm/Hw4UPs3r1bx0dDREQVnY2JDY4MPYLOtTojPScdPj/7YP/t/ZrtOaocrD6/GnWW1cFnRz5D8rNkNKjaAL8N+A3nR5+HXJBj963dOHrvqIRHQa8jaQDKycnBxYsX4eXlpVknk8ng5eWFsLCwl+43Z84c2NnZYeTIkfm23b9/H/Hx8Vp9WllZwd3d/ZV9EhERvWBuZI79H+xH7wa9ka3KRt/tffHL1V+w5coWNFzREGMPjkVcehxcrFywvtd6/D32b7zb5F00tWuKcW3GAQAmBU3i+8bKMUkDUFJSElQqFZRKpdZ6pVKJ+Pj4AvcJDQ3FunXrEBgYWOD2F/sVpc/s7GykpaVpLUREpN+MDYyx490dGNxsMPLUeRiyawiG7R6G+yn3oTRTYnm35YgYHwHflr4wkBlo9pv11ixUNamKG49uYPWF1RIeAb2K5ENgRfH06VMMHToUgYGBsLW1LbV+582bBysrK83i5ORUan0TEVHFZSg3xOa+m/GJ2ycAABtjG8zvPB93J97F+LbjoTBQ5NvHxsQG3739HQDA/7g/HmU8KvL3Bt8LxrSj05CcmVyyA6CXkjQA2draQi6XIyEhQWt9QkIC7O3t87W/e/cuoqKi0LNnTxgYGMDAwACbN2/G3r17YWBggLt372r2K2yfADB9+nSkpqZqltjY2FI6QiIiquhkggyreqzChdEXcH/SfXzR/guYGZm9cp9RrUahhX0LpGan4utjXxfp+4Iig9Dtl25YcGoB3H9yx81HN0tSPr2EpAHIyMgIbm5uCA4O1qxTq9UIDg6Gh4dHvvYNGzbEtWvXEB4erll69eqFTp06ITw8HE5OTqhVqxbs7e21+kxLS8PZs2cL7BMAFAoFLC0ttRYiIqIXBEGAm6MbrIytCtVeLpNjmc8yAEDgpUBcjrtcqP1CY0LRb3s/5KpzoZArcPfJXbyx7g0cunOo2LVTwSQfAvPz80NgYCA2bdqEmzdvYsyYMcjIyICvry8AYNiwYZg+fToAwNjYGE2bNtVarK2tYWFhgaZNm8LIyAiCIGDy5Mn49ttvsXfvXly7dg3Dhg2Do6NjvucFERER6UoHlw54v+n7ECFiYtBEiKL4yvbh8eF459d38CzvGbrV7YZ7k+6hg3MHpGWn4Z2t72BJ2JLX9kGFJ3kAGjhwIBYtWgR/f3+0aNEC4eHhCAoK0kxijomJQVxcXJH6/PzzzzFhwgR89NFHaNOmDdLT0xEUFARjY2NdHAIREVGBvvf6HiYGJgiNCcX269tf2u528m103dIVqdmp6ODcAb+/9zscLRxxdNhRjGw5EmpRDb/Dfhi9bzRyVDlleASVlyAyTuaTlpYGKysrpKamcjiMiIhK5JsT38A/xB81LGvg1rhb+eYPxabGwnO9J2LTYtHSviWODz+uNdQmiiKWnlmKqUemQi2q0cG5A/547w9UM6tW1odS7hXl77fkV4CIiIgqs6ntpqKmdU08SHuABacWaG1LzEhEly1dEJsWiwZVGyBoSFC+eUaCIOBTj0+xf9B+WCoscTLmJNr+1LbI7yojbQxAREREOmRiaIJFXRYBABaeXoiolCgAQGpWKnx+9kFEcgScrZxxZOgR2JnZvbSfbvW6IWxkGGrb1EZUShQ81nloPaGaioZDYAXgEBgREZUmURTReXNnHI86jv6N+mNz383w/tkboTGhsDOzw0nfk6hftX6h+krOTMaAHQM07yizUljB2thas1gZ//9nxfPPVUyqoG+jvnC2ctbhEZYPRfn7zQBUAAYgIiIqbdcSrqHlmpZQiSq0tG+Jy/GXYaWwQsiIELSwb1GkvnJUOZh0aBICLgYUqr2lwhLreq3DgMYDilF5xcEAVEIMQEREpAsTDk7AivMrAAAmBiY4MvQIPJ09i91fcmYykjKTkJKVgpSsFKRmp2p+frGc/ecsLsVdAgCMaT0Gi70Xw9igct4VzQBUQgxARESkC4+fPUbTVU2RlJmEfYP2wbuut86/M1eVC//j/ph/aj4AwFXpit/e/a3QQ24VCQNQCTEAERGRriRnJiNXnQt784Jfz6QrQZFBGLprKJIyk2BuZI4176zBB80+KNMadI23wRMREZVTVU2rlnn4AQCfuj648skVdHTpiPScdAzeORij9o5CZm5mmddSHjAAERER6YkXT5f2f9MfAgSsu7wObQPb4sajG1KXVuYYgIiIiPSIgcwAszvNxpGhR6A0U+L6o+toE9gGW69tlbq0MsUAREREpIc61+6MK59cgVdtL2TmZmLY7mG48PCC1GWVGQYgIiIiPaU0VyJocBD6N+qPPHUePvjjA2TkZEhdVplgACIiItJjcpkca3uuRQ3LGrjz+A4mB02WuqQywQBERESk56qYVMHmPpshQMBPl3/Czps7pS5J5xiAiIiICJ1qdcLnnp8DAEbvG41/0v6RuCLdYgAiIiIiAMCcTnPQyqEVHj97jOG7h0MtqqUuSWcYgIiIiAgAYCQ3wq/9foWpoSmC7wdjcdhiqUvSGQYgIiIi0mhg2wBLvZcCAL4M/hKX4y5LW5COMAARERGRllGtRqFPwz7IVefig50fVMrXZTAAERERkRZBEBDYMxAO5g64lXQLUw9PlbqkUscARERERPnYmtpiU59NAIDVF1Zjb8ReiSsqXQxAREREVKAudbpgiscUAMDIvSMR9zRO4opKDwMQERERvdR3b38HV6UrkjKTMGLPCIiiWKL+HqQ9wCf7P0FyZnIpVVg8DEBERET0UgoDBX7t/yuMDYxx+O5hbAzfWOy+RFHE2ANjsebiGvju8S29IouBAYiIiIheqXG1xvim0zcAgCmHpyAxI7FY/ey4sQP7bu+DocwQ8zrPK80Si4wBiIiIiF5r8huT0cK+BZ5kPcGnf35a5P2TM5Mx4dAEAMCXHb5EE7smpV1ikTAAERER0WsZyAwQ2DMQMkGGX6/9iqDIoCLtP/XIVCRmJKJxtcaY3n66jqosPAYgIiIiKpTWjq0xyX0SAGDMgTHIyMko1H5H7h7BxvCNz9823/MnKAwUuiyzUBiAiIiIqNDmdJoDZytnRKVEYWbIzNe2z8jJwMf7PwYAjG87Hh5OHrousVAYgIiIiKjQzI3MsbrHagDAkjNLcCnu0ivb+x/3x/2U+3CydMJ3b39XFiUWCgMQERERFUn3et0xsMlAqEU1Ru8bjTx1XoHtzv9zHkvPLgUArHlnDSwUFmVY5asxABEREVGRLfVZCmtja1yKu4RlZ5fl256rysWofaOgFtX4oNkH6FavmwRVvhwDEBERERWZvbk9FnZZCACYcXwGolKitLYvPL0QVxOuoqpJVSz1Xlr2Bb4GAxAREREVy4ctP8SbLm8iMzcTYw6M0bwmIyIpAnNOzAHw/EpRNbNqUpZZIAYgIiIiKhaZIMOad9bASG6EoMggbL++HWpRjVH7RiFblQ2fuj4Y3Gyw1GUWiAGIiIiIiq2hbUN81eErAMCkoEmYHzofoTGhMDM0Q0CPAAiCIHGFBWMAIiIiohL5wvMLNLJthMSMRHx17HkYmtt5LlysXSSu7OUYgIiIiKhEFAYKBPYM1Hx2r+6OcW3GSVjR6zEAERERUYl5OntixpszUK9KPWzovQFymVzqkl6pXASglStXombNmjA2Noa7uzvOnTv30rY7d+5E69atYW1tDTMzM7Ro0QJbtmzRajNixAgIgqC1+Pj46PowiIiI9NqcTnNwe8JtNKrWSOpSXstA6gK2b98OPz8/BAQEwN3dHUuXLoW3tzciIiJgZ2eXr32VKlXw1VdfoWHDhjAyMsL+/fvh6+sLOzs7eHt7a9r5+Phgw4YNms8KhfQvXiMiIqLyQRBf3LQvEXd3d7Rp0wYrVqwAAKjVajg5OWHChAmYNm1aofpo1aoVevTogW+++QbA8ytAKSkp2L17d7FqSktLg5WVFVJTU2FpaVmsPoiIiKhsFeXvt6RDYDk5Obh48SK8vLw062QyGby8vBAWFvba/UVRRHBwMCIiIvDmm29qbQsJCYGdnR0aNGiAMWPGIDk5+aX9ZGdnIy0tTWshIiKiykvSIbCkpCSoVCoolUqt9UqlErdu3XrpfqmpqahevTqys7Mhl8uxatUqdOnSRbPdx8cH/fr1Q61atXD37l18+eWX6NatG8LCwiCX55+UNW/ePMyePbv0DoyIiIjKNcnnABWHhYUFwsPDkZ6ejuDgYPj5+aF27dp46623AADvv/++pm2zZs3QvHlz1KlTByEhIejcuXO+/qZPnw4/Pz/N57S0NDg5Oen8OIiIiEgakgYgW1tbyOVyJCQkaK1PSEiAvb39S/eTyWSoW7cuAKBFixa4efMm5s2bpwlA/6t27dqwtbVFZGRkgQFIoVBwkjQREZEekXQOkJGREdzc3BAcHKxZp1arERwcDA8Pj0L3o1arkZ2d/dLtDx48QHJyMhwcHEpULxEREVUOkg+B+fn5Yfjw4WjdujXatm2LpUuXIiMjA76+vgCAYcOGoXr16pg3bx6A5/N1WrdujTp16iA7OxsHDx7Eli1bsHr1agBAeno6Zs+ejf79+8Pe3h53797F559/jrp162rdJk9ERET6S/IANHDgQDx69Aj+/v6Ij49HixYtEBQUpJkYHRMTA5ns3wtVGRkZGDt2LB48eAATExM0bNgQP//8MwYOHAgAkMvluHr1KjZt2oSUlBQ4Ojqia9eu+OabbzjMRURERADKwXOAyiM+B4iIiKjiqTDPASIiIiKSAgMQERER6R0GICIiItI7DEBERESkdyS/C6w8ejEvnO8EIyIiqjhe/N0uzP1dDEAFePr0KQDwdRhEREQV0NOnT2FlZfXKNrwNvgBqtRoPHz6EhYUFBEEo1b5fvGcsNjaWt9iXAZ7vssXzXbZ4vssWz3fZKs75FkURT58+haOjo9YzBAvCK0AFkMlkqFGjhk6/w9LSkv8ClSGe77LF8122eL7LFs932Srq+X7dlZ8XOAmaiIiI9A4DEBEREekdBqAyplAoMHPmTL6XrIzwfJctnu+yxfNdtni+y5auzzcnQRMREZHe4RUgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACpDK1euRM2aNWFsbAx3d3ecO3dO6pIqhb/++gs9e/aEo6MjBEHA7t27tbaLogh/f384ODjAxMQEXl5euHPnjjTFVgLz5s1DmzZtYGFhATs7O/Tp0wcRERFabbKysjBu3DhUrVoV5ubm6N+/PxISEiSquGJbvXo1mjdvrnkYnIeHBw4dOqTZznOtW/Pnz4cgCJg8ebJmHc956Zk1axYEQdBaGjZsqNmuy3PNAFRGtm/fDj8/P8ycOROXLl2Cq6srvL29kZiYKHVpFV5GRgZcXV2xcuXKArd///33WLZsGQICAnD27FmYmZnB29sbWVlZZVxp5XDixAmMGzcOZ86cwZEjR5Cbm4uuXbsiIyND0+bTTz/Fvn37sGPHDpw4cQIPHz5Ev379JKy64qpRowbmz5+Pixcv4sKFC3j77bfRu3dvXL9+HQDPtS6dP38ea9asQfPmzbXW85yXriZNmiAuLk6zhIaGarbp9FyLVCbatm0rjhs3TvNZpVKJjo6O4rx58ySsqvIBIO7atUvzWa1Wi/b29uLChQs161JSUkSFQiFu3bpVggorn8TERBGAeOLECVEUn59fQ0NDcceOHZo2N2/eFAGIYWFhUpVZqdjY2Ig//fQTz7UOPX36VKxXr5545MgRsWPHjuKkSZNEUeTvd2mbOXOm6OrqWuA2XZ9rXgEqAzk5Obh48SK8vLw062QyGby8vBAWFiZhZZXf/fv3ER8fr3Xurays4O7uznNfSlJTUwEAVapUAQBcvHgRubm5Wue8YcOGcHZ25jkvIZVKhW3btiEjIwMeHh481zo0btw49OjRQ+vcAvz91oU7d+7A0dERtWvXxuDBgxETEwNA9+eaL0MtA0lJSVCpVFAqlVrrlUolbt26JVFV+iE+Ph4ACjz3L7ZR8anVakyePBmenp5o2rQpgOfn3MjICNbW1lptec6L79q1a/Dw8EBWVhbMzc2xa9cuNG7cGOHh4TzXOrBt2zZcunQJ58+fz7eNv9+ly93dHRs3bkSDBg0QFxeH2bNno0OHDvj77791fq4ZgIio2MaNG4e///5ba8yeSl+DBg0QHh6O1NRU/P777xg+fDhOnDghdVmVUmxsLCZNmoQjR47A2NhY6nIqvW7duml+bt68Odzd3eHi4oLffvsNJiYmOv1uDoGVAVtbW8jl8nwz1xMSEmBvby9RVfrhxfnluS9948ePx/79+3H8+HHUqFFDs97e3h45OTlISUnRas9zXnxGRkaoW7cu3NzcMG/ePLi6uuLHH3/kudaBixcvIjExEa1atYKBgQEMDAxw4sQJLFu2DAYGBlAqlTznOmRtbY369esjMjJS57/fDEBlwMjICG5ubggODtasU6vVCA4OhoeHh4SVVX61atWCvb291rlPS0vD2bNnee6LSRRFjB8/Hrt27cKxY8dQq1Ytre1ubm4wNDTUOucRERGIiYnhOS8larUa2dnZPNc60LlzZ1y7dg3h4eGapXXr1hg8eLDmZ55z3UlPT8fdu3fh4OCg+9/vEk+jpkLZtm2bqFAoxI0bN4o3btwQP/roI9Ha2lqMj4+XurQK7+nTp+Lly5fFy5cviwDExYsXi5cvXxajo6NFURTF+fPni9bW1uKePXvEq1evir179xZr1aolPnv2TOLKK6YxY8aIVlZWYkhIiBgXF6dZMjMzNW0++eQT0dnZWTx27Jh44cIF0cPDQ/Tw8JCw6opr2rRp4okTJ8T79++LV69eFadNmyYKgiAePnxYFEWe67Lw37vARJHnvDRNmTJFDAkJEe/fvy+eOnVK9PLyEm1tbcXExERRFHV7rhmAytDy5ctFZ2dn0cjISGzbtq145swZqUuqFI4fPy4CyLcMHz5cFMXnt8LPmDFDVCqVokKhEDt37ixGRERIW3QFVtC5BiBu2LBB0+bZs2fi2LFjRRsbG9HU1FTs27evGBcXJ13RFdiHH34ouri4iEZGRmK1atXEzp07a8KPKPJcl4X/DUA856Vn4MCBooODg2hkZCRWr15dHDhwoBgZGanZrstzLYiiKJb8OhIRERFRxcE5QERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPQOAxARERHpHQYgIqKXEAQBu3fvlroMItIBBiAiKpdGjBgBQRDyLT4+PlKXRkSVgIHUBRARvYyPjw82bNigtU6hUEhUDRFVJrwCRETllkKhgL29vdZiY2MD4Pnw1OrVq9GtWzeYmJigdu3a+P3337X2v3btGt5++22YmJigatWq+Oijj5Cenq7VZv369WjSpAkUCgUcHBwwfvx4re1JSUno27cvTE1NUa9ePezdu1ez7cmTJxg8eDCqVasGExMT1KtXL19gI6LyiQGIiCqsGTNmoH///rhy5QoGDx6M999/Hzdv3gQAZGRkwNvbGzY2Njh//jx27NiBo0ePagWc1atXY9y4cfjoo49w7do17N27F3Xr1tX6jtmzZ+O9997D1atX0b17dwwePBiPHz/WfP+NGzdw6NAh3Lx5E6tXr4atrW3ZnQAiKr5SeaUqEVEpGz58uCiXy0UzMzOt5bvvvhNF8flb6T/55BOtfdzd3cUxY8aIoiiKa9euFW1sbMT09HTN9gMHDogymUyMj48XRVEUHR0dxa+++uqlNQAQv/76a83n9PR0EYB46NAhURRFsWfPnqKvr2/pHDARlSnOASKicqtTp05YvXq11roqVapofvbw8NDa5uHhgfDwcADAzZs34erqCjMzM812T09PqNVqREREQBAEPHz4EJ07d35lDc2bN9f8bGZmBktLSyQmJgIAxowZg/79++PSpUvo2rUr+vTpg3bt2hXrWImobDEAEVG5ZWZmlm9IqrSYmJgUqp2hoaHWZ0EQoFarAQDdunVDdHQ0Dh48iCNHjqBz584YN24cFi1aVOr1ElHp4hwgIqqwzpw5k+9zo0aNAACNGjXClStXkJGRodl+6tQpyGQyNGjQABYWFqhZsyaCg4NLVEO1atUwfPhw/Pzzz1i6dCnWrl1bov6IqGzwChARlVvZ2dmIj4/XWmdgYKCZaLxjxw60bt0a7du3xy+//IJz585h3bp1AIDBgwdj5syZGD58OGbNmoVHjx5hwoQJGDp0KJRKJQBg1qxZ+OSTT2BnZ4du3brh6dOnOHXqFCZMmFCo+vz9/eHm5oYmTZogOzsb+/fv1wQwIirfGICIqNwKCgqCg4OD1roGDRrg1q1bAJ7fobVt2zaMHTsWDg4O2Lp1Kxo3bgwAMDU1xZ9//olJkyahTZs2MDU1Rf/+/bF48WJNX8OHD0dWVhaWLFmCqVOnwtbWFgMGDCh0fUZGRpg+fTqioqJgYmKCDh06YNu2baVw5ESka4IoiqLURRARFZUgCNi1axf69OkjdSlEVAFxDhARERHpHQYgIiIi0jucA0REFRJH74moJHgFiIiIiPQOAxARERHpHQYgIiIi0jsMQERERKR3GICIiIhI7zAAERERkd5hACIiIiK9wwBEREREeocBiIiIiPTO/wHbZyOBWaz+HAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# GRADED CODE: Advanced implementation\n",
        "CNN = tf.keras.Sequential(name='CNN')\n",
        "CNN.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,1)))\n",
        "CNN.add(layers.MaxPool2D((2,2)))\n",
        "CNN.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "CNN.add(layers.MaxPool2D((2,2)))\n",
        "CNN.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
        "CNN.add(layers.Flatten())\n",
        "\n",
        "CNN.add(layers.Dropout(0.5))\n",
        "CNN.add(layers.Dense(2048,activation='relu'))\n",
        "CNN.add(layers.Dropout(0.4))\n",
        "CNN.add(layers.Dense(512,activation='relu'))\n",
        "CNN.add(layers.Dense(128,activation='relu'))\n",
        "CNN.add(layers.Dense(64,activation='relu'))\n",
        "CNN.add(layers.Dense(2,activation='softmax'))\n",
        "\n",
        "tf.keras.utils.plot_model(CNN, show_shapes=True)\n",
        "### Start training ###\n",
        "\n",
        "LR = 0.00015\n",
        "WARMUP_EPOCH = 5\n",
        "epochs_num = 50\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < WARMUP_EPOCH:\n",
        "    warmup_percent = (epoch+1) / WARMUP_EPOCH\n",
        "    return LR * warmup_percent\n",
        "  else:\n",
        "    return lr**1.0008\n",
        "\n",
        "from tensorflow.python import metrics\n",
        "\n",
        "CNN.compile(optimizer=tf.keras.optimizers.Adam(LR),\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n",
        "\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "mode='max')\n",
        "\n",
        "time_start = time.time()\n",
        "# CNN.fit(X_train, y_train, epochs=20)\n",
        "history = CNN.fit(\n",
        "      X_train, y_train,\n",
        "      epochs=epochs_num,\n",
        "      callbacks=[callback, checkpoint],\n",
        "      validation_data = (X_val, y_val),\n",
        "      verbose=True)\n",
        "\n",
        "# score = CNN.evaluate(X_val, y_val, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])\n",
        "time_end = time.time()\n",
        "time_c= time_end - time_start   #執行所花時間\n",
        "print('time cost', time_c, 's')\n",
        "\n",
        "plt.plot(history.epoch, history.history[\"loss\"], 'g', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# import other packages here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hhAjQTjPk-I0"
      },
      "outputs": [],
      "source": [
        "# GRADED CODE: Advanced implementation\n",
        "### Data preprocess & augmentation ###\n",
        "#You may have to adjust the shape of y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PgL3loUQk-LO"
      },
      "outputs": [],
      "source": [
        "# GRADED CODE: Advanced implementation\n",
        "### Start training ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pObMJ67hk-Ov"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 28ms/step\n",
            "[1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1\n",
            " 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1] 60\n",
            "Model: \"CNN\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,278,082\n",
            "Trainable params: 3,278,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "pred_test = CNN.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis = 1)\n",
        "print(pred_test, len(pred_test))\n",
        "CNN.summary()\n",
        "output[\"advanced_pred_test\"] = pred_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXGnS3HQeNUc"
      },
      "source": [
        "# Submit prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "twMsmXbQeDL_"
      },
      "outputs": [],
      "source": [
        "# sanity check\n",
        "assert(list(output.keys()) == ['conv_initialization', 'zero_padding', 'conv_single_step', 'conv_forward_1', 'conv_forward_2', 'conv_forward_3', 'conv_update_1', 'conv_update_2', 'maxpool_forward', 'flatten_forward', 'flatten_backward', 'model_1', 'model_2', 'model_3', 'model_4', 'basic_pred_test', 'basic_model_layers', 'basic_model_parameters', 'advanced_pred_test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bCJ0XTO_zE8A"
      },
      "outputs": [],
      "source": [
        "np.save(\"hw4_output.npy\", output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wFBFUUEg1to-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv_initialization： <class 'numpy.ndarray'>\n",
            "zero_padding： <class 'numpy.ndarray'>\n",
            "conv_single_step： <class 'numpy.float64'>\n",
            "conv_forward_1： <class 'numpy.float64'>\n",
            "conv_forward_2： <class 'numpy.ndarray'>\n",
            "conv_forward_3： <class 'numpy.ndarray'>\n",
            "conv_update_1： <class 'numpy.ndarray'>\n",
            "conv_update_2： <class 'numpy.ndarray'>\n",
            "maxpool_forward： <class 'numpy.ndarray'>\n",
            "flatten_forward： <class 'numpy.ndarray'>\n",
            "flatten_backward： <class 'numpy.ndarray'>\n",
            "model_1： <class 'numpy.ndarray'>\n",
            "model_2： <class 'numpy.ndarray'>\n",
            "model_3： <class 'numpy.ndarray'>\n",
            "model_4： <class 'numpy.ndarray'>\n",
            "basic_pred_test： <class 'numpy.ndarray'>\n",
            "basic_model_layers： <class 'list'>\n",
            "basic_model_parameters： <class 'list'>\n",
            "advanced_pred_test： <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "submit = np.load(\"hw4_output.npy\", allow_pickle=True).item()\n",
        "for key, value in submit.items():\n",
        "    print(str(key) + \"： \" + str(type(value)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBkBtZHxIh8Z"
      },
      "source": [
        "Expected output:<br>\n",
        "<small>\n",
        "conv_initialization： <class 'numpy.ndarray'> <br>\n",
        "zero_padding： <class 'numpy.ndarray'> <br>\n",
        "conv_single_step： <class 'numpy.ndarray'> <br>\n",
        "conv_forward_1： <class 'numpy.float64'> <br>\n",
        "conv_forward_2： <class 'numpy.ndarray'> <br>\n",
        "conv_forward_3： <class 'numpy.ndarray'> <br>\n",
        "conv_update_1： <class 'numpy.ndarray'> <br>\n",
        "conv_update_2： <class 'numpy.ndarray'> <br>\n",
        "maxpool_forward： <class 'numpy.ndarray'> <br>\n",
        "flatten_forward： <class 'numpy.ndarray'> <br>\n",
        "flatten_backward： <class 'numpy.ndarray'> <br>\n",
        "model_1： <class 'numpy.ndarray'> <br>\n",
        "model_2： <class 'numpy.ndarray'> <br>\n",
        "model_3： <class 'numpy.ndarray'> <br>\n",
        "model_4： <class 'numpy.ndarray'> <br>\n",
        "basic_pred_test： <class 'numpy.ndarray'> <br>\n",
        "basic_model_layers： <class 'list'> <br>\n",
        "basic_model_parameters： <class 'list'> <br>\n",
        "advanced_pred_test： <class 'numpy.ndarray'> <br>\n",
        "</small>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
